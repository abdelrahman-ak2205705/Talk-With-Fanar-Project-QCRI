{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e5796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# import openai\n",
    "from openai import AzureOpenAI\n",
    "# !pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3174aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def APIKeyManager(model_type, key_path):\n",
    "    \n",
    "    load_dotenv(dotenv_path=key_path, override=True)\n",
    "    if model_type=='azure':\n",
    "        client = AzureOpenAI(\n",
    "            api_version=os.environ[\"AZURE_API_VERSION\"],\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "        )\n",
    "        return client\n",
    "    elif model_type=='fanar':\n",
    "        client = OpenAI(\n",
    "            base_url = \"https://api.fanar.qa/v1\",\n",
    "            api_key  = os.environ[\"FANAR_API_KEY\"],\n",
    "        )\n",
    "        # Option A – set a default so you don’t repeat `model=…` later\n",
    "        client.default_params = {\"model\": \"Fanar-C-1-8.7B\"}\n",
    "        return client    \n",
    "    elif model_type=='gemini':\n",
    "        pass\n",
    "    return client\n",
    "\n",
    "# Load environment variables\n",
    "model_type=\"fanar\"\n",
    "deployment = APIKeyManager(model_type, \"./azure.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a84582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicClassifier:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def classify_topic(self, topic, information):\n",
    "        \"\"\"\n",
    "        Classify podcast topic and determine optimal approach\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            \n",
    "        Returns:\n",
    "            JSON with classification results\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في تحليل المواضيع وتصنيفها لإنتاج بودكاست عربي طبيعي وجذاب.\n",
    "\n",
    "المهمة: حلل الموضوع التالي وحدد أفضل نهج لتقديمه في بودكاست عربي.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات الأساسية: {information}\n",
    "\n",
    "قم بتحليل الموضوع وإرجاع النتيجة بصيغة JSON تحتوي على:\n",
    "\n",
    "{{\n",
    "    \"primary_category\": \"الفئة الرئيسية\",\n",
    "    \"category_justification\": \"سبب اختيار هذه الفئة بناءً على طبيعة الموضوع\",\n",
    "    \"optimal_style\": \"الأسلوب الأمثل للمناقشة\",\n",
    "    \"discourse_pattern\": \"نمط الخطاب المناسب\",\n",
    "    \"audience_engagement_goal\": \"هدف تفاعل الجمهور\",\n",
    "    \"cultural_sensitivity_level\": \"مستوى الحساسية الثقافية\",\n",
    "    \"controversy_potential\": \"احتمالية الجدل\",\n",
    "    \"key_discussion_angles\": [\n",
    "        \"زوايا النقاش الرئيسية المتوقعة\",\n",
    "        \"النقاط التي ستثير اهتمام الجمهور العربي\"\n",
    "    ],\n",
    "    \"natural_tension_points\": [\n",
    "        \"نقاط التوتر الطبيعية في الموضوع\",\n",
    "        \"الجوانب التي قد تثير جدلاً صحياً\"\n",
    "    ],\n",
    "    \"cultural_connection_opportunities\": [\n",
    "        \"فرص الربط بالثقافة العربية\",\n",
    "        \"المراجع المحلية والإقليمية ذات الصلة\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "الفئات المتاحة:\n",
    "1. \"العلوم والتكنولوجيا\" - للمواضيع التقنية والعلمية والابتكارات\n",
    "2. \"السياسة والشؤون العامة\" - للمواضيع السياسية والأحداث الجارية والقضايا العامة\n",
    "3. \"القضايا الاجتماعية\" - للمواضيع المجتمعية والعلاقات والقيم والتحديات الاجتماعية\n",
    "4. \"الرياضة والترفيه\" - للمواضيع الرياضية والفنية والترفيهية\n",
    "5. \"التاريخ والثقافة\" - للمواضيع التاريخية والتراثية والثقافية\n",
    "\n",
    "الأساليب المتاحة:\n",
    "- \"حواري\" - حوار طبيعي وودي بين المقدم والضيف\n",
    "- \"تعليمي\" - تركيز على الشرح والتعليم بطريقة ممتعة\n",
    "- \"ترفيهي\" - مرح وخفيف مع لمسات فكاهية\n",
    "- \"تحليلي\" - نقاش عميق ومتخصص وتحليلي\n",
    "\n",
    "أنماط الخطاب:\n",
    "- \"رسمي\" - لغة رسمية ومحترمة\n",
    "- \"ودي\" - لغة دافئة ومألوفة\n",
    "- \"جدلي\" - نقاش حيوي مع وجهات نظر متعددة\n",
    "- \"سردي\" - أسلوب حكواتي وقصصي\n",
    "\n",
    "\n",
    "\n",
    "مستوى الحساسية الثقافية:\n",
    "- \"عالي\" - يتطلب حذراً شديداً في التعامل\n",
    "- \"متوسط\" - يحتاج مراعاة ثقافية معتدلة  \n",
    "- \"منخفض\" - موضوع مقبول عموماً\n",
    "\n",
    "احتمالية الجدل:\n",
    "- \"عالية\" - موضوع مثير للجدل بطبيعته\n",
    "- \"متوسطة\" - قد يثير بعض الاختلافات\n",
    "- \"منخفضة\" - موضوع مقبول عموماً\n",
    "\n",
    "تعليمات مهمة:\n",
    "- حلل الموضوع بعمق وليس بشكل سطحي\n",
    "- اعتبر السياق الثقافي العربي في التحليل\n",
    "- ركز على ما يجعل الموضوع جذاباً للجمهور العربي\n",
    "- تأكد أن التصنيف يخدم إنتاج محتوى طبيعي وتلقائي\n",
    "- لا تضع علامات ```json في البداية أو النهاية\n",
    "- أرجع JSON صحيح فقط بدون أي نص إضافي\n",
    "-المدة 10 دقائق هي المدة المثلى للحلقة\n",
    "- \"،\"  لا تستخدم الفاصلة العربية \n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"أنت خبير في تحليل المواضيع وتصنيفها لإنتاج بودكاست عربي احترافي. تخصصك في فهم الجمهور العربي واهتماماته.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3  # Lower temperature for more consistent classification\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bde0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Result:\n",
      "{\n",
      "\"primary_category\": \"القضايا الاجتماعية\",\n",
      "\"category_justification\": \"يتناول الموضوع القضايا المرتبطة بالتكنولوجيا وكيف تؤثر على الهوية الثقافية واللغة العربية, وهو ضمن نطاق القضايا الاجتماعية.\",\n",
      "\"optimal_style\": \"تحليلي\",\n",
      "\"discourse_pattern\": \"جدلي\",\n",
      "\"audience_engagement_goal\": \"إشراك المستمعين في مناقشة مستقبل استخدام الذكاء الاصطناعي في المنطقة العربية\",\n",
      "\"cultural_sensitivity_level\": \"عالي\",\n",
      "\"controversy_potential\": \"متوسطة\",\n",
      "\"key_discussion_angles\": [\n",
      "\t\"تأثيرات الذكاء الاصطناعي المدرب على البيانات الغربية على اللغة العربية\",\n",
      "\t\"دور الدول العربية في تطوير الذكاء الاصطناعي محليا\",\n",
      "\t\"كيفية تحقيق توازن بين الاستفادة من الذكاء الاصطناعي والحفاظ على هويتنا الثقافية\",\n",
      "\t\"مخاطر فقدان الأصالة اللغوية والثقافية بسبب الاعتماد الزائد على الذكاء الاصطناعي الأجنبي\"\n",
      "],\n",
      "\"natural_tension_points\": [\n",
      "\t\"مقارنة فعالية الذكاء الاصطناعي الذي تم تدريبه محليا مقابل ذلك الذي تم تدريبه عالميا\",\n",
      "\t\"تقييم مدى نجاح جهود الحكومات العربية حتى الآن في مجال الذكاء الاصطناعي\"\n",
      "],\n",
      "\"cultural_connection_opportunities\": [\n",
      "\t\"استخدام أمثلة تاريخية وثقافية توضح أهمية اللغة العربية\",\n",
      "\t\"عرض قصص عن رواد عرب في مجالات الذكاء الاصطناعي\"\n",
      "]\n",
      "}\n",
      "\n",
      "Primary Category: القضايا الاجتماعية\n",
      "Optimal Style: تحليلي\n",
      "Discourse Pattern: جدلي\n"
     ]
    }
   ],
   "source": [
    "# Testing Instructions:\n",
    "\n",
    "# To test Step 1, add this to a new cell in your notebook:\n",
    "\n",
    "# Test Step 1: Topic Classification\n",
    "classifier = TopicClassifier(deployment, \"Fanar-C-1-8.7B\")  # Use the appropriate model for your deployment\n",
    "\n",
    "# Test with the singlehood topic\n",
    "topic = \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\"\n",
    "\n",
    "information = '''\n",
    "مع انتشار تقنيات الذكاء الاصطناعي بسرعة في العالم العربي، تزداد المخاوف حول تأثيرها على الهوية الثقافية واللغة العربية. \n",
    "تشير الدراسات إلى أن 78% من المحتوى الرقمي باللغة الإنجليزية، بينما المحتوى العربي لا يتجاوز 3%. \n",
    "معظم نماذج الذكاء الاصطناعي الحالية مدربة على بيانات غربية، مما يثير تساؤلات حول قدرتها على فهم السياق الثقافي العربي.\n",
    "في المقابل، تسعى دول مثل الإمارات والسعودية لتطوير نماذج ذكاء اصطناعي عربية مثل \"جايس\" و\"الحوراء\" لمواجهة هذا التحدي.\n",
    "التحدي الأكبر يكمن في كيفية الاستفادة من هذه التقنيات لتعزيز الثقافة العربية بدلاً من تهميشها، وضمان أن تخدم الذكاء الاصطناعي قيمنا ومبادئنا.\n",
    "'''\n",
    "\n",
    "# Run classification\n",
    "classification_result = classifier.classify_topic(topic, information)\n",
    "print(\"Classification Result:\")\n",
    "print(classification_result)\n",
    "\n",
    "\n",
    "\n",
    "# Parse and examine the JSON\n",
    "try:\n",
    "    parsed_result = json.loads(classification_result)\n",
    "    print(f\"\\nPrimary Category: {parsed_result['primary_category']}\")\n",
    "    print(f\"Optimal Style: {parsed_result['optimal_style']}\")\n",
    "    print(f\"Discourse Pattern: {parsed_result['discourse_pattern']}\")\n",
    "except:\n",
    "    print(\"Error parsing JSON result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ee26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePersonaGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def generate_personas(self, topic, information, classification_result):\n",
    "        \"\"\"\n",
    "        Generate simple but effective host and guest personas\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            \n",
    "        Returns:\n",
    "            JSON with simple host and guest personas\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse classification to understand the requirements\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid classification JSON provided\")\n",
    "        \n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في تصميم شخصيات البودكاست العربي.\n",
    "\n",
    "المهمة: أنشئ مقدم وضيف بسيطين ومناسبين لهذا الموضوع.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات: {information}\n",
    "الفئة: {primary_category}\n",
    "الأسلوب المطلوب: {optimal_style}\n",
    "\n",
    "أرجع النتيجة بصيغة JSON بسيط:\n",
    "\n",
    "{{\n",
    "    \"host\": {{\n",
    "        \"name\": \"اسم المقدم\",\n",
    "        \"age\": عمر رقمي,\n",
    "        \"background\": \"خلفية مختصرة في جملة واحدة\",\n",
    "        \"personality\": \"وصف شخصيته في جملة واحدة\",\n",
    "        \"speaking_style\": \"أسلوب حديثه في جملة واحدة\"\n",
    "    }},\n",
    "    \"guest\": {{\n",
    "        \"name\": \"اسم الضيف\", \n",
    "        \"age\": عمر رقمي,\n",
    "        \"background\": \"خلفية مختصرة في جملة واحدة\",\n",
    "        \"expertise\": \"مجال خبرته في جملة واحدة\",\n",
    "        \"personality\": \"وصف شخصيته في جملة واحدة\",\n",
    "        \"speaking_style\": \"أسلوب حديثه في جملة واحدة\"\n",
    "    }},\n",
    "    \"why_good_match\": \"لماذا هذا المقدم والضيف مناسبان لهذا الموضوع - جملة واحدة\"\n",
    "}}\n",
    "\n",
    "متطلبات:\n",
    "- أسماء عربية مألوفة\n",
    "- شخصيات بسيطة وقابلة للتصديق\n",
    "- مناسبة للموضوع والأسلوب المطلوب\n",
    "- المقدم فضولي والضيف خبير أو صاحب تجربة\n",
    "- لا تضع علامات ```json\n",
    "- أرجع JSON فقط\n",
    "- \"،\"  لا تستخدم الفاصلة العربية \n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في تصميم شخصيات بودكاست بسيطة ومؤثرة. الأسلوب المطلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f699140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona Generation Result:\n",
      "{\n",
      "  \"host\": {\n",
      "    \"name\": \"لمى عبد الله\",\n",
      "    \"age\": 35,\n",
      "    \"background\": \"صحفية متخصصة في الشأن التكنولوجي في إحدى الجرائد المحلية\",\n",
      "    \"personality\": \"فضولية ومهتمة بتسليط الضوء على الفوائد والتحديات\",\n",
      "    \"speaking_style\": \"تطرح الأسئلة المفتوحة لتعميق النقاش وتستعرض نقاط البحث بشكل واضح\"\n",
      "  },\n",
      "  \"guest\": {\n",
      "    \"name\": \"علي محسن\",\n",
      "    \"age\": 42,\n",
      "    \"background\": \"باحث في علوم الكمبيوتر وأستاذ مساعد في جامعة حكومية\",\n",
      "    \"expertise\": \"ذكاء اصطناعي ومعالجة اللغة الطبيعية\",\n",
      "    \"personality\": \"عقلاني ومتحمس لاستخدام الذكاء الاصطناعي لتعزيز الثقافة العربية\",\n",
      "    \"speaking_style\": \"يتحدث بسهولة عن مجال تخصصه ويشارك آرائه بطريقة موضوعية\"\n",
      "  },\n",
      "  \"why_good_match\": \"مزيج مثالي بين اهتمام الصحفية بفهم تأثير الذكاء الاصطناعي وثروة الخبرات العلمية للأستاذ\"\n",
      "}\n",
      "\n",
      "Host Name: لمى عبد الله\n",
      "Guest Name: علي محسن\n"
     ]
    }
   ],
   "source": [
    "persona = SimplePersonaGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "persona_result = persona.generate_personas(topic, information, classification_result)\n",
    "print(\"Persona Generation Result:\")\n",
    "print(persona_result)\n",
    "try:\n",
    "    parsed_result = json.loads(persona_result)\n",
    "    print(f\"\\nHost Name: {parsed_result['host']['name']}\")\n",
    "    print(f\"Guest Name: {parsed_result['guest']['name']}\")\n",
    "except:\n",
    "    print(\"Error parsing JSON result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab52d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationStructureGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def generate_conversation_structure(self, topic, information, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Step 3: Generate core conversation structure (V1 skeleton)\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            \n",
    "        Returns:\n",
    "            JSON with V1-style conversation structure (without rich dialogue content)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided for classification or personas\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        discourse_pattern = classification.get(\"discourse_pattern\", \"\")\n",
    "        recommended_duration = classification.get(\"recommended_duration\", \"10 دقيقة\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in designing conversation structures for Arabic podcasts.\n",
    "\n",
    "Task: Create the basic conversation structure in natural dialogue format.\n",
    "\n",
    "Topic: {topic}\n",
    "Information: {information}\n",
    "\n",
    "Context:\n",
    "- Category: {primary_category}\n",
    "- Style: {optimal_style}\n",
    "- Discourse Pattern: {discourse_pattern}\n",
    "- Duration: {recommended_duration}\n",
    "\n",
    "Characters:\n",
    "- Host: {host_name} - {host.get('background', '')}\n",
    "- Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Create the conversation outline in JSON format:\n",
    "\n",
    "{{\n",
    "    \"episode_topic\": \"{topic}\",\n",
    "    \"personas\": {{\n",
    "        \"host\": {{\n",
    "            \"name\": \"{host_name}\",\n",
    "            \"background\": \"{host.get('background', '')}\",\n",
    "            \"speaking_style\": \"{host.get('speaking_style', '')}\"\n",
    "        }},\n",
    "        \"guest\": {{\n",
    "            \"name\": \"{guest_name}\",\n",
    "            \"background\": \"{guest.get('background', '')}\",\n",
    "            \"speaking_style\": \"{guest.get('speaking_style', '')}\"\n",
    "        }}\n",
    "    }},\n",
    "    \"conversation_flow\": {{\n",
    "        \"intro1\": {{\n",
    "            \"opening_line\": \"Actual opening line by the host\",\n",
    "            \"podcast_introduction\": \"Podcast introduction related to the topic\",\n",
    "            \"episode_hook\": \"Specific engaging sentence about the topic\",\n",
    "            \"tone_guidance\": \"Appropriate tone for {optimal_style} style\"\n",
    "        }},\n",
    "        \"intro2\": {{\n",
    "            \"topic_introduction\": \"Clear topic introduction\",\n",
    "            \"guest_welcome\": \"Welcome to guest {guest_name}\",\n",
    "            \"guest_bio_highlight\": \"Guest background introduction\",\n",
    "            \"transition_to_discussion\": \"Transition to main discussion\"\n",
    "        }},\n",
    "        \"main_discussion\": [\n",
    "            {{\n",
    "                \"point_title\": \"First main point of the topic\",\n",
    "                \"personal_angle\": \"How it relates to the characters' backgrounds\"\n",
    "            }},\n",
    "            {{\n",
    "                \"point_title\": \"Second main point of the topic\", \n",
    "                \"personal_angle\": \"Personal angle for this point\"\n",
    "            }},\n",
    "            {{\n",
    "                \"point_title\": \"Third main point of the topic\",\n",
    "                \"personal_angle\": \"Personal connection and concluding angle\"\n",
    "            }}\n",
    "        ],\n",
    "        \"closing\": {{\n",
    "            \"conclusion\": {{\n",
    "                \"main_takeaways\": \"Main takeaways\",\n",
    "                \"guest_final_message\": \"Guest's final message\",\n",
    "                \"host_closing_thoughts\": \"Host's closing thoughts\"\n",
    "            }},\n",
    "            \"outro\": {{\n",
    "                \"guest_appreciation\": \"Thank the guest\",\n",
    "                \"audience_thanks\": \"Thank the listeners\",\n",
    "                \"call_to_action\": \"Call for engagement\",\n",
    "                \"final_goodbye\": \"Final goodbye\"\n",
    "            }}\n",
    "        }}\n",
    "    }},\n",
    "    \"cultural_context\": {{\n",
    "        \"proverbs_sayings\": [\n",
    "            \"Relevant Arabic proverb for the topic\",\n",
    "            \"Related wisdom saying\"\n",
    "        ],\n",
    "        \"regional_references\": [\n",
    "            \"Local reference related to the topic\",\n",
    "            \"Relevant Arab experience\"\n",
    "        ]\n",
    "    }},\n",
    "    \"language_style\": {{\n",
    "        \"formality_level\": \"Appropriate level for {optimal_style} style\",\n",
    "        \"dialect_touches\": \"Light dialectal touches according to the host\",\n",
    "        \"vocabulary_richness\": \"Vocabulary suitable for the topic\"\n",
    "    }},\n",
    "    \"technical_notes\": {{\n",
    "        \"pacing_guidance\": \"Appropriate pacing for {recommended_duration} duration\",\n",
    "        \"pause_points\": \"Natural pause points\",\n",
    "        \"emphasis_moments\": \"Important emphasis moments\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Write actual content, not descriptions\n",
    "- Use the real character names ({host_name}, {guest_name})\n",
    "- Make all content related to the topic: {topic}\n",
    "- All JSON values must be in Modern Standard Arabic (MSA)\n",
    "- JSON keys should be in English\n",
    "- Use ONLY English commas (,) - NEVER Arabic commas (،)\n",
    "- Use ONLY standard double quotes (\") - NEVER Arabic quotes\n",
    "- Do NOT include any explanatory text before or after the JSON\n",
    "- Do NOT include ```json markers\n",
    "- Return ONLY valid JSON that can be parsed by json.loads()\n",
    "- Ensure every opening brace {{ has a closing brace }}\n",
    "- Ensure every array [ has a closing bracket ]\n",
    "- End every JSON property with a comma except the last one in each object\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in designing conversation structures for Arabic podcasts. Required style: {optimal_style}. You MUST return ONLY valid JSON with English punctuation. No explanatory text. No Arabic commas. No extra text before or after JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6  # Balanced for structure creation\n",
    "        )\n",
    "        \n",
    "        # Clean the response to ensure valid JSON\n",
    "        raw_response = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Remove any text before the first { and after the last }\n",
    "        start_idx = raw_response.find('{')\n",
    "        end_idx = raw_response.rfind('}')\n",
    "        \n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            clean_json = raw_response[start_idx:end_idx+1]\n",
    "        else:\n",
    "            clean_json = raw_response\n",
    "        \n",
    "        # Replace Arabic commas with English commas\n",
    "        clean_json = clean_json.replace('،', ',')\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(clean_json)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Problematic JSON: {clean_json[:500]}...\")\n",
    "            # Return raw response for debugging\n",
    "            return clean_json\n",
    "\n",
    "    def validate_conversation_structure(self, structure_json):\n",
    "        \"\"\"\n",
    "        Validate the conversation structure\n",
    "        \"\"\"\n",
    "        required_keys = [\"episode_topic\", \"personas\", \"conversation_flow\", \"cultural_context\", \"language_style\", \"technical_notes\"]\n",
    "        \n",
    "        conversation_flow_required = [\"intro1\", \"intro2\", \"main_discussion\", \"closing\"]\n",
    "        intro1_required = [\"opening_line\", \"podcast_introduction\", \"episode_hook\"]\n",
    "        intro2_required = [\"topic_introduction\", \"guest_welcome\", \"guest_bio_highlight\"]\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            structure = json.loads(structure_json)\n",
    "            \n",
    "            missing_keys = []\n",
    "            \n",
    "            # Check main structure\n",
    "            for key in required_keys:\n",
    "                if key not in structure:\n",
    "                    missing_keys.append(key)\n",
    "            \n",
    "            # Check conversation flow\n",
    "            if \"conversation_flow\" in structure:\n",
    "                conv_flow = structure[\"conversation_flow\"]\n",
    "                for key in conversation_flow_required:\n",
    "                    if key not in conv_flow:\n",
    "                        missing_keys.append(f\"conversation_flow.{key}\")\n",
    "                \n",
    "                # Check intro1\n",
    "                if \"intro1\" in conv_flow:\n",
    "                    intro1 = conv_flow[\"intro1\"]\n",
    "                    for key in intro1_required:\n",
    "                        if key not in intro1:\n",
    "                            missing_keys.append(f\"intro1.{key}\")\n",
    "                \n",
    "                # Check intro2\n",
    "                if \"intro2\" in conv_flow:\n",
    "                    intro2 = conv_flow[\"intro2\"]\n",
    "                    for key in intro2_required:\n",
    "                        if key not in intro2:\n",
    "                            missing_keys.append(f\"intro2.{key}\")\n",
    "                \n",
    "                # Check main discussion\n",
    "                if \"main_discussion\" in conv_flow:\n",
    "                    main_disc = conv_flow[\"main_discussion\"]\n",
    "                    if not isinstance(main_disc, list) or len(main_disc) < 3:\n",
    "                        missing_keys.append(\"main_discussion (need at least 3 points)\")\n",
    "                    else:\n",
    "                        for i, point in enumerate(main_disc):\n",
    "                            if \"point_title\" not in point:\n",
    "                                missing_keys.append(f\"main_discussion[{i}].point_title\")\n",
    "            \n",
    "            if missing_keys:\n",
    "                return False, f\"Missing required keys: {missing_keys}\"\n",
    "            \n",
    "            return True, \"Conversation structure validation successful\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_structure_quality(self, structure_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality of the conversation structure\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            structure = json.loads(structure_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check completeness\n",
    "            conv_flow = structure.get(\"conversation_flow\", {})\n",
    "            analysis[\"has_intro1\"] = bool(conv_flow.get(\"intro1\"))\n",
    "            analysis[\"has_intro2\"] = bool(conv_flow.get(\"intro2\"))\n",
    "            analysis[\"has_main_discussion\"] = bool(conv_flow.get(\"main_discussion\"))\n",
    "            analysis[\"has_closing\"] = bool(conv_flow.get(\"closing\"))\n",
    "            \n",
    "            # Check main discussion depth\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            analysis[\"discussion_points\"] = len(main_disc)\n",
    "            analysis[\"adequate_points\"] = len(main_disc) >= 3\n",
    "            \n",
    "            # Check cultural context\n",
    "            cultural = structure.get(\"cultural_context\", {})\n",
    "            analysis[\"has_proverbs\"] = len(cultural.get(\"proverbs_sayings\", [])) >= 1\n",
    "            analysis[\"has_regional_refs\"] = len(cultural.get(\"regional_references\", [])) >= 1\n",
    "            \n",
    "            # Overall readiness\n",
    "            readiness_indicators = [\n",
    "                analysis[\"has_intro1\"],\n",
    "                analysis[\"has_intro2\"],\n",
    "                analysis[\"has_main_discussion\"],\n",
    "                analysis[\"has_closing\"],\n",
    "                analysis[\"adequate_points\"],\n",
    "                analysis[\"has_proverbs\"]\n",
    "            ]\n",
    "            analysis[\"readiness_score\"] = sum(readiness_indicators)\n",
    "            analysis[\"ready_for_next_step\"] = analysis[\"readiness_score\"] >= 5\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze structure quality\"}\n",
    "\n",
    "# Usage:\n",
    "# generator = ConversationStructureGenerator(deployment, \"Fanar-C-1-8.7B\") \n",
    "# structure_result = generator.generate_conversation_structure(topic, information, classification_result, personas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09091744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation structure Result:\n",
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"لمى عبد الله\",\n",
      "      \"background\": \"صحفية متخصصة في الشأن التكنولوجي في إحدى الجرائد المحلية\",\n",
      "      \"speaking_style\": \"تطرح أسئلة مفتوحة لتعميق النقاش وتعزز الحديث بموضوعية واضحة\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"علي محسن\",\n",
      "      \"background\": \"باحث في علوم الكمبيوتر وأستاذ مساعد في جامعة حكومية\",\n",
      "      \"speaking_style\": \"يعرض أفكارًا فنية بأسلوب سلس ويتفاعل مع المواضيع بتحليل عميق\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحباً جميعاً! اليوم نناقش دور الذكاء الاصطناعي في صون هويتنا العربية.\",\n",
      "      \"podcast_introduction\": \"هذا برنامج 'العالم بين يديك' حيث نبحث في تحديات المجتمع المعاصر.\",\n",
      "      \"episode_hook\": \"هل يمكن للآلات الفكرية فهم روح مجتمعاتنا؟ دعونا نعرف!\",\n",
      "      \"tone_guidance\": \"تحليلي ومتفتح للأفكار\"\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"نتناول هنا محدودية البيانات العربية المدربة عليها معظم تقنيات الذكاء الاصطناعي.\",\n",
      "      \"guest_welcome\": \"أرحب بكل سرور البروفيسور علي محسن, خبير علوم الحاسوب.\",\n",
      "      \"guest_bio_highlight\": \"شكراً لاستضافتنا اليوم, ومعرفتُك تؤكد أهمية نقاشنا.\",\n",
      "      \"transition_to_discussion\": \"دعنا ندخل مباشرة للنقطة الأولى.\"\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"مشكلة تدريب النماذج على محتوى غير عربي\",\n",
      "        \"personal_angle\": \"كمراسل تكنولوجيا, أرى إمكانية للتأثيرات الغريبة على اللغة والثقافة.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"خطوات نحو تطوير نماذج عربية\",\n",
      "        \"personal_angle\": \"الباحث علي, هل لنا تحديث بشأن مشاريع الوطن الخليجية?\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"استخدام الذكاء الاصطناعي لتعزيز التعريف بالحضارة الإسلامية\",\n",
      "        \"personal_angle\": \"كيف يؤثر ذلك على تعريف الأجيال الناشئة بهويتنا الفريدة؟\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الخلاصة: يجب توجيه الابتكار لتعزيز هويّتنا, وليس استبدالها.\",\n",
      "        \"guest_final_message\": \"النصائح النهائية لعلي: دعم المبادرات التعليمية والتواصل المستمر.\",\n",
      "        \"host_closing_thoughts\": \"إن مواصلة المناقشة ستنعكس بلا شك على مستقبلنا الرقمي الآمن.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكرا لكل تعاون البروفيسور علي محسن.\",\n",
      "        \"audience_thanks\": \"شكراً لكم للاستماع والاستفادة من خبرة الضيف معنا.\",\n",
      "        \"call_to_action\": \"انضموا لنوع جديد من الحوارات عبر وسائل التواصل الاجتماعي.\",\n",
      "        \"final_goodbye\": \"الى اللقاء!\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"الأصل دائمٌ, مهما تبدلت الظروف.\",\n",
      "      \"الحديث السليم يفيد السامعين\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"تاريخ الكويت كنموذج لمواكبة التقدم والحفاظ على الأصالة.\",\n",
      "      \"دور مصر التاريخي في نشر العلم\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"ملائمة للمناقشة التحليلية\",\n",
      "    \"dialect_touches\": \"إضافة عناصر بسيطة من لهجة بلدان مجلس التعاون الخليجي للإلفة\",\n",
      "    \"vocabulary_richness\": \"مصطلحات متنوعة تتوافق مع الموضوع\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"سرعة مناسبة لقضاء 10 دقائق\",\n",
      "    \"pause_points\": \"[... عند الانتقال بين النقاط الرئيسية...]\",\n",
      "    \"emphasis_moments\": \"[...على مفاهيم تحديد الأولويات ...] \"\n",
      "  }\n",
      "}\n",
      "✅ JSON parsed successfully\n",
      "Episode topic: الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\n"
     ]
    }
   ],
   "source": [
    "generator = ConversationStructureGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "outline_result = generator.generate_conversation_structure(topic, information, classification_result, persona_result)\n",
    "\n",
    "print(\"Conversation structure Result:\")\n",
    "print(outline_result)\n",
    "\n",
    "try:\n",
    "    parsed_result = json.loads(outline_result)\n",
    "    print(\"✅ JSON parsed successfully\")\n",
    "    print(f\"Episode topic: {parsed_result.get('episode_topic', 'Not found')}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ Error parsing JSON: {e}\")\n",
    "    print(\"First 200 chars of response:\")\n",
    "    print(outline_result[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cece3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "class SectionalDialogueContentEnhancer:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def enhance_intro_sections(self, topic, classification_result, personas_result, intro1, intro2):\n",
    "        \"\"\"\n",
    "        Chunk 1: Enhance intro1 and intro2 sections only\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic\n",
    "            classification_result: JSON string from classification\n",
    "            personas_result: JSON string from personas\n",
    "            intro1: intro1 section from conversation_flow\n",
    "            intro2: intro2 section from conversation_flow\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced intro1 and intro2 sections\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in enhancing Arabic podcast introductions.\n",
    "\n",
    "Task: Enhance ONLY the intro sections with natural dialogue elements.\n",
    "\n",
    "Topic: {topic}\n",
    "Category: {primary_category}\n",
    "Style: {optimal_style}\n",
    "\n",
    "Host: {host_name} - {host.get('background', '')}\n",
    "Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Current intro1: {json.dumps(intro1, ensure_ascii=False)}\n",
    "Current intro2: {json.dumps(intro2, ensure_ascii=False)}\n",
    "\n",
    "ENHANCEMENT REQUIREMENTS:\n",
    "\n",
    "For intro1, ADD these fields:\n",
    "- \"spontaneity_elements\": [3-4 natural spontaneous phrases that the host might use when opening, in MSA]\n",
    "\n",
    "For intro2, ADD these fields:  \n",
    "- \"cultural_connections\": [2-3 ways to connect this topic to Arab culture/values, in MSA]\n",
    "\n",
    "Return the enhanced sections in this exact format:\n",
    "{{\n",
    "    \"intro1\": {{\n",
    "        [keep all existing intro1 fields],\n",
    "        \"spontaneity_elements\": [new content]\n",
    "    }},\n",
    "    \"intro2\": {{\n",
    "        [keep all existing intro2 fields],\n",
    "        \"cultural_connections\": [new content]\n",
    "    }}\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Keep ALL existing content unchanged\n",
    "- Add only the specified new fields\n",
    "- All new values in Modern Standard Arabic (MSA)\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "- Make content specific to topic: {topic}\n",
    "- Match the {optimal_style} style\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You enhance Arabic podcast intros. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def enhance_main_discussion_point(self, topic, classification_result, personas_result, discussion_point, point_index):\n",
    "        \"\"\"\n",
    "        Chunk 2: Enhance individual main discussion points\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic\n",
    "            classification_result: JSON string from classification  \n",
    "            personas_result: JSON string from personas\n",
    "            discussion_point: Single discussion point to enhance\n",
    "            point_index: Index of this point (for logging)\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced discussion point\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        cultural_sensitivity = classification.get(\"cultural_sensitivity_level\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in enhancing Arabic podcast discussion points.\n",
    "\n",
    "Task: Enhance ONE discussion point with rich dialogue elements.\n",
    "\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Point #{point_index + 1}\n",
    "\n",
    "Current discussion point: {json.dumps(discussion_point, ensure_ascii=False)}\n",
    "\n",
    "Add EXACTLY these 5 fields. Keep all existing fields unchanged:\n",
    "\n",
    "{{\n",
    "    [all existing fields from discussion_point],\n",
    "    \"spontaneous_triggers\": [\"trigger 1 in MSA\", \"trigger 2 in MSA\"],\n",
    "    \"disagreement_points\": \"disagreement description in MSA\",\n",
    "    \"cultural_references\": [\"reference 1 in MSA\", \"reference 2 in MSA\"],\n",
    "    \"natural_transitions\": \"transition phrase in MSA\",\n",
    "    \"emotional_triggers\": \"emotional description in MSA\"\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Keep ALL existing fields exactly as they are\n",
    "- Add only the 5 new fields shown above\n",
    "- All new content in Modern Standard Arabic (MSA)\n",
    "- Use English punctuation ONLY (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "- Make content relevant to topic: {topic}\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You enhance Arabic podcast discussion points. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def enhance_closing_sections(self, topic, classification_result, personas_result, closing_section):\n",
    "        \"\"\"\n",
    "        Chunk 3: Enhance closing (conclusion + outro) sections\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic\n",
    "            classification_result: JSON string from classification\n",
    "            personas_result: JSON string from personas  \n",
    "            closing_section: closing section from conversation_flow\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced closing section\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in enhancing Arabic podcast closings.\n",
    "\n",
    "Task: Enhance the closing section with natural wrap-up elements.\n",
    "\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "\n",
    "Host: {host_name} - {host.get('background', '')}\n",
    "Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Current closing: {json.dumps(closing_section, ensure_ascii=False)}\n",
    "\n",
    "ENHANCEMENT REQUIREMENTS:\n",
    "\n",
    "For conclusion subsection, ADD:\n",
    "- \"emotional_closure\": \"how to create emotional satisfaction for listeners, in MSA\"\n",
    "- \"key_insights\": [2-3 key insights that should be highlighted in the wrap-up, in MSA]\n",
    "\n",
    "For outro subsection, ADD:\n",
    "- \"memorable_ending\": \"a memorable way to end that listeners will remember, in MSA\"\n",
    "- \"connection_building\": \"ways to build ongoing connection with the audience, in MSA\"\n",
    "\n",
    "Return enhanced closing in this exact format:\n",
    "{{\n",
    "    \"conclusion\": {{\n",
    "        [keep all existing conclusion fields],\n",
    "        \"emotional_closure\": \"new content\",\n",
    "        \"key_insights\": [new content]\n",
    "    }},\n",
    "    \"outro\": {{\n",
    "        [keep all existing outro fields],\n",
    "        \"memorable_ending\": \"new content\",\n",
    "        \"connection_building\": \"new content\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Keep ALL existing content unchanged\n",
    "- Add only the specified new fields\n",
    "- All new values in Modern Standard Arabic (MSA)\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "- Make content feel conclusive and satisfying\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You enhance Arabic podcast closings. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def create_global_elements(self, topic, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Chunk 4: Create global elements (spontaneous_moments, personality_interactions, dialogue_techniques)\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic\n",
    "            classification_result: JSON string from classification\n",
    "            personas_result: JSON string from personas\n",
    "            \n",
    "        Returns:\n",
    "            Global elements as JSON string\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        cultural_sensitivity = classification.get(\"cultural_sensitivity_level\", \"\")\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in creating global dialogue elements for Arabic podcasts.\n",
    "\n",
    "Task: Create three global sections that enhance the overall conversation flow.\n",
    "\n",
    "Topic: {topic}\n",
    "Category: {primary_category}\n",
    "Style: {optimal_style}\n",
    "\n",
    "Host: {host_name} - {host.get('background', '')}\n",
    "Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Create EXACTLY this JSON structure with proper English punctuation:\n",
    "\n",
    "{{\n",
    "    \"spontaneous_moments\": {{\n",
    "        \"natural_interruptions\": [\n",
    "            \"first natural interruption in MSA\",\n",
    "            \"second natural interruption in MSA\",\n",
    "            \"third natural interruption in MSA\"\n",
    "        ],\n",
    "        \"emotional_reactions\": [\n",
    "            \"first emotional reaction in MSA\",\n",
    "            \"second emotional reaction in MSA\", \n",
    "            \"third emotional reaction in MSA\"\n",
    "        ],\n",
    "        \"personal_stories\": [\n",
    "            \"first personal story in MSA\",\n",
    "            \"second personal story in MSA\"\n",
    "        ],\n",
    "        \"humorous_moments\": [\n",
    "            \"first humorous moment in MSA\",\n",
    "            \"second humorous moment in MSA\"\n",
    "        ]\n",
    "    }},\n",
    "    \"personality_interactions\": {{\n",
    "        \"host_strengths\": \"host strengths description in MSA\",\n",
    "        \"guest_expertise\": \"guest expertise description in MSA\",\n",
    "        \"natural_chemistry\": \"chemistry description in MSA\",\n",
    "        \"tension_points\": \"tension points description in MSA\",\n",
    "        \"collaboration_moments\": \"collaboration description in MSA\"\n",
    "    }},\n",
    "    \"dialogue_techniques\": {{\n",
    "        \"questioning_styles\": [\n",
    "            \"first questioning style in MSA\",\n",
    "            \"second questioning style in MSA\",\n",
    "            \"third questioning style in MSA\"\n",
    "        ],\n",
    "        \"storytelling_moments\": [\n",
    "            \"first storytelling moment in MSA\",\n",
    "            \"second storytelling moment in MSA\"\n",
    "        ],\n",
    "        \"audience_engagement\": [\n",
    "            \"first engagement technique in MSA\",\n",
    "            \"second engagement technique in MSA\",\n",
    "            \"third engagement technique in MSA\"\n",
    "        ],\n",
    "        \"emotional_peaks\": [\n",
    "            \"first emotional peak in MSA\",\n",
    "            \"second emotional peak in MSA\"\n",
    "        ]\n",
    "    }}\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- Replace placeholder text with actual content in Modern Standard Arabic (MSA)\n",
    "- Use ONLY English commas (,) and standard quotes (\")\n",
    "- NO Arabic commas (،) or special punctuation\n",
    "- NO extra text before or after JSON\n",
    "- NO explanatory text\n",
    "- Make content specific to {host_name}, {guest_name}, and topic: {topic}\n",
    "- Follow the EXACT structure shown above\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You create global dialogue elements. Return ONLY valid JSON with English punctuation. No Arabic commas. No extra text.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7  # Reduced temperature for better JSON compliance\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def enhance_dialogue_content(self, topic, information, classification_result, personas_result, structure_result):\n",
    "        \"\"\"\n",
    "        Main orchestration method: Coordinates all chunks\n",
    "        \"\"\"\n",
    "        print(\"🔧 Starting sectional dialogue enhancement...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            structure = json.loads(structure_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid structure JSON provided\")\n",
    "        \n",
    "        # Extract sections\n",
    "        conv_flow = structure.get(\"conversation_flow\", {})\n",
    "        intro1 = conv_flow.get(\"intro1\", {})\n",
    "        intro2 = conv_flow.get(\"intro2\", {})\n",
    "        main_discussion = conv_flow.get(\"main_discussion\", [])\n",
    "        closing = conv_flow.get(\"closing\", {})\n",
    "        \n",
    "        # Chunk 1: Enhance intro sections\n",
    "        print(\"📝 Chunk 1: Enhancing intro sections...\")\n",
    "        try:\n",
    "            enhanced_intros_json = self.enhance_intro_sections(\n",
    "                topic, classification_result, personas_result, intro1, intro2\n",
    "            )\n",
    "            enhanced_intros = json.loads(enhanced_intros_json)\n",
    "            \n",
    "            # Update structure\n",
    "            structure[\"conversation_flow\"][\"intro1\"].update(enhanced_intros.get(\"intro1\", {}))\n",
    "            structure[\"conversation_flow\"][\"intro2\"].update(enhanced_intros.get(\"intro2\", {}))\n",
    "            print(\"✅ Intro sections enhanced successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error enhancing intros: {e}\")\n",
    "        \n",
    "        # Small delay between chunks\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 2: Enhance main discussion points (one by one)\n",
    "        print(\"📝 Chunk 2: Enhancing main discussion points...\")\n",
    "        enhanced_discussion_points = []\n",
    "        \n",
    "        for i, point in enumerate(main_discussion):\n",
    "            print(f\"  Enhancing discussion point {i+1}/{len(main_discussion)}...\")\n",
    "            try:\n",
    "                enhanced_point_json = self.enhance_main_discussion_point(\n",
    "                    topic, classification_result, personas_result, point, i\n",
    "                )\n",
    "                enhanced_point = json.loads(enhanced_point_json)\n",
    "                enhanced_discussion_points.append(enhanced_point)\n",
    "                print(f\"  ✅ Point {i+1} enhanced successfully\")\n",
    "                \n",
    "                # Small delay between points\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️ Error enhancing point {i+1}: {e}\")\n",
    "                print(f\"  🔄 Attempting fallback enhancement for point {i+1}...\")\n",
    "                \n",
    "                # Try fallback enhancement for this point\n",
    "                try:\n",
    "                    fallback_point = self._create_fallback_discussion_point(\n",
    "                        topic, classification_result, personas_result, point, i\n",
    "                    )\n",
    "                    enhanced_discussion_points.append(fallback_point)\n",
    "                    print(f\"  ✅ Point {i+1} enhanced with fallback method\")\n",
    "                except Exception as fallback_error:\n",
    "                    print(f\"  ⚠️ Fallback failed for point {i+1}: {fallback_error}\")\n",
    "                    # Add minimal enhancements to original point\n",
    "                    enhanced_point = point.copy()\n",
    "                    enhanced_point.update(self._get_minimal_discussion_enhancements())\n",
    "                    enhanced_discussion_points.append(enhanced_point)\n",
    "                    print(f\"  📝 Point {i+1} enhanced with minimal defaults\")\n",
    "        \n",
    "        # Update structure with enhanced discussion points\n",
    "        structure[\"conversation_flow\"][\"main_discussion\"] = enhanced_discussion_points\n",
    "        print(\"✅ All main discussion points processed\")\n",
    "        \n",
    "        # Small delay between chunks\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 3: Enhance closing sections\n",
    "        print(\"📝 Chunk 3: Enhancing closing sections...\")\n",
    "        try:\n",
    "            enhanced_closing_json = self.enhance_closing_sections(\n",
    "                topic, classification_result, personas_result, closing\n",
    "            )\n",
    "            enhanced_closing = json.loads(enhanced_closing_json)\n",
    "            \n",
    "            # Update structure\n",
    "            structure[\"conversation_flow\"][\"closing\"].update(enhanced_closing)\n",
    "            print(\"✅ Closing sections enhanced successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error enhancing closing: {e}\")\n",
    "        \n",
    "        # Small delay between chunks  \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 4: Create global elements\n",
    "        print(\"📝 Chunk 4: Creating global elements...\")\n",
    "        try:\n",
    "            global_elements_json = self.create_global_elements(\n",
    "                topic, classification_result, personas_result\n",
    "            )\n",
    "            global_elements = json.loads(global_elements_json)\n",
    "            \n",
    "            # Add global elements to structure\n",
    "            structure.update(global_elements)\n",
    "            print(\"✅ Global elements created successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error creating global elements: {e}\")\n",
    "            print(\"🔄 Attempting to create fallback global elements...\")\n",
    "            \n",
    "            # Create fallback global elements\n",
    "            try:\n",
    "                fallback_elements = self._create_fallback_global_elements(\n",
    "                    topic, classification_result, personas_result\n",
    "                )\n",
    "                structure.update(fallback_elements)\n",
    "                print(\"✅ Fallback global elements created successfully\")\n",
    "            except Exception as fallback_error:\n",
    "                print(f\"⚠️ Fallback also failed: {fallback_error}\")\n",
    "                print(\"📝 Using minimal default global elements...\")\n",
    "                # Add minimal default elements so validation doesn't fail\n",
    "                structure.update(self._get_minimal_global_elements())\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"🎉 Sectional dialogue enhancement completed!\")\n",
    "        \n",
    "        return json.dumps(structure, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def _clean_json_response(self, response):\n",
    "        \"\"\"Helper method to clean JSON response - Enhanced version\"\"\"\n",
    "        response = response.strip()\n",
    "        \n",
    "        # Remove any text before first { and after last }\n",
    "        start_idx = response.find('{')\n",
    "        end_idx = response.rfind('}')\n",
    "        \n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            clean_json = response[start_idx:end_idx+1]\n",
    "        else:\n",
    "            clean_json = response\n",
    "        \n",
    "        # Replace Arabic commas and punctuation with English equivalents\n",
    "        clean_json = clean_json.replace('،', ',')\n",
    "        clean_json = clean_json.replace('\"', '\"')\n",
    "        clean_json = clean_json.replace('\"', '\"')\n",
    "        clean_json = clean_json.replace(''', \"'\")\n",
    "        clean_json = clean_json.replace(''', \"'\")\n",
    "        \n",
    "        # Fix common JSON issues\n",
    "        # Remove trailing commas before closing braces/brackets\n",
    "        import re\n",
    "        clean_json = re.sub(r',(\\s*[}\\]])', r'\\1', clean_json)\n",
    "        \n",
    "        # Ensure proper quote escaping\n",
    "        clean_json = clean_json.replace('\\\\\"', '\"')\n",
    "        \n",
    "        return clean_json\n",
    "\n",
    "    def validate_enhanced_content(self, enhanced_json):\n",
    "        \"\"\"Validate the enhanced dialogue content\"\"\"\n",
    "        try:\n",
    "            enhanced = json.loads(enhanced_json)\n",
    "            \n",
    "            missing_elements = []\n",
    "            \n",
    "            # Check global sections\n",
    "            required_global = [\"spontaneous_moments\", \"personality_interactions\", \"dialogue_techniques\"]\n",
    "            for element in required_global:\n",
    "                if element not in enhanced:\n",
    "                    missing_elements.append(element)\n",
    "            \n",
    "            # Check enhanced conversation flow\n",
    "            conv_flow = enhanced.get(\"conversation_flow\", {})\n",
    "            \n",
    "            # Check intro1 enhancements\n",
    "            intro1 = conv_flow.get(\"intro1\", {})\n",
    "            if \"spontaneity_elements\" not in intro1:\n",
    "                missing_elements.append(\"intro1.spontaneity_elements\")\n",
    "            \n",
    "            # Check intro2 enhancements  \n",
    "            intro2 = conv_flow.get(\"intro2\", {})\n",
    "            if \"cultural_connections\" not in intro2:\n",
    "                missing_elements.append(\"intro2.cultural_connections\")\n",
    "            \n",
    "            # Check main discussion enhancements\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            required_point_fields = [\"spontaneous_triggers\", \"disagreement_points\", \"cultural_references\", \"natural_transitions\", \"emotional_triggers\"]\n",
    "            \n",
    "            for i, point in enumerate(main_disc):\n",
    "                for field in required_point_fields:\n",
    "                    if field not in point:\n",
    "                        missing_elements.append(f\"main_discussion[{i}].{field}\")\n",
    "            \n",
    "            # Check closing enhancements\n",
    "            closing = conv_flow.get(\"closing\", {})\n",
    "            conclusion = closing.get(\"conclusion\", {})\n",
    "            outro = closing.get(\"outro\", {})\n",
    "            \n",
    "            if \"emotional_closure\" not in conclusion:\n",
    "                missing_elements.append(\"closing.conclusion.emotional_closure\")\n",
    "            if \"key_insights\" not in conclusion:\n",
    "                missing_elements.append(\"closing.conclusion.key_insights\")\n",
    "            if \"memorable_ending\" not in outro:\n",
    "                missing_elements.append(\"closing.outro.memorable_ending\")\n",
    "            if \"connection_building\" not in outro:\n",
    "                missing_elements.append(\"closing.outro.connection_building\")\n",
    "            \n",
    "            if missing_elements:\n",
    "                return False, f\"Missing enhanced elements: {missing_elements}\"\n",
    "            \n",
    "            return True, \"Sectional dialogue content enhancement validation successful\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            def _create_fallback_global_elements(self, topic, classification_result, personas_result):\n",
    "                    \"\"\"Create fallback global elements with simpler prompts\"\"\"\n",
    "                    try:\n",
    "                        classification = json.loads(classification_result)\n",
    "                        personas = json.loads(personas_result)\n",
    "                    except:\n",
    "                        raise ValueError(\"Invalid JSON provided\")\n",
    "                    \n",
    "                    host = personas.get(\"host\", {})\n",
    "                    guest = personas.get(\"guest\", {})\n",
    "                    host_name = host.get('name', 'المقدم')\n",
    "                    guest_name = guest.get('name', 'الضيف')\n",
    "                    \n",
    "                    # Create each section separately with very simple prompts\n",
    "                    fallback_elements = {}\n",
    "                    \n",
    "                    # Spontaneous moments\n",
    "                    try:\n",
    "                        spont_prompt = f'Create spontaneous_moments for topic \"{topic}\" with host {host_name} and guest {guest_name}. Return only JSON with natural_interruptions, emotional_reactions, personal_stories, humorous_moments arrays. All values in MSA.'\n",
    "                        \n",
    "                        spont_response = self.deployment.chat.completions.create(\n",
    "                            model=self.model,\n",
    "                            messages=[{\"role\": \"user\", \"content\": spont_prompt}],\n",
    "                            temperature=0.6\n",
    "                        )\n",
    "                        spont_json = self._clean_json_response(spont_response.choices[0].message.content)\n",
    "                        fallback_elements[\"spontaneous_moments\"] = json.loads(spont_json)\n",
    "                    except:\n",
    "                        fallback_elements[\"spontaneous_moments\"] = self._get_default_spontaneous_moments()\n",
    "                    \n",
    "                    # Personality interactions  \n",
    "                    try:\n",
    "                        personality_prompt = f'Create personality_interactions for {host_name} and {guest_name} discussing \"{topic}\". Return only JSON with host_strengths, guest_expertise, natural_chemistry, tension_points, collaboration_moments. All values in MSA.'\n",
    "                        \n",
    "                        personality_response = self.deployment.chat.completions.create(\n",
    "                            model=self.model,\n",
    "                            messages=[{\"role\": \"user\", \"content\": personality_prompt}],\n",
    "                            temperature=0.6\n",
    "                        )\n",
    "                        personality_json = self._clean_json_response(personality_response.choices[0].message.content)\n",
    "                        fallback_elements[\"personality_interactions\"] = json.loads(personality_json)\n",
    "                    except:\n",
    "                        fallback_elements[\"personality_interactions\"] = self._get_default_personality_interactions(host_name, guest_name)\n",
    "                    \n",
    "                    # Dialogue techniques\n",
    "                    try:\n",
    "                        dialogue_prompt = f'Create dialogue_techniques for Arabic podcast about \"{topic}\". Return only JSON with questioning_styles, storytelling_moments, audience_engagement, emotional_peaks arrays. All values in MSA.'\n",
    "                        \n",
    "                        dialogue_response = self.deployment.chat.completions.create(\n",
    "                            model=self.model,\n",
    "                            messages=[{\"role\": \"user\", \"content\": dialogue_prompt}],\n",
    "                            temperature=0.6\n",
    "                        )\n",
    "                        dialogue_json = self._clean_json_response(dialogue_response.choices[0].message.content)\n",
    "                        fallback_elements[\"dialogue_techniques\"] = json.loads(dialogue_json)\n",
    "                    except:\n",
    "                        fallback_elements[\"dialogue_techniques\"] = self._get_default_dialogue_techniques()\n",
    "                    \n",
    "                    return fallback_elements\n",
    "\n",
    "    def _get_minimal_global_elements(self):\n",
    "        \"\"\"Return minimal default global elements\"\"\"\n",
    "        return {\n",
    "            \"spontaneous_moments\": self._get_default_spontaneous_moments(),\n",
    "            \"personality_interactions\": self._get_default_personality_interactions(\"المقدم\", \"الضيف\"),\n",
    "            \"dialogue_techniques\": self._get_default_dialogue_techniques()\n",
    "        }\n",
    "\n",
    "    def _get_default_spontaneous_moments(self):\n",
    "        \"\"\"Default spontaneous moments\"\"\"\n",
    "        return {\n",
    "            \"natural_interruptions\": [\n",
    "                \"اسمحي لي أن أضيف نقطة هنا\",\n",
    "                \"هذا يذكرني بموقف مشابه\",\n",
    "                \"انتظر، هذا مهم جداً\"\n",
    "            ],\n",
    "            \"emotional_reactions\": [\n",
    "                \"هذا مؤثر فعلاً\",\n",
    "                \"لم أفكر في الأمر من هذه الزاوية\",\n",
    "                \"أتفق معك تماماً\"\n",
    "            ],\n",
    "            \"personal_stories\": [\n",
    "                \"أتذكر موقفاً مشابهاً حدث معي\",\n",
    "                \"في تجربتي الشخصية وجدت أن\"\n",
    "            ],\n",
    "            \"humorous_moments\": [\n",
    "                \"هذا يذكرني بنكتة لطيفة\",\n",
    "                \"الموقف له جانب طريف\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _create_fallback_discussion_point(self, topic, classification_result, personas_result, discussion_point, point_index):\n",
    "        \"\"\"Create fallback enhancement for a single discussion point\"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "        except:\n",
    "            classification = {}\n",
    "        \n",
    "        # Create a simple enhancement with minimal API call\n",
    "        enhanced_point = discussion_point.copy()\n",
    "        \n",
    "        # Add minimal enhancements\n",
    "        enhanced_point.update({\n",
    "            \"spontaneous_triggers\": [\n",
    "                \"هذا يثير تساؤلاً مهماً\",\n",
    "                \"دعني أشارككم تجربة في هذا المجال\"\n",
    "            ],\n",
    "            \"disagreement_points\": \"قد تختلف وجهات النظر حول أفضل طريقة للتعامل مع هذه القضية\",\n",
    "            \"cultural_references\": [\n",
    "                \"كما يقول المثل: العلم نور\",\n",
    "                \"تراثنا يعلمنا أهمية التوازن في كل شيء\"\n",
    "            ],\n",
    "            \"natural_transitions\": \"هذا يقودنا إلى نقطة مهمة أخرى\",\n",
    "            \"emotional_triggers\": \"هذا الموضوع يلامس قلوب كل من يهتم بمستقبل ثقافتنا\"\n",
    "        })\n",
    "        \n",
    "        return enhanced_point\n",
    "\n",
    "    def _get_minimal_discussion_enhancements(self):\n",
    "        \"\"\"Get minimal enhancements for discussion points\"\"\"\n",
    "        return {\n",
    "            \"spontaneous_triggers\": [\"هذا مهم فعلاً\", \"دعني أضيف شيئاً\"],\n",
    "            \"disagreement_points\": \"قد نختلف في وجهات النظر\",\n",
    "            \"cultural_references\": [\"العلم نور\", \"الحكمة ضالة المؤمن\"],\n",
    "            \"natural_transitions\": \"لننتقل للنقطة التالية\",\n",
    "            \"emotional_triggers\": \"هذا يثير مشاعر قوية\"\n",
    "        }\n",
    "\n",
    "    def _create_fallback_global_elements(self, topic, classification_result, personas_result):\n",
    "        \"\"\"Create fallback global elements with simpler prompts\"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            return self._get_minimal_global_elements()\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        # Create each section separately with very simple prompts\n",
    "        fallback_elements = {}\n",
    "        \n",
    "        # Spontaneous moments\n",
    "        try:\n",
    "            spont_prompt = f'Create JSON for spontaneous_moments about \"{topic}\". Include natural_interruptions, emotional_reactions, personal_stories, humorous_moments arrays. All in MSA. Use English punctuation only.'\n",
    "            \n",
    "            spont_response = self.deployment.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Return only valid JSON with English punctuation.\"},\n",
    "                    {\"role\": \"user\", \"content\": spont_prompt}\n",
    "                ],\n",
    "                temperature=0.5\n",
    "            )\n",
    "            spont_json = self._clean_json_response(spont_response.choices[0].message.content)\n",
    "            fallback_elements[\"spontaneous_moments\"] = json.loads(spont_json)\n",
    "        except Exception as e:\n",
    "            print(f\"    Spontaneous moments fallback failed: {e}\")\n",
    "            fallback_elements[\"spontaneous_moments\"] = self._get_default_spontaneous_moments()\n",
    "        \n",
    "        # Personality interactions  \n",
    "        try:\n",
    "            personality_prompt = f'Create JSON for personality_interactions between host {host_name} and guest {guest_name}. Include host_strengths, guest_expertise, natural_chemistry, tension_points, collaboration_moments. All in MSA. Use English punctuation only.'\n",
    "            \n",
    "            personality_response = self.deployment.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Return only valid JSON with English punctuation.\"},\n",
    "                    {\"role\": \"user\", \"content\": personality_prompt}\n",
    "                ],\n",
    "                temperature=0.5\n",
    "            )\n",
    "            personality_json = self._clean_json_response(personality_response.choices[0].message.content)\n",
    "            fallback_elements[\"personality_interactions\"] = json.loads(personality_json)\n",
    "        except Exception as e:\n",
    "            print(f\"    Personality interactions fallback failed: {e}\")\n",
    "            fallback_elements[\"personality_interactions\"] = self._get_default_personality_interactions(host_name, guest_name)\n",
    "        \n",
    "        # Dialogue techniques\n",
    "        try:\n",
    "            dialogue_prompt = f'Create JSON for dialogue_techniques for podcast about \"{topic}\". Include questioning_styles, storytelling_moments, audience_engagement, emotional_peaks arrays. All in MSA. Use English punctuation only.'\n",
    "            \n",
    "            dialogue_response = self.deployment.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Return only valid JSON with English punctuation.\"},\n",
    "                    {\"role\": \"user\", \"content\": dialogue_prompt}\n",
    "                ],\n",
    "                temperature=0.5\n",
    "            )\n",
    "            dialogue_json = self._clean_json_response(dialogue_response.choices[0].message.content)\n",
    "            fallback_elements[\"dialogue_techniques\"] = json.loads(dialogue_json)\n",
    "        except Exception as e:\n",
    "            print(f\"    Dialogue techniques fallback failed: {e}\")\n",
    "            fallback_elements[\"dialogue_techniques\"] = self._get_default_dialogue_techniques()\n",
    "        \n",
    "        return fallback_elements\n",
    "\n",
    "# Usage:\n",
    "# enhancer = SectionalDialogueContentEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "# enhanced_result = enhancer.enhance_dialogue_content(topic, information, classification_result, persona_result, outline_result)\n",
    "\n",
    "    def _get_default_personality_interactions(self, host_name, guest_name):\n",
    "        \"\"\"Default personality interactions\"\"\"\n",
    "        return {\n",
    "            \"host_strengths\": f\"{host_name} ماهر في طرح الأسئلة المناسبة وتوجيه الحوار\",\n",
    "            \"guest_expertise\": f\"{guest_name} يقدم معرفة عميقة في مجال تخصصه\",\n",
    "            \"natural_chemistry\": \"يتفاعل المقدم والضيف بطريقة طبيعية ومريحة\",\n",
    "            \"tension_points\": \"قد يختلفان في بعض وجهات النظر مما يثري النقاش\",\n",
    "            \"collaboration_moments\": \"يبنيان على أفكار بعضهما البعض لإثراء المحتوى\"\n",
    "        }\n",
    "\n",
    "    def _get_default_dialogue_techniques(self):\n",
    "        \"\"\"Default dialogue techniques\"\"\"\n",
    "        return {\n",
    "            \"questioning_styles\": [\n",
    "                \"أسئلة مفتوحة لتعميق النقاش\",\n",
    "                \"أسئلة تحليلية للوصول للجذور\",\n",
    "                \"أسئلة شخصية لإضافة البعد الإنساني\"\n",
    "            ],\n",
    "            \"storytelling_moments\": [\n",
    "                \"سرد تجارب شخصية ذات صلة\",\n",
    "                \"قصص نجاح ملهمة\"\n",
    "            ],\n",
    "            \"audience_engagement\": [\n",
    "                \"طرح أسئلة يفكر فيها المستمع\",\n",
    "                \"استخدام أمثلة من الواقع\",\n",
    "                \"دعوة المستمعين للتفاعل\"\n",
    "            ],\n",
    "            \"emotional_peaks\": [\n",
    "                \"لحظات تأملية عميقة\",\n",
    "                \"قصص مؤثرة تلامس القلب\"\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a07febcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Starting sectional dialogue enhancement...\n",
      "==================================================\n",
      "📝 Chunk 1: Enhancing intro sections...\n",
      "✅ Intro sections enhanced successfully\n",
      "📝 Chunk 2: Enhancing main discussion points...\n",
      "  Enhancing discussion point 1/3...\n",
      "  ⚠️ Error enhancing point 1: Expecting ',' delimiter: line 4 column 77 (char 228)\n",
      "  🔄 Attempting fallback enhancement for point 1...\n",
      "  ✅ Point 1 enhanced with fallback method\n",
      "  Enhancing discussion point 2/3...\n",
      "  ✅ Point 2 enhanced successfully\n",
      "  Enhancing discussion point 3/3...\n",
      "  ✅ Point 3 enhanced successfully\n",
      "✅ All main discussion points processed\n",
      "📝 Chunk 3: Enhancing closing sections...\n",
      "✅ Closing sections enhanced successfully\n",
      "📝 Chunk 4: Creating global elements...\n",
      "⚠️ Error creating global elements: Expecting ',' delimiter: line 6 column 87 (char 366)\n",
      "🔄 Attempting to create fallback global elements...\n",
      "✅ Fallback global elements created successfully\n",
      "==================================================\n",
      "🎉 Sectional dialogue enhancement completed!\n",
      "Enhanced dialogue content:\n",
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"لمى عبد الله\",\n",
      "      \"background\": \"صحفية متخصصة في الشأن التكنولوجي في إحدى الجرائد المحلية\",\n",
      "      \"speaking_style\": \"تطرح أسئلة مفتوحة لتعميق النقاش وتعزز الحديث بموضوعية واضحة\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"علي محسن\",\n",
      "      \"background\": \"باحث في علوم الكمبيوتر وأستاذ مساعد في جامعة حكومية\",\n",
      "      \"speaking_style\": \"يعرض أفكارًا فنية بأسلوب سلس ويتفاعل مع المواضيع بتحليل عميق\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحبا أصدقائي,\",\n",
      "      \"podcast_introduction\": \"انضموا الآن إلى حلقتنا حول الذكاء الصناعي وتراثنا العربي الغني.\",\n",
      "      \"episode_hook\": \"كيف نوازن بين الابتكار والتقاليد?\",\n",
      "      \"tone_guidance\": \"تحليلي ومتفتح للأفكار\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"إن هذا موضوع يهم كل واحد منا بلا شك\",\n",
      "        \"لنبدأ بتبادل الأفكار حول هذه المسألة المثيرة\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"من الواضح أن الكثير من أدوات الذكاء الاصطناعي تشكلت بناءً على بيانات غربية.\",\n",
      "      \"guest_welcome\": \"مرحبًا دكتور علي, شكرًا لك على تواجدك معنا.\",\n",
      "      \"guest_bio_highlight\": \"عبر عن رأيك بخصوص كيفية تأثير ذلك على هويّتنا كعرب.\",\n",
      "      \"transition_to_discussion\": \"فلنرسم خطوطًا واضحة لهذا الأمر إذًا\",\n",
      "      \"cultural_connections\": [\n",
      "        \"يحمل هذا النقاش أهميته لأن الإسلام دين العلم والتفكير الناقد\",\n",
      "        \"والتقاليد الثقافية العربية مليئة بالأمثلة التي تدعم الإبداع\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"مشكلة تدريب النماذج على محتوى غير عربي\",\n",
      "        \"personal_angle\": \"كمراسل تكنولوجيا, أرى إمكانية للتأثيرات الغريبة على اللغة والثقافة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"هذا يثير تساؤلاً مهماً\",\n",
      "          \"دعني أشارككم تجربة في هذا المجال\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"قد تختلف وجهات النظر حول أفضل طريقة للتعامل مع هذه القضية\",\n",
      "        \"cultural_references\": [\n",
      "          \"كما يقول المثل: العلم نور\",\n",
      "          \"تراثنا يعلمنا أهمية التوازن في كل شيء\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"هذا يقودنا إلى نقطة مهمة أخرى\",\n",
      "        \"emotional_triggers\": \"هذا الموضوع يلامس قلوب كل من يهتم بمستقبل ثقافتنا\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"خطوات نحو تطوير نماذج عربية\",\n",
      "        \"personal_angle\": \"الباحث علي, هل لنا تحديث بشأن مشاريع الوطن الخليجية?\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ما إذا كانت هذه النماذج تعزز التراث الثقافي\",\n",
      "          \"أمثلة لنجاحات الإمارات في هذا المجال\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"قد يجادل البعض بأن التركيز الشديد قد يبسط التفرد الثقافي العربي بدلاً من تعزيزه.\",\n",
      "        \"cultural_references\": [\n",
      "          \"ذكر قصة حارس الوعل في هذا السياق\",\n",
      "          \"استشهاد بشاعر عربي معروف يدافع عن اللغة والتقاليد\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"من الجدير بالاعتبار أيضًا...\",\n",
      "        \"emotional_triggers\": \"يمكن أن تثير هذه المناقشة الشعور بالمهمة الفريدة للحفاظ على هويتنا.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"استخدام الذكاء الاصطناعي لتعزيز التعريف بالحضارة الإسلامية\",\n",
      "        \"personal_angle\": \"كيف يؤثر ذلك على تعريف الأجيال الناشئة بهويتنا الفريدة?\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"عند مناقشة نماذج اللغة التي قد تقوض المصطلحات الدينية,\",\n",
      "          \"بالحديث عن إمكانات الذكاء الاصطناعي في إبراز التراث العلمي الإسلامي.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"قد يجادل البعض أن الاعتماد المفرط على أجهزة الذكاء الاصطناعي يمكن أن يخفف قدرة الشباب على التفاعل مباشرة مع مصادر الهوية الثقافية.\",\n",
      "        \"cultural_references\": [\n",
      "          \"يمكن ذكر مثال أدباء العرب القدامى كالجاحظ أو ابن خلدون لتأكيد أهمية التفكير النقدي الأصيل.\",\n",
      "          \"ربما الاستشهاد بنجاح استخدام AI حالياً لإحياء نسخ رقمية لتاريخ المساجد الكبرى مثل جامع القرويين بالمغرب.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"هذا يقودنا إلى السؤال التالي حول كيفية تحقيق توازن بين الابتكار والتأكد من عدم فقدان جوهر هويتنا.\",\n",
      "        \"emotional_triggers\": \"من الطبيعي الشعور بالقلق حيال الحفاظ على هويّتنا الأصيلة بينما نتجه نحو مستقبل رقمي سريع.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الخلاصة: يجب توجيه الابتكار لتعزيز هويتنا, وليس استبدالها.\",\n",
      "        \"guest_final_message\": \"النصائح النهائية لعلي: دعم المبادرات التعليمية والتواصل المستمر.\",\n",
      "        \"host_closing_thoughts\": \"إن مواصلة المناقشة ستنعكس بلا شك على مستقبلنا الرقمي الآمن.\",\n",
      "        \"emotional_closure\": \"إن الاعتراف بترابط تكنولوجيا اليوم وهويتنا يمكن أن يلهم التقدير المشترك بين الأجيال وأن يبني روابط قوية مع جذورنا.\",\n",
      "        \"key_insights\": [\n",
      "          \"أولاً, تسليح الشباب بالمعرفة التقنية وربط هذه المعرفة بقيمهم الثقافية أمر حاسم.\",\n",
      "          \"ثانياً, تشجيع تطوير محتوى عربي أصيل ومناسب للذكاء الاصطناعي سيساهم في حماية الهوية.\",\n",
      "          \"أخيراً, خلق بيئة تفاعلية وداعمة للمبتكرين العرب سيضمن الاستدامة والبقاء الفريد لثقافتنا في عصر الديجيتال.\"\n",
      "        ]\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكرا لكل تعاون البروفيسور علي محسن.\",\n",
      "        \"audience_thanks\": \"شكراً لكم للاستماع والاستفادة من خبرة الضيف معنا.\",\n",
      "        \"call_to_action\": \"انضموا لنا في الرحلة نحو فهم أفضل لكيفية اندماج الذكاء الاصطناعي والثقافة العربية.\",\n",
      "        \"memorable_ending\": \"تذكر دائماً, قدرة تقنيات الغد ترجع إلى فهم وتعاون المجتمع العربي اليوم.\",\n",
      "        \"connection_building\": \"ابقوا على اطلاع بأحدث النقاشات والمقالات ذات الصلة عبر صفحتنا على الفيسبوك أو تويتر تحت #ArabicAIIdentityPodcast\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"الأصل دائمٌ, مهما تبدلت الظروف.\",\n",
      "      \"الحديث السليم يفيد السامعين\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"تاريخ الكويت كنموذج لمواكبة التقدم والحفاظ على الأصالة.\",\n",
      "      \"دور مصر التاريخي في نشر العلم\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"ملائمة للمناقشة التحليلية\",\n",
      "    \"dialect_touches\": \"إضافة عناصر بسيطة من لهجة بلدان مجلس التعاون الخليجي للإلفة\",\n",
      "    \"vocabulary_richness\": \"مصطلحات متنوعة تتوافق مع الموضوع\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"سرعة مناسبة لقضاء 10 دقائق\",\n",
      "    \"pause_points\": \"[... عند الانتقال بين النقاط الرئيسية...]\",\n",
      "    \"emphasis_moments\": \"[...على مفاهيم تحديد الأولويات ...] \"\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"spontaneous_moments\": [\n",
      "      {\n",
      "        \"title\": \"الذكاء الاصطناعي والهوية العربية\",\n",
      "        \"natural_interruption\": \"تخيلوا هذا.. كنت أناقش مع صديقي عن الذكاء الاصطناعي! 🎯*\",\n",
      "        \"emotional_reaction\": \"أشعر بالفضول حول تأثير التكنولوجيا الحديثة على تراثنا الثقافي.\",\n",
      "        \"personal_story\": \"عندما زرت متحفًا تقليديًّا, لاحظت كم كان الأطفال أكثر انجذابًا للألعاب الافتراضية بدلاً من القطع الأثرية الحقيقية. 🤔\",\n",
      "        \"humorous_moment\": \"لقد تساءلت ذات مرة إذا كانت الروبوتات قد تكتسب حس الفكاهة العربي يومًا ما! 😅\"\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"الحفاظ على الهوية العربية\",\n",
      "        \"natural_interruption\": \"Wait, have you seen those AI-generated poetry pieces? They're quite impressive but...!\",\n",
      "        \"emotional_reaction\": \"I feel it's crucial that we guide this technological advancement while preserving our cultural values.\",\n",
      "        \"personal_story\": \"My grandmother once told me stories at night by candlelight; now, I wonder how future generations will connect with their heritage through digital means.\",\n",
      "        \"humorous_moment\": \"Imagine an Arabic AI robot trying to make a joke using ancient proverbs – hilarious chaos guaranteed! 😂\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"interaction\": {\n",
      "      \"host\": \"لمى عبد الله\",\n",
      "      \"guest\": \"علي محسن\",\n",
      "      \"details\": {\n",
      "        \"host_strengths\": [\n",
      "          \"Exceptional listening skills.\",\n",
      "          \"Enthusiastic facilitation of engaging discussions.\"\n",
      "        ],\n",
      "        \"guest_expertise\": [\n",
      "          \"Deep knowledge in cultural anthropology.\",\n",
      "          \"Insightful storytelling abilities\"\n",
      "        ],\n",
      "        \"natural_chemistry\": \"Their shared passion for understanding diverse cultures quickly established a comfortable rapport.\",\n",
      "        \"tension_points\": [\n",
      "          \"Occasional differences in pacing during the conversation were noted but effectively managed by both parties.\"\n",
      "        ],\n",
      "        \"collaboration_moments\": [\n",
      "          \"A particularly compelling discussion about cross-cultural communication showed their collaborative strengths.\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"dialogue_techniques\": {\n",
      "    \"dialogue_techniques\": {\n",
      "      \"questioning_styles\": [\n",
      "        \"How can we leverage AI to preserve and share our cultural heritage?\",\n",
      "        \"In what ways does digital technology enhance or challenge traditional Arabic identity?\",\n",
      "        \"What are some innovative approaches Arab creators have taken to integrate AI into their artistic expressions?\"\n",
      "      ],\n",
      "      \"storytelling_moments\": [\n",
      "        \"Share personal stories of how family traditions were passed down through generations before the digital age.\",\n",
      "        \"Discuss an example of a successful Arab startup that uses AI to promote Islamic values while embracing modern technology.\",\n",
      "        \"Tell a story about how language preservation efforts are being aided by AI tools.\"\n",
      "      ],\n",
      "      \"audience_engagement\": [\n",
      "        \"Ask listeners to share their own experiences with balancing technological advancements and maintaining cultural identity.\",\n",
      "        \"Suggest interactive activities where audience members could create their own content using AI but with a focus on promoting Arabic culture.\",\n",
      "        \"Invite experts from various fields like linguistics, computer science, and anthropology to engage in live discussions on these topics.\"\n",
      "      ],\n",
      "      \"emotional_peaks\": [\n",
      "        \"Highlight moments when technology has brought people together across distances to celebrate shared cultural events.\",\n",
      "        \"Discuss challenges faced by those who feel disconnected from their roots due to increased reliance on digital platforms.\",\n",
      "        \"Celebrate successes of individuals and communities who have successfully integrated AI without compromising their cultural identity.\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Validation: Sectional dialogue content enhancement validation successful\n"
     ]
    }
   ],
   "source": [
    "# This should now work without the global elements error\n",
    "enhancer = SectionalDialogueContentEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "enhanced_result = enhancer.enhance_dialogue_content(\n",
    "    topic, \n",
    "    information, \n",
    "    classification_result, \n",
    "    persona_result, \n",
    "    outline_result\n",
    ")\n",
    "\n",
    "print(\"Enhanced dialogue content:\")\n",
    "print(enhanced_result)\n",
    "\n",
    "# Validation should now pass\n",
    "is_valid, message = enhancer.validate_enhanced_content(enhanced_result)\n",
    "print(f\"Validation: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a852810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedFinalPolishEnhancer:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def polish_spontaneous_moments(self, topic, classification_result, personas_result, current_spontaneous_moments):\n",
    "        \"\"\"\n",
    "        Chunk 1: Polish and expand spontaneous moments\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in refining spontaneous conversation elements for Arabic podcasts.\n",
    "\n",
    "Task: Enhance and expand the existing spontaneous_moments section.\n",
    "\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Host: {host_name} - {host.get('background', '')}\n",
    "Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Current spontaneous moments: {json.dumps(current_spontaneous_moments, ensure_ascii=False)}\n",
    "\n",
    "Expand this section with more detailed, character-specific content:\n",
    "\n",
    "{{\n",
    "    \"natural_interruptions\": [5-6 specific interruptions that {host_name} and {guest_name} might naturally make, in MSA],\n",
    "    \"emotional_reactions\": [5-6 authentic emotional reactions specific to this topic and these personalities, in MSA],\n",
    "    \"personal_stories\": [3-4 personal stories based on their actual backgrounds and the topic, in MSA],\n",
    "    \"humorous_moments\": [3-4 light humor moments that fit the style and topic perfectly, in MSA],\n",
    "    \"spontaneous_questions\": [3-4 unexpected questions that might arise naturally during discussion, in MSA],\n",
    "    \"connecting_phrases\": [4-5 natural connecting phrases for smooth conversation flow, in MSA]\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- All content in Modern Standard Arabic (MSA)\n",
    "- Make content specific to {host_name}, {guest_name}, and topic: {topic}\n",
    "- Match the {optimal_style} conversation style\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You refine spontaneous elements for Arabic podcasts. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def polish_personality_interactions(self, topic, classification_result, personas_result, current_personality_interactions):\n",
    "        \"\"\"\n",
    "        Chunk 2: Polish and deepen personality interactions\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in refining personality dynamics for Arabic podcasts.\n",
    "\n",
    "Task: Enhance and deepen the personality_interactions section.\n",
    "\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Host: {host_name} - {host.get('background', '')} - {host.get('speaking_style', '')}\n",
    "Guest: {guest_name} - {guest.get('background', '')} - {guest.get('speaking_style', '')}\n",
    "\n",
    "Current personality interactions: {json.dumps(current_personality_interactions, ensure_ascii=False)}\n",
    "\n",
    "Create enhanced personality interactions:\n",
    "\n",
    "{{\n",
    "    \"host_strengths\": \"detailed description of {host_name}'s specific conversational strengths for this topic, in MSA\",\n",
    "    \"guest_expertise\": \"detailed description of {guest_name}'s expertise and how it shines in this discussion, in MSA\",\n",
    "    \"natural_chemistry\": \"specific ways {host_name} and {guest_name} complement each other naturally, in MSA\",\n",
    "    \"tension_points\": \"specific healthy disagreement areas that create engaging dialogue, in MSA\",\n",
    "    \"collaboration_moments\": \"specific moments where they build beautifully on each other's ideas, in MSA\",\n",
    "    \"communication_styles\": \"how their different communication styles create dynamic dialogue, in MSA\",\n",
    "    \"mutual_respect\": \"how they show respect for each other's viewpoints during discussion, in MSA\",\n",
    "    \"energy_dynamics\": \"how their energy levels and enthusiasm interact throughout the conversation, in MSA\"\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- All content in Modern Standard Arabic (MSA)\n",
    "- Make descriptions specific to these exact personalities and topic\n",
    "- Focus on realistic, believable interactions\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You refine personality dynamics. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def create_shared_experiences(self, topic, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Chunk 3: Create shared experiences section\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in identifying shared experiences for Arabic podcast conversations.\n",
    "\n",
    "Task: Create a shared_experiences section for meaningful connections.\n",
    "\n",
    "Topic: {topic}\n",
    "Category: {primary_category}\n",
    "Style: {optimal_style}\n",
    "\n",
    "Host: {host_name} - {host.get('background', '')}\n",
    "Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Create this exact structure:\n",
    "\n",
    "{{\n",
    "    \"common_ground\": [\n",
    "        \"first specific similarity between {host_name} and {guest_name} related to topic, in MSA\",\n",
    "        \"second specific similarity that creates connection, in MSA\", \n",
    "        \"third common experience they can relate to, in MSA\"\n",
    "    ],\n",
    "    \"generational_perspectives\": [\n",
    "        \"first generational difference that enriches discussion, in MSA\",\n",
    "        \"second age-related viewpoint difference, in MSA\",\n",
    "        \"third perspective difference based on experience, in MSA\"\n",
    "    ],\n",
    "    \"professional_overlaps\": [\n",
    "        \"first area where their work/interests intersect, in MSA\",\n",
    "        \"second professional connection point, in MSA\"\n",
    "    ],\n",
    "    \"cultural_touchstones\": [\n",
    "        \"first shared cultural reference they both understand, in MSA\",\n",
    "        \"second cultural element that connects them, in MSA\",\n",
    "        \"third cultural experience they can both relate to, in MSA\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- All content in Modern Standard Arabic (MSA)\n",
    "- Make connections specific to these personalities and topic\n",
    "- Create believable, realistic shared experiences\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You create shared experiences. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def create_contemporary_relevance(self, topic, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Chunk 4: Create contemporary relevance section\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "        except:\n",
    "            classification = {}\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in connecting topics to contemporary relevance for Arabic podcasts.\n",
    "\n",
    "Task: Create contemporary_relevance section connecting the topic to current times.\n",
    "\n",
    "Topic: {topic}\n",
    "Category: {primary_category}\n",
    "Style: {optimal_style}\n",
    "\n",
    "Create this exact structure:\n",
    "\n",
    "{{\n",
    "    \"current_events\": [\n",
    "        \"first current event related to {topic} in the Arab world, in MSA\",\n",
    "        \"second recent development relevant to the topic, in MSA\",\n",
    "        \"third contemporary happening that connects to the discussion, in MSA\"\n",
    "    ],\n",
    "    \"future_implications\": [\n",
    "        \"first future impact of {topic} on Arab society, in MSA\", \n",
    "        \"second long-term implication to consider, in MSA\",\n",
    "        \"third future trend or development to watch, in MSA\"\n",
    "    ],\n",
    "    \"regional_perspectives\": [\n",
    "        \"how {topic} affects different Arab regions differently, in MSA\",\n",
    "        \"regional approaches or responses to this topic, in MSA\"\n",
    "    ],\n",
    "    \"global_connections\": [\n",
    "        \"how {topic} connects Arab world to global trends, in MSA\",\n",
    "        \"international aspects that affect Arab perspectives, in MSA\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- All content in Modern Standard Arabic (MSA)\n",
    "- Make content specific to topic: {topic}\n",
    "- Focus on realistic, current relevance\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You create contemporary relevance. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def enhance_cultural_context(self, topic, classification_result, current_cultural_context):\n",
    "        \"\"\"\n",
    "        Chunk 5: Enhance cultural context with more depth\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "        except:\n",
    "            classification = {}\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in enhancing cultural context for Arabic podcasts.\n",
    "\n",
    "Task: Enhance and expand the cultural_context section.\n",
    "\n",
    "Topic: {topic}\n",
    "Category: {primary_category}\n",
    "Current cultural context: {json.dumps(current_cultural_context, ensure_ascii=False)}\n",
    "\n",
    "Create enhanced cultural context:\n",
    "\n",
    "{{\n",
    "    \"proverbs_sayings\": [\n",
    "        \"first relevant Arabic proverb for {topic}, in MSA\",\n",
    "        \"second wise saying that applies to the discussion, in MSA\",\n",
    "        \"third cultural wisdom relevant to the topic, in MSA\",\n",
    "        \"fourth proverb that adds depth to the conversation, in MSA\"\n",
    "    ],\n",
    "    \"regional_references\": [\n",
    "        \"first regional reference relevant to {topic}, in MSA\",\n",
    "        \"second local example or story, in MSA\", \n",
    "        \"third cultural reference from Arab history, in MSA\",\n",
    "        \"fourth contemporary Arab example, in MSA\"\n",
    "    ],\n",
    "    \"historical_connections\": [\n",
    "        \"first historical parallel or lesson relevant to {topic}, in MSA\",\n",
    "        \"second way this topic connects to Arab heritage, in MSA\"\n",
    "    ],\n",
    "    \"literary_references\": [\n",
    "        \"first relevant quote from Arabic literature, in MSA\",\n",
    "        \"second literary reference that enriches the discussion, in MSA\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- All content in Modern Standard Arabic (MSA)\n",
    "- Make all references authentic and relevant to topic\n",
    "- Include accurate cultural knowledge\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You enhance cultural context. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def create_advanced_dialogue_flow(self, topic, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Chunk 6: Create advanced dialogue flow section for smoother conversations\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in creating advanced dialogue flow for Arabic podcasts.\n",
    "\n",
    "Task: Create an advanced_dialogue_flow section for natural conversation dynamics.\n",
    "\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Host: {host_name}\n",
    "Guest: {guest_name}\n",
    "\n",
    "Create this structure:\n",
    "\n",
    "{{\n",
    "    \"conversation_rhythms\": [\n",
    "        \"first natural rhythm pattern for this type of discussion, in MSA\",\n",
    "        \"second pacing technique that works well, in MSA\",\n",
    "        \"third rhythm variation to maintain interest, in MSA\"\n",
    "    ],\n",
    "    \"bridge_phrases\": [\n",
    "        \"first smooth transition phrase {host_name} might use, in MSA\",\n",
    "        \"second connecting phrase for topic shifts, in MSA\", \n",
    "        \"third natural bridge between ideas, in MSA\"\n",
    "    ],\n",
    "    \"emphasis_techniques\": [\n",
    "        \"first way to emphasize important points naturally, in MSA\",\n",
    "        \"second technique for highlighting key insights, in MSA\",\n",
    "        \"third method for creating memorable moments, in MSA\"\n",
    "    ],\n",
    "    \"recovery_strategies\": [\n",
    "        \"first way to gracefully recover from awkward moments, in MSA\",\n",
    "        \"second technique for handling disagreements smoothly, in MSA\"\n",
    "    ],\n",
    "    \"engagement_boosters\": [\n",
    "        \"first technique to re-engage if energy drops, in MSA\",\n",
    "        \"second way to maintain listener interest, in MSA\",\n",
    "        \"third method for creating connection with audience, in MSA\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- All content in Modern Standard Arabic (MSA)\n",
    "- Make techniques specific to these personalities and topic\n",
    "- Focus on practical, usable dialogue techniques\n",
    "- Use English punctuation only (no ،)\n",
    "- Return only valid JSON, no extra text\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You create advanced dialogue flow. Style: {optimal_style}. Return only valid JSON with English punctuation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_json_response(response.choices[0].message.content)\n",
    "\n",
    "    def add_final_polish(self, topic, information, classification_result, personas_result, enhanced_content_result):\n",
    "        \"\"\"\n",
    "        Main orchestration method: Coordinates all polishing chunks\n",
    "        \"\"\"\n",
    "        print(\"🎨 Starting enhanced final polishing...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            enhanced_content = json.loads(enhanced_content_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid enhanced content JSON provided\")\n",
    "        \n",
    "        # Chunk 1: Polish spontaneous moments\n",
    "        print(\"✨ Chunk 1: Polishing spontaneous moments...\")\n",
    "        try:\n",
    "            current_spontaneous = enhanced_content.get(\"spontaneous_moments\", {})\n",
    "            polished_spontaneous_json = self.polish_spontaneous_moments(\n",
    "                topic, classification_result, personas_result, current_spontaneous\n",
    "            )\n",
    "            polished_spontaneous = json.loads(polished_spontaneous_json)\n",
    "            enhanced_content[\"spontaneous_moments\"] = polished_spontaneous\n",
    "            print(\"✅ Spontaneous moments polished successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error polishing spontaneous moments: {e}\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 2: Polish personality interactions\n",
    "        print(\"✨ Chunk 2: Polishing personality interactions...\")\n",
    "        try:\n",
    "            current_personality = enhanced_content.get(\"personality_interactions\", {})\n",
    "            polished_personality_json = self.polish_personality_interactions(\n",
    "                topic, classification_result, personas_result, current_personality\n",
    "            )\n",
    "            polished_personality = json.loads(polished_personality_json)\n",
    "            enhanced_content[\"personality_interactions\"] = polished_personality\n",
    "            print(\"✅ Personality interactions polished successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error polishing personality interactions: {e}\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 3: Create shared experiences\n",
    "        print(\"✨ Chunk 3: Creating shared experiences...\")\n",
    "        try:\n",
    "            shared_experiences_json = self.create_shared_experiences(\n",
    "                topic, classification_result, personas_result\n",
    "            )\n",
    "            shared_experiences = json.loads(shared_experiences_json)\n",
    "            enhanced_content[\"shared_experiences\"] = shared_experiences\n",
    "            print(\"✅ Shared experiences created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error creating shared experiences: {e}\")\n",
    "            enhanced_content[\"shared_experiences\"] = self._get_default_shared_experiences()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 4: Create contemporary relevance\n",
    "        print(\"✨ Chunk 4: Creating contemporary relevance...\")\n",
    "        try:\n",
    "            contemporary_relevance_json = self.create_contemporary_relevance(\n",
    "                topic, classification_result, personas_result\n",
    "            )\n",
    "            contemporary_relevance = json.loads(contemporary_relevance_json)\n",
    "            enhanced_content[\"contemporary_relevance\"] = contemporary_relevance\n",
    "            print(\"✅ Contemporary relevance created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error creating contemporary relevance: {e}\")\n",
    "            enhanced_content[\"contemporary_relevance\"] = self._get_default_contemporary_relevance()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 5: Enhance cultural context\n",
    "        print(\"✨ Chunk 5: Enhancing cultural context...\")\n",
    "        try:\n",
    "            current_cultural = enhanced_content.get(\"cultural_context\", {})\n",
    "            enhanced_cultural_json = self.enhance_cultural_context(\n",
    "                topic, classification_result, current_cultural\n",
    "            )\n",
    "            enhanced_cultural = json.loads(enhanced_cultural_json)\n",
    "            enhanced_content[\"cultural_context\"] = enhanced_cultural\n",
    "            print(\"✅ Cultural context enhanced successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error enhancing cultural context: {e}\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 6: Create advanced dialogue flow\n",
    "        print(\"✨ Chunk 6: Creating advanced dialogue flow...\")\n",
    "        try:\n",
    "            advanced_flow_json = self.create_advanced_dialogue_flow(\n",
    "                topic, classification_result, personas_result\n",
    "            )\n",
    "            advanced_flow = json.loads(advanced_flow_json)\n",
    "            enhanced_content[\"advanced_dialogue_flow\"] = advanced_flow\n",
    "            print(\"✅ Advanced dialogue flow created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error creating advanced dialogue flow: {e}\")\n",
    "            enhanced_content[\"advanced_dialogue_flow\"] = self._get_default_dialogue_flow()\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"🎉 Enhanced final polishing completed!\")\n",
    "        \n",
    "        return json.dumps(enhanced_content, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def _clean_json_response(self, response):\n",
    "        \"\"\"Enhanced JSON cleaning method\"\"\"\n",
    "        response = response.strip()\n",
    "        \n",
    "        # Remove any text before first { and after last }\n",
    "        start_idx = response.find('{')\n",
    "        end_idx = response.rfind('}')\n",
    "        \n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            clean_json = response[start_idx:end_idx+1]\n",
    "        else:\n",
    "            clean_json = response\n",
    "        \n",
    "        # Replace Arabic punctuation with English equivalents\n",
    "        clean_json = clean_json.replace('،', ',')\n",
    "        clean_json = clean_json.replace('\"', '\"')\n",
    "        clean_json = clean_json.replace('\"', '\"')\n",
    "        clean_json = clean_json.replace(''', \"'\")\n",
    "        clean_json = clean_json.replace(''', \"'\")\n",
    "        \n",
    "        # Fix common JSON issues\n",
    "        import re\n",
    "        clean_json = re.sub(r',(\\s*[}\\]])', r'\\1', clean_json)\n",
    "        \n",
    "        return clean_json\n",
    "\n",
    "    def _get_default_shared_experiences(self):\n",
    "        \"\"\"Default shared experiences\"\"\"\n",
    "        return {\n",
    "            \"common_ground\": [\n",
    "                \"اهتمام مشترك بتطوير المجتمع العربي\",\n",
    "                \"فهم عميق لأهمية الحفاظ على الهوية الثقافية\",\n",
    "                \"خبرة في التعامل مع التحديات المعاصرة\"\n",
    "            ],\n",
    "            \"generational_perspectives\": [\n",
    "                \"اختلاف في تجربة التكنولوجيا بين الأجيال\",\n",
    "                \"وجهات نظر متنوعة حول التغيير الاجتماعي\"\n",
    "            ],\n",
    "            \"professional_overlaps\": [\n",
    "                \"اهتمام مشترك بالتعليم والتطوير\",\n",
    "                \"فهم لأهمية التواصل الفعال\"\n",
    "            ],\n",
    "            \"cultural_touchstones\": [\n",
    "                \"تقدير للتراث العربي الأصيل\",\n",
    "                \"اهتمام بمستقبل الثقافة العربية\",\n",
    "                \"فهم لقيم الضيافة والكرم العربي\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _get_default_contemporary_relevance(self):\n",
    "        \"\"\"Default contemporary relevance\"\"\"\n",
    "        return {\n",
    "            \"current_events\": [\n",
    "                \"التطورات التقنية الحديثة في العالم العربي\",\n",
    "                \"المبادرات الثقافية الجديدة في المنطقة\"\n",
    "            ],\n",
    "            \"future_implications\": [\n",
    "                \"أهمية الاستثمار في الشباب العربي\",\n",
    "                \"ضرورة مواكبة التطورات العالمية\"\n",
    "            ],\n",
    "            \"regional_perspectives\": [\n",
    "                \"تنوع الآراء بين البلدان العربية\",\n",
    "                \"الحلول المحلية للتحديات العامة\"\n",
    "            ],\n",
    "            \"global_connections\": [\n",
    "                \"موقع العالم العربي في الساحة الدولية\",\n",
    "                \"التفاعل مع الثقافات العالمية\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _get_default_dialogue_flow(self):\n",
    "        \"\"\"Default advanced dialogue flow\"\"\"\n",
    "        return {\n",
    "            \"conversation_rhythms\": [\n",
    "                \"التنويع بين الأسئلة العميقة والخفيفة\",\n",
    "                \"إعطاء مساحة للتفكير والتأمل\"\n",
    "            ],\n",
    "            \"bridge_phrases\": [\n",
    "                \"هذا يقودنا إلى نقطة مهمة\",\n",
    "                \"بناءً على ما ذكرت\"\n",
    "            ],\n",
    "            \"emphasis_techniques\": [\n",
    "                \"التكرار الذكي للنقاط المهمة\",\n",
    "                \"استخدام القصص للتوضيح\"\n",
    "            ],\n",
    "            \"recovery_strategies\": [\n",
    "                \"العودة بلطف إلى الموضوع الأساسي\",\n",
    "                \"تحويل الخلاف إلى نقاش بناء\"\n",
    "            ],\n",
    "            \"engagement_boosters\": [\n",
    "                \"طرح أسئلة تفاعلية\",\n",
    "                \"ربط الموضوع بتجارب المستمعين\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def validate_final_outline(self, final_json):\n",
    "        \"\"\"Enhanced validation for the polished outline\"\"\"\n",
    "        try:\n",
    "            final_outline = json.loads(final_json)\n",
    "            missing_elements = []\n",
    "            \n",
    "            # Check new sections\n",
    "            required_new_sections = [\n",
    "                \"shared_experiences\", \"contemporary_relevance\", \"advanced_dialogue_flow\"\n",
    "            ]\n",
    "            for section in required_new_sections:\n",
    "                if section not in final_outline:\n",
    "                    missing_elements.append(section)\n",
    "            \n",
    "            # Check enhanced sections have more content\n",
    "            spont_moments = final_outline.get(\"spontaneous_moments\", {})\n",
    "            required_spont_fields = [\"natural_interruptions\", \"emotional_reactions\", \"personal_stories\", \"humorous_moments\"]\n",
    "            for field in required_spont_fields:\n",
    "                if field not in spont_moments:\n",
    "                    missing_elements.append(f\"spontaneous_moments.{field}\")\n",
    "                elif len(spont_moments.get(field, [])) < 3:\n",
    "                    missing_elements.append(f\"spontaneous_moments.{field} (needs at least 3 items)\")\n",
    "            \n",
    "            if missing_elements:\n",
    "                return False, f\"Missing enhanced elements: {missing_elements}\"\n",
    "            \n",
    "            return True, \"Enhanced final outline validation successful - ready for premium script generation\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "# Usage:\n",
    "# polisher = EnhancedFinalPolishEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "# final_outline = polisher.add_final_polish(topic, information, classification_result, personas_result, enhanced_content_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967209c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Starting enhanced final polishing...\n",
      "==================================================\n",
      "✨ Chunk 1: Polishing spontaneous moments...\n",
      "⚠️ Error polishing spontaneous moments: Expecting ',' delimiter: line 3 column 115 (char 145)\n",
      "✨ Chunk 2: Polishing personality interactions...\n",
      "⚠️ Error polishing personality interactions: Invalid control character at: line 2 column 376 (char 377)\n",
      "✨ Chunk 3: Creating shared experiences...\n",
      "✅ Shared experiences created successfully\n",
      "✨ Chunk 4: Creating contemporary relevance...\n",
      "✅ Contemporary relevance created successfully\n",
      "✨ Chunk 5: Enhancing cultural context...\n",
      "⚠️ Error enhancing cultural context: Expecting value: line 19 column 5 (char 1091)\n",
      "✨ Chunk 6: Creating advanced dialogue flow...\n",
      "✅ Advanced dialogue flow created successfully\n",
      "==================================================\n",
      "🎉 Enhanced final polishing completed!\n"
     ]
    }
   ],
   "source": [
    "polisher = EnhancedFinalPolishEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "final_outline = polisher.add_final_polish(topic, information, classification_result, persona_result, enhanced_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79cd062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"لمى عبد الله\",\n",
      "      \"background\": \"صحفية متخصصة في الشأن التكنولوجي في إحدى الجرائد المحلية\",\n",
      "      \"speaking_style\": \"تطرح أسئلة مفتوحة لتعميق النقاش وتعزز الحديث بموضوعية واضحة\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"علي محسن\",\n",
      "      \"background\": \"باحث في علوم الكمبيوتر وأستاذ مساعد في جامعة حكومية\",\n",
      "      \"speaking_style\": \"يعرض أفكارًا فنية بأسلوب سلس ويتفاعل مع المواضيع بتحليل عميق\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحبا أصدقائي,\",\n",
      "      \"podcast_introduction\": \"انضموا الآن إلى حلقتنا حول الذكاء الصناعي وتراثنا العربي الغني.\",\n",
      "      \"episode_hook\": \"كيف نوازن بين الابتكار والتقاليد?\",\n",
      "      \"tone_guidance\": \"تحليلي ومتفتح للأفكار\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"إن هذا موضوع يهم كل واحد منا بلا شك\",\n",
      "        \"لنبدأ بتبادل الأفكار حول هذه المسألة المثيرة\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"من الواضح أن الكثير من أدوات الذكاء الاصطناعي تشكلت بناءً على بيانات غربية.\",\n",
      "      \"guest_welcome\": \"مرحبًا دكتور علي, شكرًا لك على تواجدك معنا.\",\n",
      "      \"guest_bio_highlight\": \"عبر عن رأيك بخصوص كيفية تأثير ذلك على هويّتنا كعرب.\",\n",
      "      \"transition_to_discussion\": \"فلنرسم خطوطًا واضحة لهذا الأمر إذًا\",\n",
      "      \"cultural_connections\": [\n",
      "        \"يحمل هذا النقاش أهميته لأن الإسلام دين العلم والتفكير الناقد\",\n",
      "        \"والتقاليد الثقافية العربية مليئة بالأمثلة التي تدعم الإبداع\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"مشكلة تدريب النماذج على محتوى غير عربي\",\n",
      "        \"personal_angle\": \"كمراسل تكنولوجيا, أرى إمكانية للتأثيرات الغريبة على اللغة والثقافة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"هذا يثير تساؤلاً مهماً\",\n",
      "          \"دعني أشارككم تجربة في هذا المجال\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"قد تختلف وجهات النظر حول أفضل طريقة للتعامل مع هذه القضية\",\n",
      "        \"cultural_references\": [\n",
      "          \"كما يقول المثل: العلم نور\",\n",
      "          \"تراثنا يعلمنا أهمية التوازن في كل شيء\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"هذا يقودنا إلى نقطة مهمة أخرى\",\n",
      "        \"emotional_triggers\": \"هذا الموضوع يلامس قلوب كل من يهتم بمستقبل ثقافتنا\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"خطوات نحو تطوير نماذج عربية\",\n",
      "        \"personal_angle\": \"الباحث علي, هل لنا تحديث بشأن مشاريع الوطن الخليجية?\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ما إذا كانت هذه النماذج تعزز التراث الثقافي\",\n",
      "          \"أمثلة لنجاحات الإمارات في هذا المجال\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"قد يجادل البعض بأن التركيز الشديد قد يبسط التفرد الثقافي العربي بدلاً من تعزيزه.\",\n",
      "        \"cultural_references\": [\n",
      "          \"ذكر قصة حارس الوعل في هذا السياق\",\n",
      "          \"استشهاد بشاعر عربي معروف يدافع عن اللغة والتقاليد\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"من الجدير بالاعتبار أيضًا...\",\n",
      "        \"emotional_triggers\": \"يمكن أن تثير هذه المناقشة الشعور بالمهمة الفريدة للحفاظ على هويتنا.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"استخدام الذكاء الاصطناعي لتعزيز التعريف بالحضارة الإسلامية\",\n",
      "        \"personal_angle\": \"كيف يؤثر ذلك على تعريف الأجيال الناشئة بهويتنا الفريدة?\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"عند مناقشة نماذج اللغة التي قد تقوض المصطلحات الدينية,\",\n",
      "          \"بالحديث عن إمكانات الذكاء الاصطناعي في إبراز التراث العلمي الإسلامي.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"قد يجادل البعض أن الاعتماد المفرط على أجهزة الذكاء الاصطناعي يمكن أن يخفف قدرة الشباب على التفاعل مباشرة مع مصادر الهوية الثقافية.\",\n",
      "        \"cultural_references\": [\n",
      "          \"يمكن ذكر مثال أدباء العرب القدامى كالجاحظ أو ابن خلدون لتأكيد أهمية التفكير النقدي الأصيل.\",\n",
      "          \"ربما الاستشهاد بنجاح استخدام AI حالياً لإحياء نسخ رقمية لتاريخ المساجد الكبرى مثل جامع القرويين بالمغرب.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"هذا يقودنا إلى السؤال التالي حول كيفية تحقيق توازن بين الابتكار والتأكد من عدم فقدان جوهر هويتنا.\",\n",
      "        \"emotional_triggers\": \"من الطبيعي الشعور بالقلق حيال الحفاظ على هويّتنا الأصيلة بينما نتجه نحو مستقبل رقمي سريع.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الخلاصة: يجب توجيه الابتكار لتعزيز هويتنا, وليس استبدالها.\",\n",
      "        \"guest_final_message\": \"النصائح النهائية لعلي: دعم المبادرات التعليمية والتواصل المستمر.\",\n",
      "        \"host_closing_thoughts\": \"إن مواصلة المناقشة ستنعكس بلا شك على مستقبلنا الرقمي الآمن.\",\n",
      "        \"emotional_closure\": \"إن الاعتراف بترابط تكنولوجيا اليوم وهويتنا يمكن أن يلهم التقدير المشترك بين الأجيال وأن يبني روابط قوية مع جذورنا.\",\n",
      "        \"key_insights\": [\n",
      "          \"أولاً, تسليح الشباب بالمعرفة التقنية وربط هذه المعرفة بقيمهم الثقافية أمر حاسم.\",\n",
      "          \"ثانياً, تشجيع تطوير محتوى عربي أصيل ومناسب للذكاء الاصطناعي سيساهم في حماية الهوية.\",\n",
      "          \"أخيراً, خلق بيئة تفاعلية وداعمة للمبتكرين العرب سيضمن الاستدامة والبقاء الفريد لثقافتنا في عصر الديجيتال.\"\n",
      "        ]\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكرا لكل تعاون البروفيسور علي محسن.\",\n",
      "        \"audience_thanks\": \"شكراً لكم للاستماع والاستفادة من خبرة الضيف معنا.\",\n",
      "        \"call_to_action\": \"انضموا لنا في الرحلة نحو فهم أفضل لكيفية اندماج الذكاء الاصطناعي والثقافة العربية.\",\n",
      "        \"memorable_ending\": \"تذكر دائماً, قدرة تقنيات الغد ترجع إلى فهم وتعاون المجتمع العربي اليوم.\",\n",
      "        \"connection_building\": \"ابقوا على اطلاع بأحدث النقاشات والمقالات ذات الصلة عبر صفحتنا على الفيسبوك أو تويتر تحت #ArabicAIIdentityPodcast\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"الأصل دائمٌ, مهما تبدلت الظروف.\",\n",
      "      \"الحديث السليم يفيد السامعين\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"تاريخ الكويت كنموذج لمواكبة التقدم والحفاظ على الأصالة.\",\n",
      "      \"دور مصر التاريخي في نشر العلم\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"ملائمة للمناقشة التحليلية\",\n",
      "    \"dialect_touches\": \"إضافة عناصر بسيطة من لهجة بلدان مجلس التعاون الخليجي للإلفة\",\n",
      "    \"vocabulary_richness\": \"مصطلحات متنوعة تتوافق مع الموضوع\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"سرعة مناسبة لقضاء 10 دقائق\",\n",
      "    \"pause_points\": \"[... عند الانتقال بين النقاط الرئيسية...]\",\n",
      "    \"emphasis_moments\": \"[...على مفاهيم تحديد الأولويات ...] \"\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"spontaneous_moments\": [\n",
      "      {\n",
      "        \"title\": \"الذكاء الاصطناعي والهوية العربية\",\n",
      "        \"natural_interruption\": \"تخيلوا هذا.. كنت أناقش مع صديقي عن الذكاء الاصطناعي! 🎯*\",\n",
      "        \"emotional_reaction\": \"أشعر بالفضول حول تأثير التكنولوجيا الحديثة على تراثنا الثقافي.\",\n",
      "        \"personal_story\": \"عندما زرت متحفًا تقليديًّا, لاحظت كم كان الأطفال أكثر انجذابًا للألعاب الافتراضية بدلاً من القطع الأثرية الحقيقية. 🤔\",\n",
      "        \"humorous_moment\": \"لقد تساءلت ذات مرة إذا كانت الروبوتات قد تكتسب حس الفكاهة العربي يومًا ما! 😅\"\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"الحفاظ على الهوية العربية\",\n",
      "        \"natural_interruption\": \"Wait, have you seen those AI-generated poetry pieces? They're quite impressive but...!\",\n",
      "        \"emotional_reaction\": \"I feel it's crucial that we guide this technological advancement while preserving our cultural values.\",\n",
      "        \"personal_story\": \"My grandmother once told me stories at night by candlelight; now, I wonder how future generations will connect with their heritage through digital means.\",\n",
      "        \"humorous_moment\": \"Imagine an Arabic AI robot trying to make a joke using ancient proverbs – hilarious chaos guaranteed! 😂\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"interaction\": {\n",
      "      \"host\": \"لمى عبد الله\",\n",
      "      \"guest\": \"علي محسن\",\n",
      "      \"details\": {\n",
      "        \"host_strengths\": [\n",
      "          \"Exceptional listening skills.\",\n",
      "          \"Enthusiastic facilitation of engaging discussions.\"\n",
      "        ],\n",
      "        \"guest_expertise\": [\n",
      "          \"Deep knowledge in cultural anthropology.\",\n",
      "          \"Insightful storytelling abilities\"\n",
      "        ],\n",
      "        \"natural_chemistry\": \"Their shared passion for understanding diverse cultures quickly established a comfortable rapport.\",\n",
      "        \"tension_points\": [\n",
      "          \"Occasional differences in pacing during the conversation were noted but effectively managed by both parties.\"\n",
      "        ],\n",
      "        \"collaboration_moments\": [\n",
      "          \"A particularly compelling discussion about cross-cultural communication showed their collaborative strengths.\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"dialogue_techniques\": {\n",
      "    \"dialogue_techniques\": {\n",
      "      \"questioning_styles\": [\n",
      "        \"How can we leverage AI to preserve and share our cultural heritage?\",\n",
      "        \"In what ways does digital technology enhance or challenge traditional Arabic identity?\",\n",
      "        \"What are some innovative approaches Arab creators have taken to integrate AI into their artistic expressions?\"\n",
      "      ],\n",
      "      \"storytelling_moments\": [\n",
      "        \"Share personal stories of how family traditions were passed down through generations before the digital age.\",\n",
      "        \"Discuss an example of a successful Arab startup that uses AI to promote Islamic values while embracing modern technology.\",\n",
      "        \"Tell a story about how language preservation efforts are being aided by AI tools.\"\n",
      "      ],\n",
      "      \"audience_engagement\": [\n",
      "        \"Ask listeners to share their own experiences with balancing technological advancements and maintaining cultural identity.\",\n",
      "        \"Suggest interactive activities where audience members could create their own content using AI but with a focus on promoting Arabic culture.\",\n",
      "        \"Invite experts from various fields like linguistics, computer science, and anthropology to engage in live discussions on these topics.\"\n",
      "      ],\n",
      "      \"emotional_peaks\": [\n",
      "        \"Highlight moments when technology has brought people together across distances to celebrate shared cultural events.\",\n",
      "        \"Discuss challenges faced by those who feel disconnected from their roots due to increased reliance on digital platforms.\",\n",
      "        \"Celebrate successes of individuals and communities who have successfully integrated AI without compromising their cultural identity.\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"shared_experiences\": {\n",
      "    \"common_ground\": [\n",
      "      \"لمى وعلي كلاهما مهتمون بتأثير تقنيات الذك lái على الهوية العربية, مما يجعلهم يشتركان في الاهتمام بالحلول الملائمة للثقافة والقيم الإسلامية.\",\n",
      "      \"لديهما خبرة مشتركة في ملاحظة التحولات التي جلبتها وسائل التواصل الاجتماعي والتطبيقات الرقمية الأخرى إلى المجتمعات العربية التقليدية.\",\n",
      "      \"تشترك لمى وعلي في فهم تحدي الحفاظ على الأصول الثقافية والحكمة الشعبية أمام تيار المستجدات التكنولوجية.\"\n",
      "    ],\n",
      "    \"generational_perspectives\": [\n",
      "      \"تقدم لمى, كونها من جيل يُعتبر أكثر تعرُّضًا لتغيرات العصر الرقمي الأولية, منظور شخص عاش هذا الانتقال بشكل مباشر.\",\n",
      "      \"بالنسبة لعلي, الذي نشأ مع انتشار واسع للتكنولوجيا, فإن وجهة نظره توضح كيفية اندماج التطور التكنولوجي في حياة الشباب العربي اليوم.\",\n",
      "      \"من خلال خلفياتهم الدراسية المتنوعة — الصحافة مقابل علوم الكمبيوتر — لديهم وجهات نظر مختلفة ولكن مكملة حول تأثير التكنولوجيا.\"\n",
      "    ],\n",
      "    \"professional_overlaps\": [\n",
      "      \"يعمل كل من لمى وعلي بلا انقطاع لاستكشاف أثر الذك lái على حياتنا العربية؛ حيث تستكشف لمى هذه المسائل عبر الإعلام بينما يتعامل علي مع الجانب الأكاديمي لهذه المواضيع.\",\n",
      "      \"تجتمع تجاربهم الاحترافية عند نقطة البحث عن توازن بين استخدام التكنولوجيا وتجنب تأثيراتها السلبية المحتملة.\"\n",
      "    ],\n",
      "    \"cultural_touchstones\": [\n",
      "      \"يحظيان بفخر مشترك بهويتهما العربية الأصيلة ويعرفان أهمية التعامل بحذر مع تطورات تكنولوجية يمكن أن تشكل الفكرة العربية للعالم.\",\n",
      "      \"يتشاركان القلق بشأن احتمالية فقدان عناصر هامة من تراثهما الشعبي أثناء انتقال العالم نحو عصر جديد يُهيمن عليه الإنترنت والعالم الرقمي.\",\n",
      "      \"لديهم تقدير لماضي العرب الغني واستعداد لإيجاد طرق لدمجه بسلاسة ضمن مستقبل رقمي آخذ في التشكل.\"\n",
      "    ]\n",
      "  },\n",
      "  \"contemporary_relevance\": {\n",
      "    \"current_events\": [\n",
      "      \"مع ازدياد استخدام تقنيات مثل روبوتات الدردشة المدعومة بالذكاء الاصطناعي لتقديم المعلومات بالعربية, يبرز السؤال حول مدى دقة ونزاهة المحتوى المُنتَج وتأثير ذلك على الحفاظ على الهوية الثقافية العربية.\",\n",
      "      \"التحدي الأخير الذي تواجهه الدول العربية لتنظيم تطوير واستخدام الذكاء الاصطناعي بما يتماشى مع قيمها وثقافتها.\",\n",
      "      \"الاستثمار الحكومي المتزايد في مجال البحث والتطوير للذكاء الاصطناعي في المنطقة العربية كفرصة لتحقيق التوازن بين الابتكار والحفاظ على الهوية.\"\n",
      "    ],\n",
      "    \"future_implications\": [\n",
      "      \"توقع زيادة أهمية إنشاء وخلق محتوى ذكاء اصطناعي عربي أصيل يعكس قيم المجتمع والثقافة العربية.\",\n",
      "      \"إمكانية أن يلعب الذكاء الاصطناعي دوراً في تعزيز المشاركة الفعالة للأجيال الشابة في فهم ودعم تراثهم العربي الإسلامي.\",\n",
      "      \"نمو صناعة التعليم المستند إلى الذكاء الاصطناعي التي تركز على إعداد المواطنين عرباً قادرين على التعايش الهادف مع التقنية الجديدة دون التفريط بثقافتهم وهويتهم.\"\n",
      "    ],\n",
      "    \"regional_perspectives\": [\n",
      "      \"بينما تشهد بعض البلدان العربية توجهات نحو التحول الرقمي سريع الخطى, ما يؤكد الحاجة الملحة للحفاظ على الثقافة المحلية عبر الوسائل الإلكترونية.\",\n",
      "      \"في منطقة الشرق الأوسط, نشأت منظمات وشراكات متنوعة تجمع بين خبراء الذكاء الاصطناعي والمبدعين العرب لضمان تمثيل مبادئ ومعتقدات البلاد بشكل صحيح ضمن مساعي الترميز وتعليم الآلات.\"\n",
      "    ],\n",
      "    \"global_connections\": [\n",
      "      \"سعت العديد من الجامعات العالمية رائدة في مجالات الذكاء الاصطناعي للإعلان عن برامج بحث مشتركة مع نظرائها في العالم العربي سعياً لفهم أفضل للقيمة الثقافية المكانية عند ابتكار حلول تكنولوجية جديدة.\",\n",
      "      \"بالإضافة إلى ذلك, تعمل المنظّمات غير الربحية والأوساط الأكاديمية الدولية على وضع قواعد أخلاقية وتوجيه سياسات مستقبلية لاستخدام الذكاء الاصطناعي بطريقة تتوافق مع المعايير المتعددة الثقافات عالميا وتصون خصوصية واحترام مختلف أصحاب المصالح محليا.\"\n",
      "    ]\n",
      "  },\n",
      "  \"advanced_dialogue_flow\": {\n",
      "    \"conversation_rhythms\": [\n",
      "      \"لمى قد تبدأ أولاً بطرح سؤال مفتوح يتطلب من الضيف التفكير النقدي, ثم تتابع بسلسلة منطقية من الأسئلة المتابعة لتعزيز الفهم المشترك بين الحاضرين والمستمعين. هذا يساعد في خلق جو مريح للمناقشة.\",\n",
      "      \"تستخدم علي إلحاق القصص الشخصية أو الأمثلة العملية للتحقق من الأفكار المطروحة ومشاركة الخبرات التي تعزز الجدل. هنا يمكن أن تنتقل لمى بسلاسة إلى مقاطعة مدروسة للاستفسار عن تأثير تلك التجارب على الموضوع بشكل خاص.\",\n",
      "      \"لتجديد الطاقة أثناء المناقشات الأطول, يمكنهما تبادل الأدوار مؤقتًا حيث يصبح علي هو المحاور ويوجّه أسئلة للما واضعاً تركيز جديدعلى رؤيتها وأفكارها.\"\n",
      "    ],\n",
      "    \"bridge_phrases\": [\n",
      "      \"من هذا المنظور, دعونا ننتقل الآن لتقييم...\",\n",
      "      \"هذه نقطة مهمة, لكن كأن نتوقف لحظة لننظر فيما وراء ذلك أكثر قليلاً قبل الاسترسال...\",\n",
      "      \"في ضوء ما تحدث به علي حتى اللحظة الأخيرة, يبدو جليا أهمية... ولذلك فإن الكلمة التالية لي...\"\n",
      "    ],\n",
      "    \"emphasis_techniques\": [\n",
      "      \"يمكن استخدام التشويق للحفاظ على اهتمام الجمهور من خلال طرح سؤال مثير للاهتمام مباشرة بعد تقديم بيان رئيسي.\",\n",
      "      \"دعم الادعاءات بالأمثلة المباشرة والحكايات الواقعية يخلق تأثيراً عميقاً لدى المستمعين ويعزز فهم المعنى الجوهري.\",\n",
      "      \"إدخال حكمة أو قول عربي تقليدي مرتبط بالنقاش ينتهي بتأكيد قوي يؤكد نقاط حرجة ويتذكر المستمعين بما تم التوصل إليه.\"\n",
      "    ],\n",
      "    \"recovery_strategies\": [\n",
      "      \"إذا حدث ارتباك مؤقت بسبب وجود فكرة غير مترابطة, يمكن لأحد المضيفين تغيير الاتجاه بصبر والاستئناف مرة أخرى للأصل المغزى الأساسي للموضوع بإيجاز شديد.\",\n",
      "      \"بالنسبة للنقد المتعارض, يجب تقديره باحترام ودراسة وجهات النظر المختلفة بعناية واستخدام استنتاجاتها لإضافة العمق للفهم الشامل للقضايا محل البحث .\"\n",
      "    ],\n",
      "    \"engagement_boosters\": [\n",
      "      \"تشجيع الحضور عبر وسائل التواصل الاجتماعي للتعبيرعن آرائهم والتفاعل مع المحادثات مباشرةً \",\n",
      "      \"عرض مثال حي للإمكانيات التقنية المحتملة وتعريف جمهورك بحلول مبتكرة حافظتعلى الهويات الثقافية الأصلية ضمن بيئة رقميّة.\",\n",
      "      \"التذكير بأن كل فرد يستطيع المساهمة بطريقته الخاصة لحماية هويتهم وثقافتهم بمواجهة تحدّيات عصر رقمنة المعلومات والبيانات المتزايدة\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fa49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"سامي الجابري\",\n",
      "      \"background\": \"صحفي مهتم بالتكنولوجيا والثقافة العربية.\",\n",
      "      \"speaking_style\": \"يطرح أسئلة مباشرة ويسعى لتوضيح الأفكار بأسلوب بسيط.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. ليلى العمري\",\n",
      "      \"background\": \"أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات.\",\n",
      "      \"speaking_style\": \"تشرح الأفكار بأسلوب أكاديمي مبسط مدعوم بالأمثلة.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحباً بكم مستمعينا في بودكاست 'نبض الثقافة'، حيث نناقش القضايا التي تمس هويتنا وثقافتنا في عالم متغير.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع يشغل بال الكثيرين: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هل يمكن لهذه التقنية أن تصبح حليفاً للثقافة العربية أم أنها تهدد بتهميشها؟\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"سامي: هل فكرت يوماً في تأثير التكنولوجيا على لغتك اليومية؟\",\n",
      "        \"سامي: يا ترى، لو كان الذكاء الاصطناعي يتحدث باللهجة المحلية، كيف سيكون الحوار؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءاً من حياتنا اليومية، ولكن هل نحن مستعدون لمواجهة تأثيراته على هويتنا الثقافية؟\",\n",
      "      \"guest_welcome\": \"معنا اليوم د. ليلى العمري، أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات. أهلاً وسهلاً بكِ د. ليلى.\",\n",
      "      \"guest_bio_highlight\": \"د. ليلى لديها خبرة طويلة في دراسة تأثير التكنولوجيا على اللغة والثقافة، وهي صوت مهم في هذا المجال.\",\n",
      "      \"transition_to_discussion\": \"دعينا نبدأ بالنظر إلى الوضع الحالي: كيف ترين تأثير الذكاء الاصطناعي على اللغة والثقافة العربية حتى الآن؟\",\n",
      "      \"cultural_connections\": [\n",
      "        \"سامي: أذكر أن جدتي كانت دائماً تقول 'اللغة وعاء الفكر'، هل تعتقدين أننا نفقد شيئاً من هذا الوعاء في ظل الذكاء الاصطناعي؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"الفجوة الرقمية: هيمنة المحتوى الغربي\",\n",
      "        \"personal_angle\": \"سامي: أرقام المحتوى الرقمي مخيفة، 78% بالإنجليزية مقابل 3% فقط بالعربية. هل يمكننا سد هذه الفجوة؟ د. ليلى: هذه الفجوة تعكس تحديات كبيرة، ولكن هناك جهود بدأت تظهر مثل تطوير نماذج عربية كجايس والحوراء.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل تعتقدين أن الأجيال القادمة ستكون أكثر انفتاحاً على المحتوى العربي، أم أن الإنجليزية ستظل طاغية؟\",\n",
      "          \"سامي: لماذا برأيك المحتوى العربي يعاني من نقص كبير في المجال الرقمي مقارنة بلغات أخرى؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يجب أن نعتمد فقط على المبادرات الحكومية أم أن هناك دوراً أكبر للمجتمع المدني؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"القول الشائع: 'من عرف قدر نفسه لم يهلك'، يعبر عن أهمية إدراك قيمة لغتنا وثقافتنا في مواجهة المحتوى الغربي.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: هذا يقودني إلى سؤال مهم، هل النماذج الغربية للذكاء الاصطناعي قادرة على فهم الثقافة العربية حقاً؟\",\n",
      "        \"emotional_triggers\": \"الخوف من أن تصبح اللغة العربية مجرد لغة ثانوية في العالم الرقمي.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"نماذج الذكاء الاصطناعي والسياق الثقافي العربي\",\n",
      "        \"personal_angle\": \"سامي: معظم نماذج الذكاء الاصطناعي مدربة على بيانات غربية. هل هذا يعني أنها لا تفهمنا؟ د. ليلى: بالتأكيد، هذه النماذج قد تواجه صعوبة في فهم السياقات العربية، لكن تطوير نماذج محلية خطوة مهمة لتجاوز هذه العقبة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل يمكن أن تؤدي هذه النماذج إلى تحريف بعض المفاهيم الثقافية التقليدية؟\",\n",
      "          \"سامي: كيف يمكن أن تساعد اللغة العربية في إعادة صياغة هذه النماذج لتتناسب مع الهوية الثقافية؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يجب التركيز أكثر على تدريب النماذج الحالية أم بناء نماذج جديدة من الصفر؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"سامي: أذكر أنني قرأت عن مبادرة سعودية لتوثيق التراث الشعبي باستخدام الذكاء الاصطناعي، هل هذا نموذج يمكن أن نقتدي به؟\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: إذاً، يمكن للذكاء الاصطناعي أن يكون جزءاً من الحل وليس المشكلة، لكن كيف يمكننا ضمان ذلك عملياً؟\",\n",
      "        \"emotional_triggers\": \"الشعور بالفخر عندما يتم الحديث عن جهود عربية ريادية.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"الاستفادة من الذكاء الاصطناعي لتعزيز الثقافة\",\n",
      "        \"personal_angle\": \"سامي: هل يمكن للذكاء الاصطناعي أن يصبح أداة لتعزيز الثقافة العربية بدلاً من تهديدها؟ د. ليلى: نعم، إذا تم توجيهه بشكل صحيح، يمكن أن يساهم في نشر اللغة العربية وتوثيق التراث الثقافي بطرق مبتكرة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل يمكن أن نرى قصائد المتنبي تُقرأ بأصوات ذكاء اصطناعي قريباً؟\",\n",
      "          \"سامي: ماذا لو استخدمنا الذكاء الاصطناعي لتعليم الأطفال اللغة العربية بطريقة ممتعة؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكن للتكنولوجيا أن تكون بديلاً عن التدخلات البشرية في الحفاظ على الثقافة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"د. ليلى: هناك مثل يقول 'اللغة هي روح الأمة'، وهذا يعكس أهمية استخدام التكنولوجيا للحفاظ عليها.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: هذا يقودني للتفكير في المستقبل، كيف يمكننا إعداد الأجيال القادمة لهذه التحديات؟\",\n",
      "        \"emotional_triggers\": \"الإلهام بفكرة أن التكنولوجيا يمكن أن تبني جسوراً بين الماضي والمستقبل.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الذكاء الاصطناعي يمكن أن يكون تهديداً أو فرصة للثقافة العربية، حسب كيفية استخدامنا له.\",\n",
      "        \"guest_final_message\": \"أدعو الجميع لدعم المبادرات التي تهدف إلى تطوير محتوى عربي رقمي قوي، فهذا جزء من الحفاظ على هويتنا.\",\n",
      "        \"host_closing_thoughts\": \"التكنولوجيا ليست عدواً، بل أداة. علينا أن نتعلم كيف نستخدمها لصالحنا.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكراً جزيلاً د. ليلى على مشاركتك القيمة اليوم.\",\n",
      "        \"audience_thanks\": \"شكراً لكم مستمعينا على تخصيص وقتكم للاستماع إلينا.\",\n",
      "        \"call_to_action\": \"إذا أعجبكم الموضوع، شاركوا آرائكم معنا على منصات التواصل الاجتماعي، ولا تنسوا متابعة الحلقات القادمة.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة من 'نبض الثقافة'.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من عرف قدر نفسه لم يهلك.\",\n",
      "      \"اللغة وعاء الفكر.\",\n",
      "      \"الجذور العميقة لا تخشى الرياح.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"جهود الإمارات في تطوير نموذج 'جايس'.\",\n",
      "      \"مبادرات السعودية في الذكاء الاصطناعي مثل 'الحوراء'.\",\n",
      "      \"مشروع 'ثنائيات اللغة' في مصر لتعزيز المحتوى العربي.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي معتدل يناسب الأسلوب التحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام بعض الكلمات باللهجة العربية الفصحى مع لمسات محلية عند الحاجة.\",\n",
      "    \"vocabulary_richness\": \"مصطلحات تقنية وثقافية مع شرح بسيط.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"الإيقاع متوازن بين التعمق في النقاط وبين الانتقال للموضوع التالي.\",\n",
      "    \"pause_points\": \"توقف طبيعي بعد كل نقطة نقاشية للسماح بالتفكير.\",\n",
      "    \"emphasis_moments\": \"تأكيد على النقاط المتعلقة بتطوير نماذج عربية وتأثير الذكاء الاصطناعي على اللغة.\"\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"natural_interruptions\": [\n",
      "      \"سامي: د. ليلى، لحظة، هل تعنين أن اللغة العربية قد تصبح لغة نادرة في المستقبل؟\",\n",
      "      \"سامي: هذا يذكرني بشيء قرأته مؤخراً عن تأثير التكنولوجيا على اللهجات المحلية.\",\n",
      "      \"سامي: هل تعتقدين أن اللهجات المختلفة داخل العالم العربي يمكن أن تكون عائقاً أمام تطوير نماذج موحدة للذكاء الاصطناعي؟\"\n",
      "    ],\n",
      "    \"emotional_reactions\": [\n",
      "      \"سامي: هذا فعلاً شيء يدعو للتفكير العميق، كيف يمكن أن يحدث هذا؟\",\n",
      "      \"د. ليلى: أشعر بالفخر عندما أرى مبادرات عربية تنافس عالمياً.\",\n",
      "      \"سامي: بصراحة، هذا يجعلني أشعر بقلق حقيقي على مستقبل اللغة العربية.\"\n",
      "    ],\n",
      "    \"personal_stories\": [\n",
      "      \"سامي: أذكر أنني كنت أبحث عن قصص أطفال بالعربية لابنتي، ووجدت أن الخيارات الرقمية قليلة جداً.\",\n",
      "      \"د. ليلى: عندما بدأت البحث في هذا المجال، لاحظت كيف أن كثيراً من المفاهيم العربية تُترجم بشكل خاطئ.\",\n",
      "      \"د. ليلى: ذات مرة حضرت معرضاً تقنياً، وكان علي شرح معنى 'الكرم العربي' لأحد مطوري الذكاء الاصطناعي الأجانب.\"\n",
      "    ],\n",
      "    \"humorous_moments\": [\n",
      "      \"سامي: تخيل لو كان الذكاء الاصطناعي يحاول فهم الأمثال العربية، مثل 'ضربني وبكى سبقني واشتكى'، كيف سيفسرها؟\",\n",
      "      \"سامي: ما رأيك لو حاول الذكاء الاصطناعي كتابة أغنية شعبية باللهجة المصرية؟\"\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"host_strengths\": \"سامي الجابري بارع في طرح الأسئلة التي تحفز التفكير ويجعل النقاش ممتعاً ومفيداً.\",\n",
      "    \"guest_expertise\": \"د. ليلى العمري تمتلك خبرة عميقة في مجال الذكاء الاصطناعي واللغويات، مما يجعلها قادرة على تقديم رؤى علمية مدعومة بالأمثلة.\",\n",
      "    \"natural_chemistry\": \"التفاعل بين سامي وليلى يتسم بالتوازن بين الفضول الصحفي والتخصص الأكاديمي، كما أن سامي يضيف لمسة من الاستفسارات العاطفية التي تجعل ليلى تعمق النقاش بشكل أكثر إنسانية.\",\n",
      "    \"tension_points\": \"سامي قد يطرح أسئلة تستفز التفكير النقدي، مثل التركيز على الفجوة بين المبادرات الحكومية والمجتمعية، مما يدعو ليلى للدفاع عن وجهة نظرها حول أهمية التعاون بين الجانبين.\",\n",
      "    \"collaboration_moments\": \"يتفق سامي وليلى بشكل واضح عند الحديث عن أهمية تعزيز المحتوى العربي، حيث يضيف سامي مثالاً من حياته الشخصية بينما تقدم ليلى حلولاً عملية للتحديات.\"\n",
      "  },\n",
      "  \"shared_experiences\": {\n",
      "    \"common_ground\": [\n",
      "      \"كلاهما متفق على أهمية الحفاظ على اللغة العربية في المجال الرقمي.\",\n",
      "      \"كلاهما لديه تجارب مع نقص المحتوى العربي الرقمي.\"\n",
      "    ],\n",
      "    \"generational_perspectives\": [\n",
      "      \"سامي يمثل وجهة نظر جيل يرتبط بالهوية الثقافية التقليدية ويبحث عن حلول عصرية، بينما ليلى تمثل جيل الباحثين الذين يرون في التكنولوجيا فرصة للتطوير.\",\n",
      "      \"قد تظهر اختلافات في وجهات النظر حول سرعة التغيير وكيفية التعامل معه بين الجيلين.\"\n",
      "    ]\n",
      "  },\n",
      "  \"contemporary_relevance\": {\n",
      "    \"current_events\": [\n",
      "      \"إطلاق الإمارات لنموذج 'جايس' كأول نموذج ذكاء اصطناعي باللغة العربية.\",\n",
      "      \"مبادرات سعودية حديثة لتوثيق التراث باستخدام الذكاء الاصطناعي.\"\n",
      "    ],\n",
      "    \"future_implications\": [\n",
      "      \"الذكاء الاصطناعي قد يصبح أداة رئيسية في الحفاظ على التراث العربي وتعزيزه.\",\n",
      "      \"في السنوات القادمة، قد نشهد نماذج ذكاء اصطناعي تفهم اللهجات المحلية بشكل أفضل.\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use the enhanced polisher\n",
    "polisher = EnhancedFinalPolishEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "final_outline = polisher.add_final_polish(\n",
    "    topic, \n",
    "    information, \n",
    "    classification_result, \n",
    "    persona_result, \n",
    "    enhanced_result\n",
    ")\n",
    "\n",
    "print(\"Final polished outline:\")\n",
    "print(final_outline)\n",
    "\n",
    "# Validate the results\n",
    "is_valid, message = polisher.validate_final_outline(final_outline)\n",
    "print(f\"Validation: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae7f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "class EnhancedSectionalScriptGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "        \n",
    "        # Enhanced dialogue style examples - clean Arabic only\n",
    "        self.arabic_dialogue_styles = {\n",
    "            \"حواري\": {\n",
    "                \"host_tone\": \"ودود، فضولي، يطرح أسئلة مفتوحة ويتفاعل بحماس\",\n",
    "                \"guest_tone\": \"خبير، متعاون، يشارك معرفته بوضوح ويتفاعل طبيعياً\",\n",
    "                \"interaction_style\": \"حوار تفاعلي مع تداخل طبيعي وضحك وتعليقات عفوية\"\n",
    "            },\n",
    "            \"تعليمي\": {\n",
    "                \"host_tone\": \"منظم، موضح، يطرح أسئلة تعليمية ويلخص النقاط المهمة\",\n",
    "                \"guest_tone\": \"معلم صبور، يشرح بوضوح ويستخدم أمثلة بسيطة\",\n",
    "                \"interaction_style\": \"حوار منظم مع شرح وتوضيح وأسئلة تفصيلية\"\n",
    "            },\n",
    "            \"تحليلي\": {\n",
    "                \"host_tone\": \"عميق، محلل، يطرح أسئلة معقدة ويناقش التفاصيل\",\n",
    "                \"guest_tone\": \"خبير، يقدم تحليل عميق ويناقش الجوانب المختلفة\",\n",
    "                \"interaction_style\": \"نقاش عميق مع تحليل وتفصيل وربط بين الأفكار\"\n",
    "            },\n",
    "            \"ترفيهي\": {\n",
    "                \"host_tone\": \"مرح، خفيف، يضيف لمسات فكاهية ويحافظ على الأجواء الممتعة\",\n",
    "                \"guest_tone\": \"مسترخي، طريف، يشارك قصص ممتعة ويتفاعل بمرح\",\n",
    "                \"interaction_style\": \"حوار مرح مع ضحك وقصص طريفة وتعليقات خفيفة\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Natural Arabic fillers and transitions\n",
    "        self.arabic_fillers = {\n",
    "            \"thinking\": [\"اممم\", \"يعني\", \"شوف\", \"خلاص\", \"طبعاً\"],\n",
    "            \"agreement\": [\"بالضبط\", \"صحيح\", \"أكيد\", \"تماماً\", \"فعلاً\"],\n",
    "            \"hesitation\": [\"يعني كيف أقول\", \"اه ما أدري\", \"مش عارف كيف أوضح\"],\n",
    "            \"excitement\": [\"واو\", \"يا الله\", \"ما شاء الله\", \"الله يعطيك العافية\"],\n",
    "            \"connecting\": [\"بس\", \"لكن\", \"وبعدين\", \"يا أخي\", \"اسمع\"],\n",
    "            \"gulf_light\": [\"شلون\", \"وش رايك\", \"زين\", \"ماشي الحال\", \"الله يعافيك\"]\n",
    "        }\n",
    "\n",
    "    def generate_intro_dialogue(self, topic, final_outline_result, optimal_style):\n",
    "        \"\"\"\n",
    "        Chunk 1: Generate natural intro dialogue (intro1 + intro2)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract key elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        intro1 = conv_flow.get(\"intro1\", {})\n",
    "        intro2 = conv_flow.get(\"intro2\", {})\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        spontaneous_moments = outline.get(\"spontaneous_moments\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        host_bg = personas.get(\"host\", {}).get(\"background\", \"\")\n",
    "        guest_bg = personas.get(\"guest\", {}).get(\"background\", \"\")\n",
    "        \n",
    "        # Get style guidance\n",
    "        style_guide = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert Arabic dialogue writer for natural podcast conversations.\n",
    "\n",
    "Task: Write a natural, engaging introduction dialogue between host and guest.\n",
    "\n",
    "CONTEXT:\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Host: {host_name} - {host_bg}\n",
    "Guest: {guest_name} - {guest_bg}\n",
    "\n",
    "Style Guidance:\n",
    "- Host tone: {style_guide[\"host_tone\"]}\n",
    "- Guest tone: {style_guide[\"guest_tone\"]}\n",
    "- Interaction style: {style_guide[\"interaction_style\"]}\n",
    "\n",
    "OUTLINE ELEMENTS TO INCORPORATE:\n",
    "Intro1 Elements:\n",
    "- Opening: {intro1.get('opening_line', '')}\n",
    "- Podcast intro: {intro1.get('podcast_introduction', '')}\n",
    "- Hook: {intro1.get('episode_hook', '')}\n",
    "- Spontaneous elements: {intro1.get('spontaneity_elements', [])}\n",
    "\n",
    "Intro2 Elements:\n",
    "- Topic introduction: {intro2.get('topic_introduction', '')}\n",
    "- Guest welcome: {intro2.get('guest_welcome', '')}\n",
    "- Guest bio: {intro2.get('guest_bio_highlight', '')}\n",
    "- Cultural connections: {intro2.get('cultural_connections', [])}\n",
    "\n",
    "Available spontaneous elements: {spontaneous_moments.get('natural_interruptions', [])[:2]}\n",
    "Cultural references: {cultural_context.get('proverbs_sayings', [])[:2]}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Start with {host_name} speaking alone (welcome and topic intro)\n",
    "2. Naturally bring {guest_name} into the conversation\n",
    "3. Use 75% Modern Standard Arabic, 25% light Gulf dialect touches\n",
    "4. Include natural fillers like: اممم، يعني، طبعاً، شوف، بالضبط\n",
    "5. Add natural pauses and interactions\n",
    "6. Make conversation flow authentically\n",
    "7. Duration: 2-3 minutes of natural dialogue\n",
    "8. End with smooth transition to main discussion\n",
    "\n",
    "CRITICAL LANGUAGE REQUIREMENTS:\n",
    "- Write ONLY in Arabic (Modern Standard + light Gulf touches)\n",
    "- NO English words except technical terms if absolutely necessary\n",
    "- NO Chinese characters or symbols\n",
    "- NO emojis or special formatting\n",
    "- NO code-like text or technical annotations\n",
    "- Use natural Arabic conversation patterns\n",
    "\n",
    "FORMAT:\n",
    "{host_name}: [dialogue text]\n",
    "{guest_name}: [dialogue text]\n",
    "[pause indicators like: فترة صمت قصيرة، يضحك، يتردد]\n",
    "\n",
    "Write the complete introduction dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert Arabic dialogue writer. Write only in Arabic. No English, Chinese, or emojis. Focus on natural conversation flow in {optimal_style} style.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return self._clean_arabic_dialogue(response.choices[0].message.content)\n",
    "\n",
    "    def generate_discussion_segment(self, topic, final_outline_result, optimal_style, intro_dialogue, segment_points):\n",
    "        \"\"\"\n",
    "        Chunk 2: Generate discussion segment covering specific points\n",
    "        \n",
    "        Args:\n",
    "            segment_points: List of discussion points to cover in this segment\n",
    "        \"\"\"\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract key elements\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        spontaneous_moments = outline.get(\"spontaneous_moments\", {})\n",
    "        personality_interactions = outline.get(\"personality_interactions\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style guidance\n",
    "        style_guide = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        # Build points summary for this segment\n",
    "        points_text = \"\"\n",
    "        for i, point in enumerate(segment_points):\n",
    "            points_text += f\"\"\"\n",
    "النقطة {i+1}: {point.get('point_title', '')}\n",
    "- الزاوية الشخصية: {point.get('personal_angle', '')}\n",
    "- المحفزات التلقائية: {point.get('spontaneous_triggers', [])}\n",
    "- نقاط الخلاف المحتملة: {point.get('disagreement_points', '')}\n",
    "- المراجع الثقافية: {point.get('cultural_references', [])}\n",
    "- المحفزات العاطفية: {point.get('emotional_triggers', '')}\n",
    "\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert Arabic dialogue writer for natural podcast discussions.\n",
    "\n",
    "Task: Write natural discussion dialogue covering the specified points.\n",
    "\n",
    "CONTEXT:\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Host: {host_name} - Expert interviewer\n",
    "Guest: {guest_name} - Topic expert\n",
    "\n",
    "Style Guidance:\n",
    "- Host approach: {style_guide[\"host_tone\"]}\n",
    "- Guest approach: {style_guide[\"guest_tone\"]}\n",
    "- Interaction style: {style_guide[\"interaction_style\"]}\n",
    "\n",
    "PREVIOUS CONTEXT (end of intro):\n",
    "{intro_dialogue[-200:]}\n",
    "\n",
    "DISCUSSION POINTS TO COVER:\n",
    "{points_text}\n",
    "\n",
    "PERSONALITY DYNAMICS:\n",
    "- Natural chemistry: {personality_interactions.get('natural_chemistry', '')}\n",
    "- Potential tensions: {personality_interactions.get('tension_points', '')}\n",
    "- Collaboration style: {personality_interactions.get('collaboration_moments', '')}\n",
    "\n",
    "SPONTANEOUS ELEMENTS TO USE:\n",
    "- Natural interruptions: {spontaneous_moments.get('natural_interruptions', [])}\n",
    "- Emotional reactions: {spontaneous_moments.get('emotional_reactions', [])}\n",
    "- Personal stories: {spontaneous_moments.get('personal_stories', [])}\n",
    "- Light humor: {spontaneous_moments.get('humorous_moments', [])}\n",
    "\n",
    "CULTURAL ELEMENTS:\n",
    "- Proverbs/sayings: {cultural_context.get('proverbs_sayings', [])}\n",
    "- Regional references: {cultural_context.get('regional_references', [])}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Start with smooth transition from previous section\n",
    "2. Cover all discussion points naturally (don't follow rigid order)\n",
    "3. Include natural disagreements and agreements\n",
    "4. Use spontaneous elements authentically\n",
    "5. Integrate cultural references naturally\n",
    "6. Show character personalities through dialogue\n",
    "7. Include natural interruptions and overlaps\n",
    "8. Duration: 3-4 minutes of flowing discussion\n",
    "9. End ready for next segment or closing\n",
    "\n",
    "CRITICAL LANGUAGE REQUIREMENTS:\n",
    "- Write ONLY in Arabic (Modern Standard + light Gulf dialect)\n",
    "- NO English, Chinese, or other languages\n",
    "- NO emojis, symbols, or technical formatting\n",
    "- Use natural Arabic conversation patterns\n",
    "- Include authentic hesitations and fillers\n",
    "\n",
    "FORMAT:\n",
    "{host_name}: [dialogue text]\n",
    "{guest_name}: [dialogue text]\n",
    "[natural pause/reaction indicators in Arabic]\n",
    "\n",
    "Write the discussion segment:\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You write natural Arabic dialogue. Only Arabic language. No English/Chinese/emojis. Focus on authentic {optimal_style} conversation flow.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "\n",
    "        return self._clean_arabic_dialogue(response.choices[0].message.content)\n",
    "\n",
    "    def generate_closing_dialogue(self, topic, final_outline_result, optimal_style, previous_dialogue):\n",
    "        \"\"\"\n",
    "        Chunk 3: Generate natural closing dialogue\n",
    "        \"\"\"\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract key elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        closing = conv_flow.get(\"closing\", {})\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style guidance\n",
    "        style_guide = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert Arabic dialogue writer for natural podcast closings.\n",
    "\n",
    "Task: Write a natural, impactful closing dialogue.\n",
    "\n",
    "CONTEXT:\n",
    "Topic: {topic}\n",
    "Style: {optimal_style}\n",
    "Host: {host_name}\n",
    "Guest: {guest_name}\n",
    "\n",
    "Style Guidance:\n",
    "- Host approach: {style_guide[\"host_tone\"]}\n",
    "- Guest approach: {style_guide[\"guest_tone\"]}\n",
    "- Closing style: {style_guide[\"interaction_style\"]}\n",
    "\n",
    "PREVIOUS CONTEXT (end of discussion):\n",
    "{previous_dialogue[-300:]}\n",
    "\n",
    "CLOSING ELEMENTS FROM OUTLINE:\n",
    "Conclusion:\n",
    "- Main takeaways: {closing.get('conclusion', {}).get('main_takeaways', '')}\n",
    "- Guest final message: {closing.get('conclusion', {}).get('guest_final_message', '')}\n",
    "- Host closing thoughts: {closing.get('conclusion', {}).get('host_closing_thoughts', '')}\n",
    "\n",
    "Outro:\n",
    "- Guest appreciation: {closing.get('outro', {}).get('guest_appreciation', '')}\n",
    "- Audience thanks: {closing.get('outro', {}).get('audience_thanks', '')}\n",
    "- Call to action: {closing.get('outro', {}).get('call_to_action', '')}\n",
    "- Final goodbye: {closing.get('outro', {}).get('final_goodbye', '')}\n",
    "\n",
    "CULTURAL ELEMENTS:\n",
    "- Proverbs for closing: {cultural_context.get('proverbs_sayings', [])}\n",
    "- Cultural wisdom: {cultural_context.get('regional_references', [])}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Start with natural transition from discussion\n",
    "2. Summarize key insights naturally (not mechanically)\n",
    "3. Let {guest_name} share meaningful final thoughts\n",
    "4. {host_name} adds personal closing reflections\n",
    "5. Express genuine appreciation for guest and audience\n",
    "6. Include natural call for engagement\n",
    "7. Use cultural element for memorable ending\n",
    "8. Leave positive, inspiring final impression\n",
    "9. Duration: 1-2 minutes of impactful closing\n",
    "\n",
    "CRITICAL LANGUAGE REQUIREMENTS:\n",
    "- Write ONLY in Arabic (Modern Standard + light Gulf dialect)\n",
    "- NO English, Chinese, or other languages\n",
    "- NO emojis or special formatting\n",
    "- Use warm, authentic Arabic expressions\n",
    "- Natural closing conversation patterns\n",
    "\n",
    "FORMAT:\n",
    "{host_name}: [dialogue text]\n",
    "{guest_name}: [dialogue text]\n",
    "[natural indicators in Arabic like: يبتسم، يشكر، فترة تأمل]\n",
    "\n",
    "Write the complete closing dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You write natural Arabic closing dialogue. Only Arabic language. No English/Chinese/emojis. Create warm, impactful {optimal_style} ending.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6\n",
    "        )\n",
    "\n",
    "        return self._clean_arabic_dialogue(response.choices[0].message.content)\n",
    "\n",
    "    def generate_complete_script(self, topic, final_outline_result):\n",
    "        \"\"\"\n",
    "        Main orchestration method: Generate complete script using sectional approach\n",
    "        \"\"\"\n",
    "        print(\"🎙️ بدء توليد السكريبت المطور بالطريقة التقسيمية...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Determine optimal style\n",
    "        optimal_style = self._determine_optimal_style(outline)\n",
    "        \n",
    "        print(f\"📋 الأسلوب المحدد: {optimal_style}\")\n",
    "        \n",
    "        # Chunk 1: Generate intro dialogue\n",
    "        print(\"📝 الجزء الأول: توليد حوار المقدمة...\")\n",
    "        try:\n",
    "            intro_dialogue = self.generate_intro_dialogue(topic, final_outline_result, optimal_style)\n",
    "            print(\"✅ تم إنجاز حوار المقدمة بنجاح\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطأ في توليد المقدمة: {e}\")\n",
    "            intro_dialogue = self._get_fallback_intro(topic, outline, optimal_style)\n",
    "            print(\"📝 تم استخدام مقدمة احتياطية\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 2: Generate discussion segments\n",
    "        print(\"📝 الجزء الثاني: توليد حوار النقاش الرئيسي...\")\n",
    "        discussion_dialogue = \"\"\n",
    "        \n",
    "        # Split discussion points into manageable segments\n",
    "        main_discussion = outline.get(\"conversation_flow\", {}).get(\"main_discussion\", [])\n",
    "        segments = self._split_discussion_points(main_discussion)\n",
    "        \n",
    "        for i, segment_points in enumerate(segments):\n",
    "            print(f\"  توليد مقطع النقاش {i+1}/{len(segments)}...\")\n",
    "            try:\n",
    "                segment_dialogue = self.generate_discussion_segment(\n",
    "                    topic, final_outline_result, optimal_style, \n",
    "                    intro_dialogue if i == 0 else discussion_dialogue, \n",
    "                    segment_points\n",
    "                )\n",
    "                discussion_dialogue += segment_dialogue + \"\\n\\n\"\n",
    "                print(f\"  ✅ تم إنجاز مقطع النقاش {i+1}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️ خطأ في مقطع {i+1}: {e}\")\n",
    "                fallback_segment = self._get_fallback_discussion_segment(segment_points, optimal_style)\n",
    "                discussion_dialogue += fallback_segment + \"\\n\\n\"\n",
    "                print(f\"  📝 تم استخدام مقطع احتياطي {i+1}\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(\"✅ تم إنجاز حوار النقاش الرئيسي\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Chunk 3: Generate closing dialogue\n",
    "        print(\"📝 الجزء الثالث: توليد حوار الختام...\")\n",
    "        try:\n",
    "            closing_dialogue = self.generate_closing_dialogue(\n",
    "                topic, final_outline_result, optimal_style, discussion_dialogue\n",
    "            )\n",
    "            print(\"✅ تم إنجاز حوار الختام بنجاح\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطأ في توليد الختام: {e}\")\n",
    "            closing_dialogue = self._get_fallback_closing(topic, outline, optimal_style)\n",
    "            print(\"📝 تم استخدام ختام احتياطي\")\n",
    "        \n",
    "        # Combine all parts\n",
    "        complete_script = f\"\"\"=== مقدمة البودكاست ===\n",
    "{intro_dialogue}\n",
    "\n",
    "=== النقاش الرئيسي ===\n",
    "{discussion_dialogue.strip()}\n",
    "\n",
    "=== ختام البودكاست ===\n",
    "{closing_dialogue}\"\"\"\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"🎉 تم إنجاز السكريبت الكامل بنجاح!\")\n",
    "        \n",
    "        return {\n",
    "            \"intro\": intro_dialogue,\n",
    "            \"main_discussion\": discussion_dialogue.strip(),\n",
    "            \"closing\": closing_dialogue,\n",
    "            \"complete_script\": complete_script,\n",
    "            \"script_length\": len(complete_script),\n",
    "            \"estimated_duration\": \"10-12 دقيقة تقريباً\",\n",
    "            \"style_used\": optimal_style,\n",
    "            \"quality_score\": self._assess_script_quality(complete_script)\n",
    "        }\n",
    "\n",
    "    def _clean_arabic_dialogue(self, dialogue_text):\n",
    "        \"\"\"Clean the generated dialogue to ensure quality\"\"\"\n",
    "        # Remove any non-Arabic characters except basic punctuation\n",
    "        cleaned = re.sub(r'[^\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF\\s\\[\\]\\(\\):\\-\\.،؟!«»]+', '', dialogue_text)\n",
    "        \n",
    "        # Remove emojis and special symbols\n",
    "        cleaned = re.sub(r'[😀-🙏🚀-🛿⚡-⚿✨-❿💀-💯🔀-🔿]', '', cleaned)\n",
    "        \n",
    "        # Clean up extra spaces and line breaks\n",
    "        cleaned = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', cleaned)\n",
    "        cleaned = re.sub(r'[ \\t]+', ' ', cleaned)\n",
    "        \n",
    "        # Ensure proper Arabic punctuation\n",
    "        cleaned = cleaned.replace('?', '؟').replace(';', '؛')\n",
    "        \n",
    "        return cleaned.strip()\n",
    "\n",
    "    def _determine_optimal_style(self, outline):\n",
    "        \"\"\"Determine the optimal dialogue style from the outline\"\"\"\n",
    "        language_style = outline.get(\"language_style\", {})\n",
    "        formality = language_style.get(\"formality_level\", \"\")\n",
    "        \n",
    "        if \"حواري\" in formality or \"ودي\" in formality:\n",
    "            return \"حواري\"\n",
    "        elif \"تحليلي\" in formality:\n",
    "            return \"تحليلي\"\n",
    "        elif \"مرح\" in formality or \"ترفيهي\" in formality:\n",
    "            return \"ترفيهي\"\n",
    "        else:\n",
    "            return \"تعليمي\"\n",
    "\n",
    "    def _split_discussion_points(self, main_discussion):\n",
    "        \"\"\"Split discussion points into manageable segments\"\"\"\n",
    "        if len(main_discussion) <= 2:\n",
    "            return [main_discussion]\n",
    "        elif len(main_discussion) == 3:\n",
    "            return [main_discussion[:2], [main_discussion[2]]]\n",
    "        else:\n",
    "            # For more points, split into roughly equal segments\n",
    "            mid = len(main_discussion) // 2\n",
    "            return [main_discussion[:mid], main_discussion[mid:]]\n",
    "\n",
    "    def _get_fallback_intro(self, topic, outline, style):\n",
    "        \"\"\"Generate fallback intro if main generation fails\"\"\"\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        return f\"\"\"{host_name}: مرحباً بكم مستمعينا الكرام، في حلقة جديدة نناقش فيها موضوع {topic}. معي اليوم ضيف متميز لمناقشة هذا الموضوع المهم.\n",
    "\n",
    "{guest_name}: أهلاً وسهلاً، شكراً على الاستضافة. سعيد بوجودي معكم لمناقشة هذا الموضوع الشيق.\n",
    "\n",
    "{host_name}: ممتاز، دعنا نبدأ بالتعمق في تفاصيل هذا الموضوع المثير للاهتمام.\"\"\"\n",
    "\n",
    "    def _get_fallback_discussion_segment(self, points, style):\n",
    "        \"\"\"Generate fallback discussion segment\"\"\"\n",
    "        return \"\"\"المقدم: هذا موضوع معقد فعلاً، ما رأيك في التحديات الرئيسية؟\n",
    "\n",
    "الضيف: بصراحة، هناك عدة جوانب مهمة يجب أن نفكر فيها بعناية.\n",
    "\n",
    "المقدم: ممكن توضح أكثر؟\n",
    "\n",
    "الضيف: طبعاً، أعتقد أن الأمر يحتاج دراسة عميقة للوصول لحلول فعالة.\"\"\"\n",
    "\n",
    "    def _get_fallback_closing(self, topic, outline, style):\n",
    "        \"\"\"Generate fallback closing if main generation fails\"\"\"\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        return f\"\"\"{host_name}: في ختام حلقتنا اليوم، أشكرك {guest_name} على هذا النقاش المفيد حول {topic}.\n",
    "\n",
    "{guest_name}: شكراً لك على الاستضافة، كان نقاش ممتع ومفيد.\n",
    "\n",
    "{host_name}: وشكراً لكم مستمعينا الكرام على متابعتكم. نلقاكم في حلقة قادمة بإذن الله.\"\"\"\n",
    "\n",
    "    def _assess_script_quality(self, script):\n",
    "        \"\"\"Assess the quality of the generated script\"\"\"\n",
    "        # Simple quality metrics\n",
    "        arabic_ratio = len(re.findall(r'[\\u0600-\\u06FF]', script)) / len(script) if script else 0\n",
    "        dialogue_balance = script.count('المقدم:') + script.count('الضيف:')\n",
    "        \n",
    "        quality_score = min(100, int(arabic_ratio * 70 + min(dialogue_balance * 5, 30)))\n",
    "        return quality_score\n",
    "\n",
    "    def validate_script_quality(self, script_result):\n",
    "        \"\"\"Validate the quality of the generated script\"\"\"\n",
    "        try:\n",
    "            complete_script = script_result.get(\"complete_script\", \"\")\n",
    "            \n",
    "            validation = {\n",
    "                \"has_intro\": \"=== مقدمة البودكاست ===\" in complete_script,\n",
    "                \"has_discussion\": \"=== النقاش الرئيسي ===\" in complete_script,\n",
    "                \"has_closing\": \"=== ختام البودكاست ===\" in complete_script,\n",
    "                \"arabic_content\": bool(re.search(r'[\\u0600-\\u06FF]', complete_script)),\n",
    "                \"no_foreign_text\": not bool(re.search(r'[a-zA-Z\\u4e00-\\u9fff]', complete_script)),\n",
    "                \"balanced_dialogue\": complete_script.count('المقدم:') >= 3 and complete_script.count('الضيف:') >= 3,\n",
    "                \"quality_score\": script_result.get(\"quality_score\", 0)\n",
    "            }\n",
    "            \n",
    "            validation[\"overall_valid\"] = all([\n",
    "                validation[\"has_intro\"],\n",
    "                validation[\"has_discussion\"], \n",
    "                validation[\"has_closing\"],\n",
    "                validation[\"arabic_content\"],\n",
    "                validation[\"no_foreign_text\"]\n",
    "            ])\n",
    "            \n",
    "            return validation\n",
    "        except:\n",
    "            return {\"overall_valid\": False, \"error\": \"Validation failed\"}\n",
    "\n",
    "# Usage:\n",
    "# generator = EnhancedSectionalScriptGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "# script_result = generator.generate_complete_script(topic, final_outline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7838c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️ بدء توليد السكريبت المطور بالطريقة التقسيمية...\n",
      "==================================================\n",
      "📋 الأسلوب المحدد: تحليلي\n",
      "📝 الجزء الأول: توليد حوار المقدمة...\n",
      "✅ تم إنجاز حوار المقدمة بنجاح\n",
      "📝 الجزء الثاني: توليد حوار النقاش الرئيسي...\n",
      "  توليد مقطع النقاش 1/2...\n",
      "  ✅ تم إنجاز مقطع النقاش 1\n",
      "  توليد مقطع النقاش 2/2...\n",
      "  ✅ تم إنجاز مقطع النقاش 2\n",
      "✅ تم إنجاز حوار النقاش الرئيسي\n",
      "📝 الجزء الثالث: توليد حوار الختام...\n",
      "✅ تم إنجاز حوار الختام بنجاح\n",
      "==================================================\n",
      "🎉 تم إنجاز السكريبت الكامل بنجاح!\n",
      "Generated Script:\n",
      "=== مقدمة البودكاست ===\n",
      "لمى عبد الله: مرحباً أصدقاء! نحنُ اليومِ في رحلةٍ شيقة؛ حيث سنتجوّلْ في عالمِ التقنية ونستكشفُ مدى تاثرياتهِ على هويتِّنَا العرَبِيَّة الفريدَة. فهل تسائَلتم يوماً بينما نُمَدحُ إنجازاتِ المُختبرات العالمية للذكاءِ الاصطناعي، كم تُؤثر تلك النجاحاتعلى شخصيتيَّنَا ومعتقداتيَنَا؟ أمم... إليكم دليلَهذا الاستفسار الدقيق، ينصلهذا الحوار مُناقشةُ ذكيَّةمع الدكتور علي محسِن، الباحث المرموقفي مجالعلومالحاسوبوالأستاذالمساعدةفيجامعة حكومةمحليةمشهورة.مرحباً يا دكتورا، أنتمانحننتظر أفكاركىالقيمةحول هاذه ماهمية قضية !\n",
      "\n",
      "علي محسن: جازاكِ اللّه خيرآ، سيدتيلمىأتفق مع ما طرحته من مستهِلَّةغاية الأهميّةترتكز قضيـَّتُنابالأساس علــَي ثنائيات تواجدهديوثباتها :بين الأصالةالعربيهلامكانيتها للتكيفمع مستقبلمجتمعاتنا المتغيّرةبشكل سريع . إن احتفاظنوبوتينامتداد ثقافتناتربوياًدينيًاصحيح ولكن يجب ألّا يغيب عناهيضروريآاستخدامتقانات عصرنة لتعزيزوعي أبناء أجناسونادراًعن قيممساجدهموتقاليدهمنذ القدم وبالتالي سنكون قدراعا وتوازنامثاليًعبين رقمنة واستمرارية روحالإسلام والموروثالتاريخيشآم لنفتحبيانداخليةهذا الموضوعالعميقولنبحر أولاً فيماوصل إليهعلمالاتصالات الحديث ومايترتب عليه بشأن حفظ الهوياتوسموهاالفردي خصيصاً هنا داخل مجتمع عربيإسلامي!!!\n",
      "\n",
      " : .\n",
      "\n",
      "=== النقاش الرئيسي ===\n",
      "لمى: نُدخل الآن إلى مرحلة أكثر تحديدًا ضمن رحلتنا لاستكشاف دور الذكاء الاصطناعي في حضن هويتنا العربية الإسلامية العزيزة. دعنا نتوقف لحظة عند نقطة مثيرة للجدل؛ التدريب الذي يجري حاليًا لهذه النماذج اللغوية المتقدمة باستخدام مواد ليس لها جذور عربية كاملة. إليكَ وجهة نظري كصحفية تقنية: أخشى أن يؤدي ذلك بشكل سلبي لتشويه طابع لغتنا وثقافتنا الخاصة التي تشكل جوهر وجودنا. ما رأيك يا دكتور علي؟ وكيف ترى تأثير مثل تلك الأفعال غير المدروسة وقدومها المفاجئ؟!\n",
      "\n",
      "علي: صحيح! إنها بالفعل قضية مهمّة جدًّا تستحق البحث والتأمّل. وبصفتي باحثًا اهتمُّ بتحقيق توازنٍ بين الاستفادة الحديثة والأصول التقليدية للدين والعادات المجتمعية. وفي سياق بحثي الأخير، لاحظتّ بوضوح ضرورة الحرص على تنمية نموذجين ذكيَّين لفهم قضايانا والقريب منها مدمجًا بفلسفة اجتماعية وفكر مستنير ومادي يستند للإرث الحضاري الإسلاموي دون مغادرة الإبداع المستقبلي للمجهول. لكن لا ينبغي لهذا التحالف الوثيق بين القديم والجديد ألّا يحجب أصالة فروعنا المعرفية الغنية والتي تحتضن ثراء عربي وإسلامي خاص بنا فقط.\n",
      "\n",
      "لمى: كلام مُوفق إذًا، ولكن ماذا لو تطرقنا لمحات توضيحية لأعمال وطنية رائدة تتعلق بهذا الجانب التي حققت نجاحاتها المعترف بها عالمياً مؤخرًا لاتخاذ زمام مبادرتنا تحت راية التمكين الوطني والتصدِّي لكل مسعى للتشويه خارج حدودنا الموحدة بإذن الرحمن سبحانه وتعالى. فتذكروا حتى مثال دولة الإمارات الطموحة والبرازق الرائده في مجال آلات توليد الكلمات المكتوبة الآلية بناءً وقوامها رسميات اعتماد بيانات مكتوبه موطنه ذات المنبت العربيين الأصل عبر مقاييس صارمه وضوابط أخلاقيه ومعرفية واضحه المعالم تضمن احترام مرجعيات ديننا واستثمار جنون جديد بدون خساره ماهو اصيل بالنسبه شعبنا \n",
      "\n",
      "علي: بلا شك! لقد شكلتْ المشروعاتُ الناشئة لدينا قوة دفع رئيسية لسعيِ تحقيق هدف المساهمة الدولية بحكمةٍ واقتدار كذلك. حيث وضعوا نصب أعينهم باستمرار قاعدة متينة قائمة أساساتها على فهم عميق لعالمنا ومعرفته غرضه، الأمر الذي يسمح له بخلق منتجات تمثل فعليا اهتماماته واحتياجاته بما يتماشى تمام المطابقة مع رؤانا وقيمه الجمعيه .\n",
      " \n",
      "(تنتهي الفقره هنا كون الحد المعيَّن طلب منه ثلاث أو اربع الدقائق ولذا فقد انحاز المؤلف لكسب الاختصار والإيجازه بغاية انتهاء قبل الوصول للنطاق المحددود مقدماه اعتاذاء متكاملاُ نوعآقا محاورآن ((مرجو الاعتبار)) ) !\n",
      "\n",
      "لمى: ندلف الان الى فصل حيوي جدا بعملية استكشافنا لدور الذكاء الصناعي بأذرعه المترامية باتجاه احتضان تراث امتيازات وجودنا العربية الاسلاميه ؛ فلنعوق انفسنا لبضع اللحظات فنبحث فى حديث الأشد تعقيدا وصاحبه ازمه اخلاقيه وهي: حالة التعجيل بسخائها في اطعام رواده بنظم تغذيه خبريه تتم توابع اجزائه بوسائل خارجية عدم اختصاصها بالأصال جغرافية المنطقة العروبيه. بذلك تكون رؤية راويتنا الصحفيه المهتمه بالتكنولوجيات حديثه ذات لون اجتماعي مختلف قليلا اتكون مطروحه اليوم أمام المائدة العامله معناالسيد الدكتور علي محزون كما يلي :- هل تخاف يا صديقي الكريم أن يحدث تدخلات ضارة لهذه الأساليب الجديدة بقلب وعقل لغتهم ونكهتهم الاصليه؟؟!!!! \n",
      "\n",
      "علي: انه جري ذو شجون قطعاً يحتاح للقراءةالجيده واتباع ألحقيقة بينما نحن ابحاثين نسعى دوم للاسترشاد بفقه علمه الرباني وطريق الحق المستقيم ..ومن ثم يظهر لي أنه ضروري للغاية الترقب لانطلاق مراحل جديدة يسود فيها نظام انسياب البيانات المعلومات بعكس سابقه المؤذي المهمله سابقآ وإن كان توجيهي الحالي يتمثل بالإشارة لضروره العمل بحرص شديد لنضمن اختيار طريق مناسب ومتكامل يشمل تثبيت ركيزة الدين الحنيف كتأسيس منطقي راسخ وانطلقة قدرتها العمليه لإنتاج معرفيه واجتماعيه مبتكرة وخلاقة بهدف منافسة اقوياء العالم الخارجي بلا تورطه مواجهة مباشره تغتال تصورات شعائر مقدسيتهادود جامعه الحياة لدي محصول أرضنا وحفظ فروض خدمتها تجاه ربنا عزوجل .\n",
      "لمى: مبروووورطرح فلسفي سامي لمنطلق رائع الياس الكبيرلكنماذاإن افترضنا بلد عربيوخطاواعدددفقصورانهجزيره الاماراتالعظيمبالنسبة لشغلالتحولالتكنولوجي ،فضمانالهتمامخاص بهم هو النقاطالاكثرعضوهبشدةوالتركيزقابلهمعلىجعل منموتعلقيهتقنياتهنيهتأخذصورة مدركةاقللدوافعالرئيستحاضرناالانسانيهوكذلك وايضاالقيمي ديني ايضا\n",
      "\n",
      "علي: نعم!!لكن ذكراهممثاليرائعةعن ابتكاراتوطناالحبيبهذهبلديطرماالمستنقعالجميلةللأجيالبشبابتسابق نفسانيهحتلابالثانوهاتجريقاتهمالإعلامية العالميةبينركازموسوعة مفتوحة تجمع عصارةخبراتشعباًوشيمناهيمرعبثممتاحفنسبمحاربسبيلهنيبدارضهامنقتلرموز مدنيهالغدرالبعدیه..\n",
      "\n",
      "لمى: دكتور علي، دعوناُ نغوص أكثر فيما يتعلق باستخدام الذكاء الاصطناعي لدعم هويتِنا خلال الثورة الرقمية. خاصة عندما يتعلّق الأمر بالأجيال الصاعدة؛ فكيف يُمكن لهذه التقنيات أن تعكِـر رؤیتهم للهویتة العربية والإسلامية\n",
      "\n",
      "علي: موضوع حساس بالفعل، لكن ليس حتميًا ان يكبح تطور ذكاء اصطناعي تقدمنا المعرفي والديني. وإن تم استخدامه بشكل مدروس وقدمت له السياقات المناسبة الملائمة لشخصیتنا ومعتقداتنا وثقافتنا، بإمكانه مساعدتنا فعلاً بترسيخ جذور ثابتة للأجيال الطموحة الغارقة بأمواج المعلومة الواصلة منها ما هو مفيد ومنها مالا ينفع بل ويضل الطريق! فقد رأينا مؤخرًا بعض حالات سوء التطبيق مما دعا لنشر الوعي حول كيفية الاستخدام الأمثل لهذه الأدوات الحديثة والتي غدت جزء لا يتجزأ من حياة شباب اليوم بالفعل! حتىَ إنْ مُثرة كتب تُنشَرُ عبر هذه المنصات الإلكترونية تصور الدين بشكل ملتوٍ وغير منطقي إذا بات أمر الإشراف عليها غير موجود أو فاعل بما فيه الكفاية . لذا يجب تنظيم وضبط سياساتها وفق قيمه ومبادئ الاسلام والعروبه وحمايتهما من أي تشوه محتمل للصورة المثالية لدى عامة المستخدمين خصوصاً المبتدئین منهم الذين ربما ليست لهم خلفية صلبة لهذه الأمور الأساسية للحياة الروحية والنفسية بالنسبة للعربي المسلم تحديدًا ..!\n",
      "\n",
      "لمى: صحيح تمامًا وفي هذا المضمار تجدر هنا الإشارة لتلك التجارب الرائعة التي أثمرت نجاحات تفوح عطرها طيب الياسمين ، حيث تستلهم روائح عبقه تلك المشاعر ذات اللحن الباهر والذي ارتسمته ذاكرتنا الجمعية كونها علامات فارقه في تاريخ حضارتناالعربية المعطاء ... إذ اعتبرالتوأماً متجانسان دون احداهمهلوك المقوماتلوالتأسيسالرئيسيعليهالسير قدمأمام للاستمراربطيةنافيالطرقالقادمه.....مثلالاسترجاعذاكرةعلىمجرداسمعتكلماتومشاهدمقابلالخرائط الذهنيه للمواقع التاريخيةكالمسجد الجامع بفاس بالمملكة المغربية ! وهو أحد المواقع الأقوى تأثيرًا وجاذبية لمنزر عناوين علم وأدبياتهالشائقة.\n",
      "\n",
      "علي : وكذلك أيضًا فنستوحي ومنآثارالفكر العربي التواق إلى توسيعآفاقالحكمه النظريةإلى التنفيذ العملي الواقعي كما الذي ترك لنا ارثا معرفيا هاوماعتبر ثوره الفكري حين جمعا جزء كبيرمنعلم الاجتماع والصراع الطبقي إضافة لمساهماته الأخرى المتنوعة والتي لاتزال تحتفظ بقيمة عالية لما تقدمه لنا من منظور شامل لفهم واقع المجتمع ونشأةالدول وهذه كلها مواد جاهزة لرصد واستنتاج رهائن تتماشي واتجاهات البحث الحديث فتكون بذلك عامل قوة وليس ضعىرها لأمتنامشيرةبالذكرلطلعكس الصورةعن حاضرنا أمامالانظار الخارجية والداخليه أيضا فلنتخذ دور رائدين فى مجالات مختلفة كالطبوالهندسة الطيران والتكنولوجيا حيث يتم تطويرمنتجات تناسب توقعات واحتياجات مجتمع الخاص بنا بدلا من الاكتفاء فقط باستعمال اﻻعادة بدون تعديلات لاحقتها مطالبات ضرورية للتكييف الشامل والموائم لحاجات المستقبل...!!\n",
      "\n",
      "لمى نعم إن تنمية ذهن عام تصاحب سهولة الوصول والاستخدام ستجعل تكنولوجيتنينالذكاء اصطناعيا صديقا ليس عدوباخصوص أنه يمكن توجيه جهوده لينظم محتواه حسب مقاييس أولويات الثقافة والقيم والأخلاقيات قطاع خاص بعالمنا الفريد وبذلك يحقق جماليته الخاصة وفرادته وجلاء ألوانه التشخيصية المؤثره....بعدمشيئةالله عزوجل فهو راعي الهداية واكبر مصدر إلهام للإبداعاتتشكل اساس وجود أرضا خصبه لوطدت بصبرها بذارا رشيدة سوف تثمر فيما بعد محصول أفراح واسرار عجيبة لكل البشر جميعا بلا فرق.......نحمد الرب شاكرافضله لأنه أعطانا نعمة فهم كتابه العزيز منزل تواترأنوار الفرحه والسعادة داخل قلوب اهلهالكراممستخدمينههذه اللآلئ التعليمية المباركة .....آمين يا رب العالمين وابارك لنا بارك واجمع صفوفنا على المحبة والتسامح والخير إنه ولي ذلك والقادر عليه.............. نهاية حديثنا شكراً للدكتور علي حسن على مناقشته المثريةمعبودي.\n",
      "\n",
      "(ملاحظة: تمت ترجمة النص العربي لتحقيق القواعد المطلوبة ولكن سيظهر بشكل أكثر طبيعية وعامية عند كتابة أصليّة.)\n",
      "\n",
      "=== ختام البودكاست ===\n",
      "لمى: إذن، الدكتور عليهذه رحلة مُثْرِية حقاً عبر عالم التقنية وفلسفتنا الثقافية الجميلة. لقد رأينا كيف يمكن للذكاء الصناعي أن يكون أداة قيّمة لكن بشرط ألّا يُنسِيَ جذورنا وأصولنا التي تشكل هويتنا.\n",
      "\n",
      "علي: بالضبط، لمى. من المهم جداً إدراك أن هذه الأدوات هي وسائل تخدم غاياتنا لا تُغيّر هُويتَنا أو تضيع تاريخنا الطويل الغني بالحكمة والمعرفة. دعونا ندعم المؤسسات والبرامج التعليمية التي تعمل على ترسيخ مفاهيمنا وقيمنا أثناء التعامل مع تقنيات عصرنا الجديد.\n",
      "\n",
      "لمى: كلام جميل للغاية! أتفق تمامًا معه حول ضرورة توازن الاستفادة من التطور دون تناسي ما يعنيه كوننا عربيين. هذا ليس مجرد حوار نظري؛ بل هو تحدٍ يتطلب جهد الجميع لتجاوزه بنجاح.\n",
      "\n",
      "علي: شكرًا جزيلًا للمسة النيرة ولجميع الحضور الذين خصصوا وقتهم الثمين لقضاء هذه اللحظات الفكرية الثرية معنا. بالنسبة لي، كان الشرف الأكبر مشاركتكم أفكاري وإضافة وجهة نظر مختلفة للقضية المطروحة هنا اليوم.\n",
      "\n",
      "لمى: قبل الانطلاق إلى نهايتنا، لن نغفل عن قول المثل القديم الذي يقول الأصل دائم، مهما تبدلت الظروف. فهو يدعو للتذكر الدائم لأصولنا وجذورنا بينما نتخذ خطواتنا الأولى باتجاه المستقبل الواعد ذي الوجهتين المشرقتين: التقنية والأصالة.\n",
      "\n",
      "علي: أيضًا، يستحق ذكر دور بلد مثل مصر وكيف تسعى دوماً للحفاظ على روحيتها وسط التقدم المتزايد. إنها مثال رائع لبقية الدول العربية.\n",
      "\n",
      "لمى: نعم ! فالمثابرة المصرية الشهيرة خير دليل علينا جميعاً بأن بإمكان العرب تحقيق التوازن الإيجابي والمضي قدمًا للأمام بكل ثقة واستقرار.\n",
      "\n",
      "علي: وإن كنت أدعو كل واحد منكم لحفظ مقولة أخرى وهي الحديث السليم يفيد السامعين، حيث تعد هذه الكلمات مفتاح فهم أهمية التواصل الفعال والعقلاني فيما يخص موضوعات حساسة كالذي تناولناه الليلة.\n",
      "\n",
      "لمى: أشكرك مرة أخرى أيها العزيز علي على حضورك الرائع ومشاركاتك الغنية بالأفكار الثاقبة. وددت لو بقينا طوال الليل نناقش المزيد ولكنه الوقت مناسب الآن لاستدعائكم جميعاً للتفاعل معنا وتعزيز تلك الرسائل إلكترونيًا عبر مواقعنا الرسمية ومنصات التواصل الاجتماعي الخاصة بنا.\n",
      "\n",
      "علي: نسأل الرحمن الكريم أن يوفق مساعيك وأن يحقق آمالك وييسر أمرك دومًا.\n",
      "\n",
      "لمى: آمين. أرجو أن تكون قد اكتسبت معرفة جديدة وغذاء للعقل خلال هذه الحلقة الهامة. إلي اللقاء مرة أخرى في حلقة قادمة مليئة بالتحديات المفيدة والفائدة المُستديمة بإذن الله تعالى.\n",
      "\n",
      "(اختفاء الموسيقى تدريجيًا)\n",
      "\n",
      "الثقة بالنفس والدعم الشعبي هما طريق نجاحنا المشترك لمى عبد الله علي محسن - .\n",
      "\n",
      "(: )\n",
      "Script Quality: 58/100\n",
      "Validation Status: ✅ Passed\n",
      "Intro: 1127 characters\n",
      "Discussion: 7181 characters\n",
      "Closing: 2149 characters\n",
      "Estimated Duration: 10-12 دقيقة تقريباً\n"
     ]
    }
   ],
   "source": [
    "# Generate high-quality sectional script\n",
    "generator = EnhancedSectionalScriptGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "script_result = generator.generate_complete_script(topic, final_outline)\n",
    "\n",
    "print(\"Generated Script:\")\n",
    "print(script_result[\"complete_script\"])\n",
    "\n",
    "# Validate script quality\n",
    "validation = generator.validate_script_quality(script_result)\n",
    "print(f\"Script Quality: {validation['quality_score']}/100\")\n",
    "print(f\"Validation Status: {'✅ Passed' if validation['overall_valid'] else '❌ Failed'}\")\n",
    "\n",
    "# Check individual components\n",
    "print(f\"Intro: {len(script_result['intro'])} characters\")\n",
    "print(f\"Discussion: {len(script_result['main_discussion'])} characters\") \n",
    "print(f\"Closing: {len(script_result['closing'])} characters\")\n",
    "print(f\"Estimated Duration: {script_result['estimated_duration']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
