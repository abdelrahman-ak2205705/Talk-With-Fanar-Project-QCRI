{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e5796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# import openai\n",
    "from openai import AzureOpenAI\n",
    "# !pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3174aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def APIKeyManager(model_type, key_path):\n",
    "    \n",
    "    load_dotenv(dotenv_path=key_path, override=True)\n",
    "    if model_type=='azure':\n",
    "        client = AzureOpenAI(\n",
    "            api_version=os.environ[\"AZURE_API_VERSION\"],\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "        )\n",
    "        return client\n",
    "    elif model_type=='fanar':\n",
    "        client = OpenAI(base_url=\"https://api.fanar.qa/v1\",api_key=os.environ[\"FANAR_API_KEY\"],)\n",
    "    elif model_type=='gemini':\n",
    "        pass\n",
    "    return client\n",
    "\n",
    "# Load environment variables\n",
    "model_type=\"azure\"\n",
    "deployment = APIKeyManager(model_type, \"./azure.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a84582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicClassifier:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def classify_topic(self, topic, information):\n",
    "        \"\"\"\n",
    "        Classify podcast topic and determine optimal approach\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            \n",
    "        Returns:\n",
    "            JSON with classification results\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in analyzing and classifying topics for producing natural and engaging Arabic podcasts.\n",
    "\n",
    "Task: Analyze the following topic and determine the best approach for presenting it in an Arabic podcast.\n",
    "\n",
    "Topic: {topic}\n",
    "Background Information: {information}\n",
    "\n",
    "Analyze the topic and return the result in JSON format containing:\n",
    "\n",
    "{{\n",
    "    \"primary_category\": \"Main category\",\n",
    "    \"category_justification\": \"Reason for choosing this category based on the topic's nature\",\n",
    "    \"optimal_style\": \"Optimal discussion style\",\n",
    "    \"discourse_pattern\": \"Appropriate discourse pattern\",\n",
    "    \"audience_engagement_goal\": \"Audience engagement objective\",\n",
    "    \"cultural_sensitivity_level\": \"Cultural sensitivity level\",\n",
    "    \"controversy_potential\": \"Controversy potential\",\n",
    "    \"key_discussion_angles\": [\n",
    "        \"Main expected discussion angles\",\n",
    "        \"Points that will interest the Arabic audience\"\n",
    "    ],\n",
    "    \"natural_tension_points\": [\n",
    "        \"Natural tension points in the topic\",\n",
    "        \"Aspects that might generate healthy debate\"\n",
    "    ],\n",
    "    \"cultural_connection_opportunities\": [\n",
    "        \"Opportunities to connect with Arabic culture\",\n",
    "        \"Relevant local and regional references\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Available Categories:\n",
    "1. \"العلوم والتكنولوجيا\" - For technical, scientific topics and innovations\n",
    "2. \"السياسة والشؤون العامة\" - For political topics, current events and public affairs\n",
    "3. \"القضايا الاجتماعية\" - For social topics, relationships, values and social challenges\n",
    "4. \"الرياضة والترفيه\" - For sports, arts and entertainment topics\n",
    "5. \"التاريخ والثقافة\" - For historical, heritage and cultural topics\n",
    "\n",
    "Available Styles:\n",
    "- \"حواري\" - Natural and friendly dialogue between host and guest\n",
    "- \"تعليمي\" - Focus on explanation and education in an entertaining way\n",
    "- \"ترفيهي\" - Fun and light with humorous touches\n",
    "- \"تحليلي\" - Deep, specialized and analytical discussion\n",
    "\n",
    "Discourse Patterns:\n",
    "- \"رسمي\" - Formal and respectful language\n",
    "- \"ودي\" - Warm and familiar language\n",
    "- \"جدلي\" - Lively discussion with multiple viewpoints\n",
    "- \"سردي\" - Storytelling and narrative style\n",
    "\n",
    "Cultural Sensitivity Level:\n",
    "- \"عالي\" - Requires extreme caution in handling\n",
    "- \"متوسط\" - Needs moderate cultural consideration\n",
    "- \"منخفض\" - Generally acceptable topic\n",
    "\n",
    "Controversy Potential:\n",
    "- \"عالية\" - Inherently controversial topic\n",
    "- \"متوسطة\" - May generate some disagreements\n",
    "- \"منخفضة\" - Generally acceptable topic\n",
    "\n",
    "Important Instructions:\n",
    "- Analyze the topic deeply, not superficially\n",
    "- Consider the Arabic cultural context in your analysis\n",
    "- Focus on what makes the topic appealing to Arabic audiences\n",
    "- Ensure the classification serves natural and spontaneous content production\n",
    "- Do not include ```json markers at the beginning or end\n",
    "- Return only valid JSON without any additional text\n",
    "- All JSON values should be written in Modern Standard Arabic (MSA)\n",
    "- The optimal episode duration is 10 minutes\n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in analyzing and classifying topics for producing professional Arabic podcasts. You specialize in understanding Arabic audiences and their interests. Always respond with JSON values in Modern Standard Arabic.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3  # Lower temperature for more consistent classification\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bde0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Result:\n",
      "{\n",
      "    \"primary_category\": \"التاريخ والثقافة\",\n",
      "    \"category_justification\": \"الموضوع يتناول الهوية الثقافية العربية وتأثير الذكاء الاصطناعي عليها، مما يجعله مرتبطًا بالتراث والثقافة العربية بشكل مباشر.\",\n",
      "    \"optimal_style\": \"تحليلي\",\n",
      "    \"discourse_pattern\": \"رسمي\",\n",
      "    \"audience_engagement_goal\": \"إثارة التفكير حول أهمية الحفاظ على الهوية الثقافية في ظل التطورات الرقمية، وتشجيع الجمهور على المشاركة في النقاش حول مستقبل الثقافة العربية.\",\n",
      "    \"cultural_sensitivity_level\": \"عالي\",\n",
      "    \"controversy_potential\": \"متوسطة\",\n",
      "    \"key_discussion_angles\": [\n",
      "        \"تأثير الذكاء الاصطناعي على اللغة العربية والهوية الثقافية.\",\n",
      "        \"جهود الدول العربية في تطوير نماذج ذكاء اصطناعي تعكس الثقافة المحلية.\",\n",
      "        \"كيفية تحقيق التوازن بين الابتكار الرقمي والحفاظ على القيم الثقافية.\"\n",
      "    ],\n",
      "    \"natural_tension_points\": [\n",
      "        \"هيمنة المحتوى الرقمي باللغة الإنجليزية مقابل ضعف المحتوى العربي.\",\n",
      "        \"التحديات في تدريب نماذج ذكاء اصطناعي على بيانات عربية ذات جودة عالية.\",\n",
      "        \"مخاوف من تهميش الثقافة العربية بسبب الاعتماد على تقنيات غربية.\"\n",
      "    ],\n",
      "    \"cultural_connection_opportunities\": [\n",
      "        \"الإشارة إلى مبادرات عربية مثل نموذج \\\"جايس\\\" و\\\"الحوراء\\\".\",\n",
      "        \"تسليط الضوء على أهمية اللغة العربية كجزء من الهوية الثقافية.\",\n",
      "        \"ربط الموضوع بتاريخ العرب في الحفاظ على تراثهم في مواجهة التحديات.\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "Primary Category: التاريخ والثقافة\n",
      "Optimal Style: تحليلي\n",
      "Error parsing JSON result\n"
     ]
    }
   ],
   "source": [
    "# Testing Instructions:\n",
    "\n",
    "# To test Step 1, add this to a new cell in your notebook:\n",
    "\n",
    "# Test Step 1: Topic Classification\n",
    "classifier = TopicClassifier(deployment, \"gpt-4o\")\n",
    "\n",
    "# Test with the singlehood topic\n",
    "topic = \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\"\n",
    "\n",
    "information = '''\n",
    "مع انتشار تقنيات الذكاء الاصطناعي بسرعة في العالم العربي، تزداد المخاوف حول تأثيرها على الهوية الثقافية واللغة العربية. \n",
    "تشير الدراسات إلى أن 78% من المحتوى الرقمي باللغة الإنجليزية، بينما المحتوى العربي لا يتجاوز 3%. \n",
    "معظم نماذج الذكاء الاصطناعي الحالية مدربة على بيانات غربية، مما يثير تساؤلات حول قدرتها على فهم السياق الثقافي العربي.\n",
    "في المقابل، تسعى دول مثل الإمارات والسعودية لتطوير نماذج ذكاء اصطناعي عربية مثل \"جايس\" و\"الحوراء\" لمواجهة هذا التحدي.\n",
    "التحدي الأكبر يكمن في كيفية الاستفادة من هذه التقنيات لتعزيز الثقافة العربية بدلاً من تهميشها، وضمان أن تخدم الذكاء الاصطناعي قيمنا ومبادئنا.\n",
    "'''\n",
    "\n",
    "# Run classification\n",
    "classification_result = classifier.classify_topic(topic, information)\n",
    "print(\"Classification Result:\")\n",
    "print(classification_result)\n",
    "\n",
    "\n",
    "\n",
    "# Parse and examine the JSON\n",
    "try:\n",
    "    parsed_result = json.loads(classification_result)\n",
    "    print(f\"\\nPrimary Category: {parsed_result['primary_category']}\")\n",
    "    print(f\"Optimal Style: {parsed_result['optimal_style']}\")\n",
    "    print(f\"Emotional Intent: {parsed_result['emotional_intent']}\")\n",
    "    print(f\"Discourse Pattern: {parsed_result['discourse_pattern']}\")\n",
    "except:\n",
    "    print(\"Error parsing JSON result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9ee26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePersonaGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def generate_personas(self, topic, information, classification_result):\n",
    "        \"\"\"\n",
    "        Generate simple but effective host and guest personas\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            \n",
    "        Returns:\n",
    "            JSON with simple host and guest personas\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse classification to understand the requirements\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid classification JSON provided\")\n",
    "        \n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in designing Arabic podcast personas.\n",
    "\n",
    "Task: Create simple and suitable host and guest personas for this topic.\n",
    "\n",
    "Topic: {topic}\n",
    "Information: {information}\n",
    "Category: {primary_category}\n",
    "Required Style: {optimal_style}\n",
    "\n",
    "Return the result in simple JSON format:\n",
    "\n",
    "{{\n",
    "    \"host\": {{\n",
    "        \"name\": \"Host's name\",\n",
    "        \"age\": numeric_age,\n",
    "        \"background\": \"Brief background in one sentence\",\n",
    "        \"personality\": \"Personality description in one sentence\",\n",
    "        \"speaking_style\": \"Speaking style in one sentence\"\n",
    "    }},\n",
    "    \"guest\": {{\n",
    "        \"name\": \"Guest's name\", \n",
    "        \"age\": numeric_age,\n",
    "        \"background\": \"Brief background in one sentence\",\n",
    "        \"expertise\": \"Area of expertise in one sentence\",\n",
    "        \"personality\": \"Personality description in one sentence\",\n",
    "        \"speaking_style\": \"Speaking style in one sentence\"\n",
    "    }},\n",
    "    \"why_good_match\": \"Why this host and guest are suitable for this topic - one sentence\"\n",
    "}}\n",
    "\n",
    "Requirements:\n",
    "- Use familiar Arabic names\n",
    "- Simple and believable personas\n",
    "- Suitable for the topic and required style\n",
    "- Host should be curious and guest should be expert or have experience\n",
    "- All JSON values must be in Modern Standard Arabic (MSA)\n",
    "- JSON keys should be in English\n",
    "- Do not include ```json markers\n",
    "- Return only JSON\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in designing simple and effective podcast personas. Required style: {optimal_style}. Always provide JSON values in Modern Standard Arabic while keeping keys in English.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f699140",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona = SimplePersonaGenerator(deployment, \"gpt-4o\")\n",
    "persona_result = persona.generate_personas(topic, information, classification_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab52d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationStructureGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def generate_conversation_structure(self, topic, information, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Step 3: Generate core conversation structure (V1 skeleton)\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            \n",
    "        Returns:\n",
    "            JSON with V1-style conversation structure (without rich dialogue content)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided for classification or personas\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        discourse_pattern = classification.get(\"discourse_pattern\", \"\")\n",
    "        recommended_duration = classification.get(\"recommended_duration\", \"10 دقيقة\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in designing conversation structures for Arabic podcasts.\n",
    "\n",
    "Task: Create the basic conversation structure in natural dialogue format.\n",
    "\n",
    "Topic: {topic}\n",
    "Information: {information}\n",
    "\n",
    "Context:\n",
    "- Category: {primary_category}\n",
    "- Style: {optimal_style}\n",
    "- Discourse Pattern: {discourse_pattern}\n",
    "- Duration: {recommended_duration}\n",
    "\n",
    "Characters:\n",
    "- Host: {host_name} - {host.get('background', '')}\n",
    "- Guest: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "Create the conversation outline in JSON format:\n",
    "\n",
    "{{\n",
    "    \"episode_topic\": \"{topic}\",\n",
    "    \"personas\": {{\n",
    "        \"host\": {{\n",
    "            \"name\": \"{host_name}\",\n",
    "            \"background\": \"{host.get('background', '')}\",\n",
    "            \"speaking_style\": \"{host.get('speaking_style', '')}\"\n",
    "        }},\n",
    "        \"guest\": {{\n",
    "            \"name\": \"{guest_name}\",\n",
    "            \"background\": \"{guest.get('background', '')}\",\n",
    "            \"speaking_style\": \"{guest.get('speaking_style', '')}\"\n",
    "        }}\n",
    "    }},\n",
    "    \"conversation_flow\": {{\n",
    "        \"intro1\": {{\n",
    "            \"opening_line\": \"Actual opening line by the host\",\n",
    "            \"podcast_introduction\": \"Podcast introduction related to the topic\",\n",
    "            \"episode_hook\": \"Specific engaging sentence about the topic\",\n",
    "            \"tone_guidance\": \"Appropriate tone for {optimal_style} style\"\n",
    "        }},\n",
    "        \"intro2\": {{\n",
    "            \"topic_introduction\": \"Clear topic introduction\",\n",
    "            \"guest_welcome\": \"Welcome to guest {guest_name}\",\n",
    "            \"guest_bio_highlight\": \"Guest background introduction\",\n",
    "            \"transition_to_discussion\": \"Transition to main discussion\"\n",
    "        }},\n",
    "        \"main_discussion\": [\n",
    "            {{\n",
    "                \"point_title\": \"First main point of the topic\",\n",
    "                \"personal_angle\": \"How it relates to the characters' backgrounds\"\n",
    "            }},\n",
    "            {{\n",
    "                \"point_title\": \"Second main point of the topic\", \n",
    "                \"personal_angle\": \"Personal angle for this point\"\n",
    "            }},\n",
    "            {{\n",
    "                \"point_title\": \"Third main point of the topic\",\n",
    "                \"personal_angle\": \"Personal connection and concluding angle\"\n",
    "            }}\n",
    "        ],\n",
    "        \"closing\": {{\n",
    "            \"conclusion\": {{\n",
    "                \"main_takeaways\": \"Main takeaways\",\n",
    "                \"guest_final_message\": \"Guest's final message\",\n",
    "                \"host_closing_thoughts\": \"Host's closing thoughts\"\n",
    "            }},\n",
    "            \"outro\": {{\n",
    "                \"guest_appreciation\": \"Thank the guest\",\n",
    "                \"audience_thanks\": \"Thank the listeners\",\n",
    "                \"call_to_action\": \"Call for engagement\",\n",
    "                \"final_goodbye\": \"Final goodbye\"\n",
    "            }}\n",
    "        }}\n",
    "    }},\n",
    "    \"cultural_context\": {{\n",
    "        \"proverbs_sayings\": [\n",
    "            \"Relevant Arabic proverb for the topic\",\n",
    "            \"Related wisdom saying\"\n",
    "        ],\n",
    "        \"regional_references\": [\n",
    "            \"Local reference related to the topic\",\n",
    "            \"Relevant Arab experience\"\n",
    "        ]\n",
    "    }},\n",
    "    \"language_style\": {{\n",
    "        \"formality_level\": \"Appropriate level for {optimal_style} style\",\n",
    "        \"dialect_touches\": \"Light dialectal touches according to the host\",\n",
    "        \"vocabulary_richness\": \"Vocabulary suitable for the topic\"\n",
    "    }},\n",
    "    \"technical_notes\": {{\n",
    "        \"pacing_guidance\": \"Appropriate pacing for {recommended_duration} duration\",\n",
    "        \"pause_points\": \"Natural pause points\",\n",
    "        \"emphasis_moments\": \"Important emphasis moments\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Important Requirements:\n",
    "- Write actual content, not descriptions\n",
    "- Use the real character names ({host_name}, {guest_name})\n",
    "- Make all content related to the topic: {topic}\n",
    "- Focus on building the basic conversation structure\n",
    "- Make content ready for development in the next step\n",
    "- All JSON values must be in Modern Standard Arabic (MSA)\n",
    "- JSON keys should be in English\n",
    "- Do not include ```json markers\n",
    "- Return only valid JSON\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in designing conversation structures for Arabic podcasts. Required style: {optimal_style}. Always provide JSON values in Modern Standard Arabic while keeping keys in English.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6  # Balanced for structure creation\n",
    "        )\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(response.choices[0].message.content)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except:\n",
    "            # If parsing fails, return raw response\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def validate_conversation_structure(self, structure_json):\n",
    "        \"\"\"\n",
    "        Validate the conversation structure\n",
    "        \"\"\"\n",
    "        required_keys = [\"episode_topic\", \"personas\", \"conversation_flow\", \"cultural_context\", \"language_style\", \"technical_notes\"]\n",
    "        \n",
    "        conversation_flow_required = [\"intro1\", \"intro2\", \"main_discussion\", \"closing\"]\n",
    "        intro1_required = [\"opening_line\", \"podcast_introduction\", \"episode_hook\"]\n",
    "        intro2_required = [\"topic_introduction\", \"guest_welcome\", \"guest_bio_highlight\"]\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            structure = json.loads(structure_json)\n",
    "            \n",
    "            missing_keys = []\n",
    "            \n",
    "            # Check main structure\n",
    "            for key in required_keys:\n",
    "                if key not in structure:\n",
    "                    missing_keys.append(key)\n",
    "            \n",
    "            # Check conversation flow\n",
    "            if \"conversation_flow\" in structure:\n",
    "                conv_flow = structure[\"conversation_flow\"]\n",
    "                for key in conversation_flow_required:\n",
    "                    if key not in conv_flow:\n",
    "                        missing_keys.append(f\"conversation_flow.{key}\")\n",
    "                \n",
    "                # Check intro1\n",
    "                if \"intro1\" in conv_flow:\n",
    "                    intro1 = conv_flow[\"intro1\"]\n",
    "                    for key in intro1_required:\n",
    "                        if key not in intro1:\n",
    "                            missing_keys.append(f\"intro1.{key}\")\n",
    "                \n",
    "                # Check intro2\n",
    "                if \"intro2\" in conv_flow:\n",
    "                    intro2 = conv_flow[\"intro2\"]\n",
    "                    for key in intro2_required:\n",
    "                        if key not in intro2:\n",
    "                            missing_keys.append(f\"intro2.{key}\")\n",
    "                \n",
    "                # Check main discussion\n",
    "                if \"main_discussion\" in conv_flow:\n",
    "                    main_disc = conv_flow[\"main_discussion\"]\n",
    "                    if not isinstance(main_disc, list) or len(main_disc) < 3:\n",
    "                        missing_keys.append(\"main_discussion (need at least 3 points)\")\n",
    "                    else:\n",
    "                        for i, point in enumerate(main_disc):\n",
    "                            if \"point_title\" not in point:\n",
    "                                missing_keys.append(f\"main_discussion[{i}].point_title\")\n",
    "            \n",
    "            if missing_keys:\n",
    "                return False, f\"Missing required keys: {missing_keys}\"\n",
    "            \n",
    "            return True, \"Conversation structure validation successful\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_structure_quality(self, structure_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality of the conversation structure\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            structure = json.loads(structure_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check completeness\n",
    "            conv_flow = structure.get(\"conversation_flow\", {})\n",
    "            analysis[\"has_intro1\"] = bool(conv_flow.get(\"intro1\"))\n",
    "            analysis[\"has_intro2\"] = bool(conv_flow.get(\"intro2\"))\n",
    "            analysis[\"has_main_discussion\"] = bool(conv_flow.get(\"main_discussion\"))\n",
    "            analysis[\"has_closing\"] = bool(conv_flow.get(\"closing\"))\n",
    "            \n",
    "            # Check main discussion depth\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            analysis[\"discussion_points\"] = len(main_disc)\n",
    "            analysis[\"adequate_points\"] = len(main_disc) >= 3\n",
    "            \n",
    "            # Check cultural context\n",
    "            cultural = structure.get(\"cultural_context\", {})\n",
    "            analysis[\"has_proverbs\"] = len(cultural.get(\"proverbs_sayings\", [])) >= 1\n",
    "            analysis[\"has_regional_refs\"] = len(cultural.get(\"regional_references\", [])) >= 1\n",
    "            \n",
    "            # Overall readiness\n",
    "            readiness_indicators = [\n",
    "                analysis[\"has_intro1\"],\n",
    "                analysis[\"has_intro2\"],\n",
    "                analysis[\"has_main_discussion\"],\n",
    "                analysis[\"has_closing\"],\n",
    "                analysis[\"adequate_points\"],\n",
    "                analysis[\"has_proverbs\"]\n",
    "            ]\n",
    "            analysis[\"readiness_score\"] = sum(readiness_indicators)\n",
    "            analysis[\"ready_for_next_step\"] = analysis[\"readiness_score\"] >= 5\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze structure quality\"}\n",
    "\n",
    "# Usage:\n",
    "# generator = ConversationStructureGenerator(deployment, \"Fanar\") \n",
    "# structure_result = generator.generate_conversation_structure(topic, information, classification_result, personas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09091744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"ليلى أحمد\",\n",
      "      \"background\": \"صحفية ومقدمة برامج ثقافية مهتمة بالتكنولوجيا والهوية العربية.\",\n",
      "      \"speaking_style\": \"تتحدث بطريقة تحليلية واضحة وتطرح أسئلة ذكية.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. سامي الحسن\",\n",
      "      \"background\": \"أستاذ جامعي وخبير في الذكاء الاصطناعي وتطبيقاته في العالم العربي.\",\n",
      "      \"speaking_style\": \"يشرح الأفكار بطريقة علمية مبسطة وموجهة للجمهور.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحبًا بكم في حلقة جديدة من بودكاستنا حيث نناقش القضايا التي تؤثر على ثقافتنا وهويتنا.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع في غاية الأهمية: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هناك تساؤلات حول تأثيره على لغتنا وقيمنا. هل يمكن لهذه التقنيات أن تكون أداة لتعزيز هويتنا أم أنها خطر يهددها؟\",\n",
      "      \"tone_guidance\": \"نهدف إلى تقديم تحليل متوازن وعميق لهذا الموضوع.\"\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءًا لا يتجزأ من حياتنا اليومية، ولكن كيف يمكننا ضمان أنه يخدم هويتنا العربية؟\",\n",
      "      \"guest_welcome\": \"يسعدني أن أرحب اليوم بالدكتور سامي الحسن، الذي سيشاركنا بخبراته حول هذا الموضوع.\",\n",
      "      \"guest_bio_highlight\": \"الدكتور سامي الحسن هو أستاذ جامعي وخبير في تطبيقات الذكاء الاصطناعي، وله أبحاث عديدة تركز على التأثير الثقافي لهذه التكنولوجيا.\",\n",
      "      \"transition_to_discussion\": \"لنبدأ النقاش حول كيف يمكننا الموازنة بين التقدم التكنولوجي والحفاظ على هويتنا.\"\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"تأثير تدريب نماذج الذكاء الاصطناعي على بيانات غربية\",\n",
      "        \"personal_angle\": \"د. سامي: هذه النماذج قد تكون محدودة في فهم السياق الثقافي العربي، مما يؤثر على جودة النتائج.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"مبادرات عربية لتطوير نماذج ذكاء اصطناعي محلية\",\n",
      "        \"personal_angle\": \"ليلى: الإمارات والسعودية تعملان على نماذج مثل 'جايس' و'الحوراء'. هل تعتقد أن هذه المبادرات كافية؟\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"كيفية استخدام الذكاء الاصطناعي لتعزيز الثقافة العربية\",\n",
      "        \"personal_angle\": \"د. سامي: يمكننا استخدام الذكاء الاصطناعي لإنشاء محتوى عربي غني وتعزيز اللغة العربية في العالم الرقمي.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"التقنيات الحديثة تحمل إمكانيات كبيرة، ولكن علينا استخدامها بحذر لضمان حماية هويتنا.\",\n",
      "        \"guest_final_message\": \"نحتاج إلى تعاون بين الحكومات والمؤسسات الأكاديمية لتطوير حلول تقنية تخدم ثقافتنا وقيمنا.\",\n",
      "        \"host_closing_thoughts\": \"الحفاظ على الهوية العربية في العصر الرقمي يتطلب وعيًا وجهودًا مستمرة.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكرًا جزيلاً لك د. سامي على مشاركتك القيمة معنا اليوم.\",\n",
      "        \"audience_thanks\": \"شكرًا لكم مستمعينا على انضمامكم إلينا في هذه الحلقة.\",\n",
      "        \"call_to_action\": \"لا تنسوا مشاركة آرائكم حول هذا الموضوع على منصاتنا الاجتماعية.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة!\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من عرف قدر نفسه لم يهينه.\",\n",
      "      \"الثقافة هي الجسر بين الماضي والمستقبل.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"مبادرة مكتبة دبي الرقمية لتعزيز المحتوى العربي.\",\n",
      "      \"تجربة السعودية في تطوير الذكاء الاصطناعي لخدمة اللغة العربية.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي ومناسب لنقاش تحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام مصطلحات تقنية باللغة العربية الفصحى.\",\n",
      "    \"vocabulary_richness\": \"مفردات تعكس أهمية الموضوع وتناسب الجمهور المثقف.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"توزيع النقاط بحيث تُناقش كل نقطة في حوالي 3 دقائق.\",\n",
      "    \"pause_points\": \"التوقف بعد كل نقطة رئيسية للسماح بالتفاعل أو التفكير.\",\n",
      "    \"emphasis_moments\": \"التأكيد على دور الذكاء الاصطناعي في تعزيز الهوية الثقافية.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "generator = ConversationStructureGenerator(deployment, \"gpt-4o\")\n",
    "outline_result = generator.generate_conversation_structure(topic, information, classification_result, persona_result)\n",
    "print(outline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cece3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueContentEnhancer:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def enhance_dialogue_content(self, topic, information, classification_result, personas_result, structure_result):\n",
    "        \"\"\"\n",
    "        Step 4: Enhance conversation structure with rich dialogue content\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            structure_result: JSON string from Step 3 conversation structure\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced structure with rich dialogue content (V1 style)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "            structure = json.loads(structure_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        cultural_sensitivity = classification.get(\"cultural_sensitivity_level\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in enriching conversations with natural dialogue content for Arabic podcasts.\n",
    "\n",
    "Task: Add rich dialogue content to the existing structure to make it ready for script generation.\n",
    "\n",
    "Topic: {topic}\n",
    "Information: {information}\n",
    "\n",
    "Context:\n",
    "- Category: {primary_category}\n",
    "- Style: {optimal_style}\n",
    "- Cultural Sensitivity: {cultural_sensitivity}\n",
    "\n",
    "Characters:\n",
    "- Host: {host_name} - {host.get('personality', '')}\n",
    "- Guest: {guest_name} - {guest.get('expertise', '')}\n",
    "\n",
    "Current Structure:\n",
    "{structure_result}\n",
    "\n",
    "Add the following elements to the existing structure and return the complete result:\n",
    "\n",
    "For intro1: Add\n",
    "- \"spontaneity_elements\": [list of specific spontaneous phrases]\n",
    "\n",
    "For intro2: Add  \n",
    "- \"cultural_connections\": [specific cultural connection to the topic]\n",
    "\n",
    "For each point in main_discussion: Add\n",
    "- \"spontaneous_triggers\": [spontaneous triggers related to the point]\n",
    "- \"disagreement_points\": \"potential points of disagreement\"\n",
    "- \"cultural_references\": [proverbs and cultural references]\n",
    "- \"natural_transitions\": \"natural transition to the next point\"\n",
    "- \"emotional_triggers\": \"emotional triggers\"\n",
    "\n",
    "Add new section:\n",
    "\"spontaneous_moments\": {{\n",
    "    \"natural_interruptions\": [natural interruption points],\n",
    "    \"emotional_reactions\": [emotional reactions],\n",
    "    \"personal_stories\": [personal stories based on character backgrounds],\n",
    "    \"humorous_moments\": [funny moments related to the topic]\n",
    "}},\n",
    "\n",
    "Add new section:\n",
    "\"personality_interactions\": {{\n",
    "    \"host_strengths\": \"{host_name}'s strengths in dialogue\",\n",
    "    \"guest_expertise\": \"{guest_name}'s areas of expertise\",\n",
    "    \"natural_chemistry\": \"how they interact naturally\",\n",
    "    \"tension_points\": \"healthy tension points\",\n",
    "    \"collaboration_moments\": \"moments of collaboration\"\n",
    "}}\n",
    "\n",
    "Important Requirements:\n",
    "- Keep all existing content from the basic structure\n",
    "- Only add the new content\n",
    "- Write actual content, not descriptions\n",
    "- Make every addition related to the topic: {topic}\n",
    "- Make content suitable for the style: {optimal_style}\n",
    "- Use character names ({host_name}, {guest_name})\n",
    "- Make content natural and dialogue-ready\n",
    "- All JSON values must be in Modern Standard Arabic (MSA)\n",
    "- JSON keys should be in English\n",
    "- Do not include ```json markers\n",
    "- Return complete enhanced JSON\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in enriching conversations with natural dialogue content. Style: {optimal_style}. Always provide JSON values in Modern Standard Arabic while keeping keys in English.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7  # Higher creativity for dialogue content\n",
    "        )\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(response.choices[0].message.content)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except:\n",
    "            # If parsing fails, return raw response\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def validate_enhanced_content(self, enhanced_json):\n",
    "        \"\"\"\n",
    "        Validate the enhanced dialogue content\n",
    "        \"\"\"\n",
    "        required_new_elements = [\"spontaneous_moments\", \"personality_interactions\"]\n",
    "        \n",
    "        # Elements that should be added to existing sections\n",
    "        intro1_should_have = [\"spontaneity_elements\"]\n",
    "        intro2_should_have = [\"cultural_connections\"]\n",
    "        main_discussion_should_have = [\"spontaneous_triggers\", \"cultural_references\", \"disagreement_points\"]\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            enhanced = json.loads(enhanced_json)\n",
    "            \n",
    "            missing_elements = []\n",
    "            \n",
    "            # Check new sections\n",
    "            for element in required_new_elements:\n",
    "                if element not in enhanced:\n",
    "                    missing_elements.append(element)\n",
    "            \n",
    "            # Check enhanced intro1\n",
    "            conv_flow = enhanced.get(\"conversation_flow\", {})\n",
    "            intro1 = conv_flow.get(\"intro1\", {})\n",
    "            for element in intro1_should_have:\n",
    "                if element not in intro1:\n",
    "                    missing_elements.append(f\"intro1.{element}\")\n",
    "            \n",
    "            # Check enhanced intro2\n",
    "            intro2 = conv_flow.get(\"intro2\", {})\n",
    "            for element in intro2_should_have:\n",
    "                if element not in intro2:\n",
    "                    missing_elements.append(f\"intro2.{element}\")\n",
    "            \n",
    "            # Check enhanced main discussion\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            for i, point in enumerate(main_disc):\n",
    "                for element in main_discussion_should_have:\n",
    "                    if element not in point:\n",
    "                        missing_elements.append(f\"main_discussion[{i}].{element}\")\n",
    "            \n",
    "            if missing_elements:\n",
    "                return False, f\"Missing enhanced elements: {missing_elements}\"\n",
    "            \n",
    "            return True, \"Dialogue content enhancement validation successful\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_enhancement_quality(self, enhanced_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality of dialogue content enhancement\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            enhanced = json.loads(enhanced_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check spontaneous moments\n",
    "            spont_moments = enhanced.get(\"spontaneous_moments\", {})\n",
    "            analysis[\"has_interruptions\"] = len(spont_moments.get(\"natural_interruptions\", [])) >= 2\n",
    "            analysis[\"has_personal_stories\"] = len(spont_moments.get(\"personal_stories\", [])) >= 2\n",
    "            analysis[\"has_humor\"] = len(spont_moments.get(\"humorous_moments\", [])) >= 1\n",
    "            \n",
    "            # Check personality interactions\n",
    "            personality = enhanced.get(\"personality_interactions\", {})\n",
    "            analysis[\"has_chemistry\"] = bool(personality.get(\"natural_chemistry\"))\n",
    "            analysis[\"has_host_strengths\"] = bool(personality.get(\"host_strengths\"))\n",
    "            analysis[\"has_guest_expertise\"] = bool(personality.get(\"guest_expertise\"))\n",
    "            \n",
    "            # Check main discussion enhancement\n",
    "            conv_flow = enhanced.get(\"conversation_flow\", {})\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            \n",
    "            enhanced_points = 0\n",
    "            for point in main_disc:\n",
    "                if (point.get(\"spontaneous_triggers\") and \n",
    "                    point.get(\"cultural_references\") and \n",
    "                    point.get(\"disagreement_points\")):\n",
    "                    enhanced_points += 1\n",
    "            \n",
    "            analysis[\"enhanced_discussion_points\"] = enhanced_points\n",
    "            analysis[\"all_points_enhanced\"] = enhanced_points == len(main_disc)\n",
    "            \n",
    "            # Overall readiness for script generation\n",
    "            readiness_indicators = [\n",
    "                analysis[\"has_interruptions\"],\n",
    "                analysis[\"has_personal_stories\"],\n",
    "                analysis[\"has_chemistry\"],\n",
    "                analysis[\"has_host_strengths\"],\n",
    "                analysis[\"all_points_enhanced\"]\n",
    "            ]\n",
    "            analysis[\"readiness_score\"] = sum(readiness_indicators)\n",
    "            analysis[\"ready_for_script_generation\"] = analysis[\"readiness_score\"] >= 4\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze enhancement quality\"}\n",
    "\n",
    "# Usage:\n",
    "# enhancer = DialogueContentEnhancer(deployment, \"Fanar\")\n",
    "# enhanced_result = enhancer.enhance_dialogue_content(topic, information, classification_result, personas_result, structure_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07febcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"ليلى أحمد\",\n",
      "      \"background\": \"صحفية ومقدمة برامج ثقافية مهتمة بالتكنولوجيا والهوية العربية.\",\n",
      "      \"speaking_style\": \"تتحدث بطريقة تحليلية واضحة وتطرح أسئلة ذكية.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. سامي الحسن\",\n",
      "      \"background\": \"أستاذ جامعي وخبير في الذكاء الاصطناعي وتطبيقاته في العالم العربي.\",\n",
      "      \"speaking_style\": \"يشرح الأفكار بطريقة علمية مبسطة وموجهة للجمهور.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحبًا بكم في حلقة جديدة من بودكاستنا حيث نناقش القضايا التي تؤثر على ثقافتنا وهويتنا.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع في غاية الأهمية: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هناك تساؤلات حول تأثيره على لغتنا وقيمنا. هل يمكن لهذه التقنيات أن تكون أداة لتعزيز هويتنا أم أنها خطر يهددها؟\",\n",
      "      \"tone_guidance\": \"نهدف إلى تقديم تحليل متوازن وعميق لهذا الموضوع.\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"كلنا نلاحظ كيف أصبح الذكاء الاصطناعي جزءًا من حياتنا اليومية، أليس كذلك؟\",\n",
      "        \"شخصيًا، أتساءل دائمًا عن تأثير هذه التقنيات على مستقبل اللغة العربية.\",\n",
      "        \"هل تعتقدون أن التكنولوجيا يمكن أن تُصبح حليفًا للثقافة؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءًا لا يتجزأ من حياتنا اليومية، ولكن كيف يمكننا ضمان أنه يخدم هويتنا العربية؟\",\n",
      "      \"guest_welcome\": \"يسعدني أن أرحب اليوم بالدكتور سامي الحسن، الذي سيشاركنا بخبراته حول هذا الموضوع.\",\n",
      "      \"guest_bio_highlight\": \"الدكتور سامي الحسن هو أستاذ جامعي وخبير في تطبيقات الذكاء الاصطناعي، وله أبحاث عديدة تركز على التأثير الثقافي لهذه التكنولوجيا.\",\n",
      "      \"transition_to_discussion\": \"لنبدأ النقاش حول كيف يمكننا الموازنة بين التقدم التكنولوجي والحفاظ على هويتنا.\",\n",
      "      \"cultural_connections\": [\n",
      "        \"هل تعلم أن تاريخ اللغة العربية كان دائمًا مرتبطًا بالتكنولوجيا؟ من المطبعة إلى البرمجيات الحديثة، هناك دائمًا جهود للحفاظ على اللغة.\",\n",
      "        \"في العصر العباسي، كان هناك اهتمام كبير بالترجمة والتكنولوجيا؛ ربما يمكننا أن نستلهم من تلك التجارب.\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"تأثير تدريب نماذج الذكاء الاصطناعي على بيانات غربية\",\n",
      "        \"personal_angle\": \"د. سامي: هذه النماذج قد تكون محدودة في فهم السياق الثقافي العربي، مما يؤثر على جودة النتائج.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ليلى: هل سبق أن واجهت موقفًا شعرت فيه أن إحدى هذه النماذج لم تفهم السياق العربي جيدًا؟\",\n",
      "          \"د. سامي: بالفعل، كان هناك تجربة مع ترجمة نصوص عربية، وكانت النتائج مضللة.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكننا حقًا الاعتماد فقط على البيانات المحلية لتطوير نماذج فعالة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"مثلما يقول المثل: 'من عرف قدر نفسه لم يهينه'، يمكننا العمل على تعزيز ثقافتنا من خلال التكنولوجيا.\",\n",
      "          \"تجربة مكتبة دبي الرقمية هي مثال على جهود جيدة لتعزيز المحتوى العربي.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"لننتقل الآن إلى الحديث عن الجهود المبذولة لتطوير نماذج ذكاء اصطناعي محلية.\",\n",
      "        \"emotional_triggers\": \"الشعور بالإحباط عندما لا تُفهم الثقافة العربية بشكل صحيح في التطبيقات.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"مبادرات عربية لتطوير نماذج ذكاء اصطناعي محلية\",\n",
      "        \"personal_angle\": \"ليلى: الإمارات والسعودية تعملان على نماذج مثل 'جايس' و'الحوراء'. هل تعتقد أن هذه المبادرات كافية؟\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ليلى: هل تعتقد أن هذه المبادرات يمكنها أن تنافس النماذج الغربية؟\",\n",
      "          \"د. سامي: بالتأكيد، إذا حصلت على الدعم الكافي والبيانات المناسبة.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"بعض النقاد يرون أن هذه المبادرات قد تكون محدودة إذا لم تتوسع لتشمل تعاونًا إقليميًا أوسع.\",\n",
      "        \"cultural_references\": [\n",
      "          \"تجربة السعودية في تطوير الذكاء الاصطناعي لخدمة اللغة العربية تُظهر كيف يمكن للتكنولوجيا أن تخدم الثقافة.\",\n",
      "          \"كما يقول المثل: 'الثقافة هي الجسر بين الماضي والمستقبل'.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"هذا يقودنا إلى النقاش الأهم حول كيفية استخدام هذه التكنولوجيا لتعزيز الثقافة العربية.\",\n",
      "        \"emotional_triggers\": \"الفخر بالمبادرات العربية وجهودها للنهوض بالتكنولوجيا.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"كيفية استخدام الذكاء الاصطناعي لتعزيز الثقافة العربية\",\n",
      "        \"personal_angle\": \"د. سامي: يمكننا استخدام الذكاء الاصطناعي لإنشاء محتوى عربي غني وتعزيز اللغة العربية في العالم الرقمي.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ليلى: هل يمكن للذكاء الاصطناعي أن يساعد في تعليم اللغة العربية للجيل الجديد؟\",\n",
      "          \"د. سامي: بالتأكيد، يمكن تطوير تطبيقات تعليمية مبتكرة.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكن أن يكون هناك خطر من الاعتماد المفرط على التكنولوجيا في الحفاظ على الثقافة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"مبادرة مكتبة دبي الرقمية تقدم نموذجًا عمليًا للاستخدام الثقافي للتكنولوجيا.\",\n",
      "          \"كما يقول المثل: 'من عرف قدر نفسه لم يهينه'.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"لنختتم هذا النقاش بتسليط الضوء على أهمية التعاون بين الحكومات والمؤسسات لتحقيق هذه الأهداف.\",\n",
      "        \"emotional_triggers\": \"الأمل بأن التكنولوجيا يمكن أن تُصبح أداة قوية لخدمة الثقافة.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"التقنيات الحديثة تحمل إمكانيات كبيرة، ولكن علينا استخدامها بحذر لضمان حماية هويتنا.\",\n",
      "        \"guest_final_message\": \"نحتاج إلى تعاون بين الحكومات والمؤسسات الأكاديمية لتطوير حلول تقنية تخدم ثقافتنا وقيمنا.\",\n",
      "        \"host_closing_thoughts\": \"الحفاظ على الهوية العربية في العصر الرقمي يتطلب وعيًا وجهودًا مستمرة.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكرًا جزيلاً لك د. سامي على مشاركتك القيمة معنا اليوم.\",\n",
      "        \"audience_thanks\": \"شكرًا لكم مستمعينا على انضمامكم إلينا في هذه الحلقة.\",\n",
      "        \"call_to_action\": \"لا تنسوا مشاركة آرائكم حول هذا الموضوع على منصاتنا الاجتماعية.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة!\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"natural_interruptions\": [\n",
      "      \"ليلى: عذرًا، لكن لدي سؤال سريع حول النقطة التي ذكرتها قبل قليل.\",\n",
      "      \"د. سامي: صحيح، ولكن دعيني أضيف شيئًا على هذه الفكرة.\"\n",
      "    ],\n",
      "    \"emotional_reactions\": [\n",
      "      \"ليلى: هذا فعلاً مثير للاهتمام! لم أفكر في ذلك من قبل.\",\n",
      "      \"د. سامي: أشعر بحماس كبير تجاه هذه المبادرات، فهي خطوة عظيمة.\"\n",
      "    ],\n",
      "    \"personal_stories\": [\n",
      "      \"ليلى: شخصيًا، أذكر عندما كنت أبحث عن محتوى عربي عالي الجودة، كان الأمر صعبًا للغاية.\",\n",
      "      \"د. سامي: في أحد مشاريعي، واجهت تحديًا في إيجاد بيانات عربية متنوعة لتطوير النموذج.\"\n",
      "    ],\n",
      "    \"humorous_moments\": [\n",
      "      \"ليلى: أتساءل، هل يمكن للذكاء الاصطناعي أن يصنع لنا أمثال عربية جديدة؟\",\n",
      "      \"د. سامي: ربما، لكن لا أعتقد أنه سيُنافس أمثال جداتنا!\"\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"host_strengths\": \"قدرة ليلى أحمد على طرح أسئلة تحليلية تحفز النقاش وتجعل الحلقة أكثر تفاعلًا.\",\n",
      "    \"guest_expertise\": \"خبرة د. سامي الحسن في تطوير نماذج الذكاء الاصطناعي وتقديم أفكار علمية مبسطة للجمهور.\",\n",
      "    \"natural_chemistry\": \"تفاعل طبيعي بين ليلى ود. سامي، حيث يضيف كل منهما وجهة نظر مختلفة ولكن متكاملة.\",\n",
      "    \"tension_points\": \"اختلاف وجهات النظر حول مدى كفاية المبادرات العربية لمواجهة النماذج الغربية.\",\n",
      "    \"collaboration_moments\": \"اتفاقهما على أهمية التعاون بين الحكومات والمؤسسات الأكاديمية لتعزيز الهوية الثقافية.\"\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من عرف قدر نفسه لم يهينه.\",\n",
      "      \"الثقافة هي الجسر بين الماضي والمستقبل.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"مبادرة مكتبة دبي الرقمية لتعزيز المحتوى العربي.\",\n",
      "      \"تجربة السعودية في تطوير الذكاء الاصطناعي لخدمة اللغة العربية.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي ومناسب لنقاش تحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام مصطلحات تقنية باللغة العربية الفصحى.\",\n",
      "    \"vocabulary_richness\": \"مفردات تعكس أهمية الموضوع وتناسب الجمهور المثقف.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"توزيع النقاط بحيث تُناقش كل نقطة في حوالي 3 دقائق.\",\n",
      "    \"pause_points\": \"التوقف بعد كل نقطة رئيسية للسماح بالتفاعل أو التفكير.\",\n",
      "    \"emphasis_moments\": \"التأكيد على دور الذكاء الاصطناعي في تعزيز الهوية الثقافية.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "style_enhancer = DialogueContentEnhancer(deployment, \"gpt-4o\")\n",
    "style_enhanced_result = style_enhancer.enhance_dialogue_content(topic, information, classification_result, persona_result, outline_result)\n",
    "print(style_enhanced_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79cd062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalPolishEnhancer:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def add_final_polish(self, topic, information, classification_result, personas_result, enhanced_content_result):\n",
    "        \"\"\"\n",
    "        Step 5: Add final polish and spontaneity for natural flow\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            enhanced_content_result: JSON string from Step 4 enhanced content\n",
    "            \n",
    "        Returns:\n",
    "            Final V1-style outline with complete natural flow elements\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "            enhanced_content = json.loads(enhanced_content_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        cultural_sensitivity = classification.get(\"cultural_sensitivity_level\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in adding final touches to conversations to make them completely natural and spontaneous.\n",
    "\n",
    "Task: Add final touches and natural flow to the enhanced content.\n",
    "\n",
    "Topic: {topic}\n",
    "Information: {information}\n",
    "\n",
    "Context:\n",
    "- Category: {primary_category}\n",
    "- Style: {optimal_style}\n",
    "- Cultural Sensitivity: {cultural_sensitivity}\n",
    "\n",
    "Characters:\n",
    "- Host: {host_name} - {host.get('speaking_style', '')}\n",
    "- Guest: {guest_name} - {guest.get('speaking_style', '')}\n",
    "\n",
    "Current Enhanced Content:\n",
    "{enhanced_content_result}\n",
    "\n",
    "Add the following final improvements:\n",
    "\n",
    "1. Enhance \"spontaneous_moments\" by adding more details:\n",
    "   - Add more specific \"natural_interruptions\"\n",
    "   - Add more realistic \"emotional_reactions\"\n",
    "   - Add more \"personal_stories\" suitable for the characters\n",
    "   - Add more \"humorous_moments\" related to the topic\n",
    "\n",
    "2. Enhance \"personality_interactions\" with more details:\n",
    "   - Make \"natural_chemistry\" more specific\n",
    "   - Add details to \"tension_points\"\n",
    "   - Make \"collaboration_moments\" clearer\n",
    "\n",
    "3. Add new section \"shared_experiences\":\n",
    "   {{\n",
    "       \"common_ground\": [\n",
    "           \"similarities between host and guest\",\n",
    "           \"shared experiences they can discuss\"\n",
    "       ],\n",
    "       \"generational_perspectives\": [\n",
    "           \"generational differences that may appear in discussion\",\n",
    "           \"different viewpoints based on age and experience\"\n",
    "       ]\n",
    "   }}\n",
    "\n",
    "4. Add new section \"contemporary_relevance\":\n",
    "   {{\n",
    "       \"current_events\": [\n",
    "           \"current events related to the topic\",\n",
    "           \"recent developments in the field\"\n",
    "       ],\n",
    "       \"future_implications\": [\n",
    "           \"future implications of the topic\",\n",
    "           \"what can be expected in coming years\"\n",
    "       ]\n",
    "   }}\n",
    "\n",
    "5. Enhance \"cultural_context\" sections with more details:\n",
    "   - Add more \"proverbs_sayings\"\n",
    "   - Add more \"regional_references\"\n",
    "   - Make \"shared_experiences\" more specific\n",
    "\n",
    "Final Requirements:\n",
    "- Keep all existing content from Step 4\n",
    "- Only add the final improvements\n",
    "- Write specific content, not general\n",
    "- Make every addition related to the topic: {topic}\n",
    "- Make characters seem real and interactive\n",
    "- Use character names ({host_name}, {guest_name})\n",
    "- Make flow extremely natural\n",
    "- All JSON values must be in Modern Standard Arabic (MSA)\n",
    "- JSON keys should be in English\n",
    "- Do not include ```json markers\n",
    "- Return complete final JSON\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in adding final touches to natural conversations. Style: {optimal_style}. Always provide JSON values in Modern Standard Arabic while keeping keys in English.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8  # High creativity for final spontaneity\n",
    "        )\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(response.choices[0].message.content)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except:\n",
    "            # If parsing fails, return raw response\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def validate_final_outline(self, final_json):\n",
    "        \"\"\"\n",
    "        Validate the final polished outline\n",
    "        \"\"\"\n",
    "        required_new_elements = [\"shared_experiences\", \"contemporary_relevance\"]\n",
    "        \n",
    "        # Enhanced elements that should be richer\n",
    "        enhanced_elements = {\n",
    "            \"spontaneous_moments\": [\"natural_interruptions\", \"emotional_reactions\", \"personal_stories\", \"humorous_moments\"],\n",
    "            \"personality_interactions\": [\"natural_chemistry\", \"tension_points\", \"collaboration_moments\"]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            final_outline = json.loads(final_json)\n",
    "            \n",
    "            missing_elements = []\n",
    "            \n",
    "            # Check new sections\n",
    "            for element in required_new_elements:\n",
    "                if element not in final_outline:\n",
    "                    missing_elements.append(element)\n",
    "            \n",
    "            # Check enhanced spontaneous moments\n",
    "            spont_moments = final_outline.get(\"spontaneous_moments\", {})\n",
    "            for element in enhanced_elements[\"spontaneous_moments\"]:\n",
    "                if element not in spont_moments:\n",
    "                    missing_elements.append(f\"spontaneous_moments.{element}\")\n",
    "                elif len(spont_moments.get(element, [])) < 2:\n",
    "                    missing_elements.append(f\"spontaneous_moments.{element} (needs at least 2 items)\")\n",
    "            \n",
    "            # Check enhanced personality interactions\n",
    "            personality = final_outline.get(\"personality_interactions\", {})\n",
    "            for element in enhanced_elements[\"personality_interactions\"]:\n",
    "                if element not in personality:\n",
    "                    missing_elements.append(f\"personality_interactions.{element}\")\n",
    "            \n",
    "            if missing_elements:\n",
    "                return False, f\"Missing final elements: {missing_elements}\"\n",
    "            \n",
    "            return True, \"Final outline validation successful - ready for V1 script generation\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_final_quality(self, final_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality and completeness of the final outline\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            final_outline = json.loads(final_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check V1 compatibility\n",
    "            required_v1_sections = [\"episode_topic\", \"personas\", \"conversation_flow\", \"spontaneous_moments\", \"personality_interactions\"]\n",
    "            analysis[\"v1_compatible\"] = all(section in final_outline for section in required_v1_sections)\n",
    "            \n",
    "            # Check conversation flow completeness\n",
    "            conv_flow = final_outline.get(\"conversation_flow\", {})\n",
    "            analysis[\"has_complete_flow\"] = all(section in conv_flow for section in [\"intro1\", \"intro2\", \"main_discussion\", \"closing\"])\n",
    "            \n",
    "            # Check spontaneous moments richness\n",
    "            spont_moments = final_outline.get(\"spontaneous_moments\", {})\n",
    "            spont_count = sum(len(spont_moments.get(key, [])) for key in [\"natural_interruptions\", \"personal_stories\", \"humorous_moments\"])\n",
    "            analysis[\"spontaneous_richness\"] = spont_count\n",
    "            analysis[\"adequate_spontaneity\"] = spont_count >= 6\n",
    "            \n",
    "            # Check cultural integration depth\n",
    "            cultural = final_outline.get(\"cultural_context\", {})\n",
    "            cultural_count = sum(len(cultural.get(key, [])) for key in [\"proverbs_sayings\", \"regional_references\", \"shared_experiences\"])\n",
    "            analysis[\"cultural_depth\"] = cultural_count\n",
    "            analysis[\"adequate_culture\"] = cultural_count >= 4\n",
    "            \n",
    "            # Check main discussion enhancement\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            enhanced_points = sum(1 for point in main_disc if all(key in point for key in [\"spontaneous_triggers\", \"cultural_references\", \"disagreement_points\"]))\n",
    "            analysis[\"enhanced_discussion_points\"] = enhanced_points\n",
    "            analysis[\"all_discussions_enhanced\"] = enhanced_points == len(main_disc)\n",
    "            \n",
    "            # Overall V1 readiness score\n",
    "            v1_readiness_indicators = [\n",
    "                analysis[\"v1_compatible\"],\n",
    "                analysis[\"has_complete_flow\"],\n",
    "                analysis[\"adequate_spontaneity\"],\n",
    "                analysis[\"adequate_culture\"],\n",
    "                analysis[\"all_discussions_enhanced\"]\n",
    "            ]\n",
    "            analysis[\"v1_readiness_score\"] = sum(v1_readiness_indicators)\n",
    "            analysis[\"ready_for_v1_script_generation\"] = analysis[\"v1_readiness_score\"] >= 4\n",
    "            analysis[\"perfect_v1_outline\"] = analysis[\"v1_readiness_score\"] == 5\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze final quality\"}\n",
    "\n",
    "    def create_v1_summary(self, final_json):\n",
    "        \"\"\"\n",
    "        Create a summary showing V1 compatibility\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            final_outline = json.loads(final_json)\n",
    "            \n",
    "            summary = {}\n",
    "            \n",
    "            # Extract key V1 elements\n",
    "            conv_flow = final_outline.get(\"conversation_flow\", {})\n",
    "            summary[\"intro1_ready\"] = bool(conv_flow.get(\"intro1\", {}).get(\"opening_line\"))\n",
    "            summary[\"main_points_count\"] = len(conv_flow.get(\"main_discussion\", []))\n",
    "            summary[\"spontaneous_elements\"] = len(final_outline.get(\"spontaneous_moments\", {}).get(\"natural_interruptions\", []))\n",
    "            summary[\"cultural_references\"] = len(final_outline.get(\"cultural_context\", {}).get(\"proverbs_sayings\", []))\n",
    "            summary[\"personality_defined\"] = bool(final_outline.get(\"personality_interactions\", {}).get(\"natural_chemistry\"))\n",
    "            \n",
    "            # V1 script generation readiness\n",
    "            summary[\"v1_script_ready\"] = all([\n",
    "                summary[\"intro1_ready\"],\n",
    "                summary[\"main_points_count\"] >= 3,\n",
    "                summary[\"spontaneous_elements\"] >= 2,\n",
    "                summary[\"personality_defined\"]\n",
    "            ])\n",
    "            \n",
    "            return summary\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not create V1 summary\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7fa49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"ليلى أحمد\",\n",
      "      \"background\": \"صحفية ومقدمة برامج ثقافية مهتمة بالتكنولوجيا والهوية العربية.\",\n",
      "      \"speaking_style\": \"تتحدث بطريقة تحليلية واضحة وتطرح أسئلة ذكية.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. سامي الحسن\",\n",
      "      \"background\": \"أستاذ جامعي وخبير في الذكاء الاصطناعي وتطبيقاته في العالم العربي.\",\n",
      "      \"speaking_style\": \"يشرح الأفكار بطريقة علمية مبسطة وموجهة للجمهور.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحبًا بكم في حلقة جديدة من بودكاستنا حيث نناقش القضايا التي تؤثر على ثقافتنا وهويتنا.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع في غاية الأهمية: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هناك تساؤلات حول تأثيره على لغتنا وقيمنا. هل يمكن لهذه التقنيات أن تكون أداة لتعزيز هويتنا أم أنها خطر يهددها؟\",\n",
      "      \"tone_guidance\": \"نهدف إلى تقديم تحليل متوازن وعميق لهذا الموضوع.\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"كلنا نلاحظ كيف أصبح الذكاء الاصطناعي جزءًا من حياتنا اليومية، أليس كذلك؟\",\n",
      "        \"شخصيًا، أتساءل دائمًا عن تأثير هذه التقنيات على مستقبل اللغة العربية.\",\n",
      "        \"هل تعتقدون أن التكنولوجيا يمكن أن تُصبح حليفًا للثقافة؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءًا لا يتجزأ من حياتنا اليومية، ولكن كيف يمكننا ضمان أنه يخدم هويتنا العربية؟\",\n",
      "      \"guest_welcome\": \"يسعدني أن أرحب اليوم بالدكتور سامي الحسن، الذي سيشاركنا بخبراته حول هذا الموضوع.\",\n",
      "      \"guest_bio_highlight\": \"الدكتور سامي الحسن هو أستاذ جامعي وخبير في تطبيقات الذكاء الاصطناعي، وله أبحاث عديدة تركز على التأثير الثقافي لهذه التكنولوجيا.\",\n",
      "      \"transition_to_discussion\": \"لنبدأ النقاش حول كيف يمكننا الموازنة بين التقدم التكنولوجي والحفاظ على هويتنا.\",\n",
      "      \"cultural_connections\": [\n",
      "        \"هل تعلم أن تاريخ اللغة العربية كان دائمًا مرتبطًا بالتكنولوجيا؟ من المطبعة إلى البرمجيات الحديثة، هناك دائمًا جهود للحفاظ على اللغة.\",\n",
      "        \"في العصر العباسي، كان هناك اهتمام كبير بالترجمة والتكنولوجيا؛ ربما يمكننا أن نستلهم من تلك التجارب.\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"تأثير تدريب نماذج الذكاء الاصطناعي على بيانات غربية\",\n",
      "        \"personal_angle\": \"د. سامي: هذه النماذج قد تكون محدودة في فهم السياق الثقافي العربي، مما يؤثر على جودة النتائج.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ليلى: هل سبق أن واجهت موقفًا شعرت فيه أن إحدى هذه النماذج لم تفهم السياق العربي جيدًا؟\",\n",
      "          \"د. سامي: بالفعل، كان هناك تجربة مع ترجمة نصوص عربية، وكانت النتائج مضللة.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكننا حقًا الاعتماد فقط على البيانات المحلية لتطوير نماذج فعالة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"مثلما يقول المثل: 'من عرف قدر نفسه لم يهينه'، يمكننا العمل على تعزيز ثقافتنا من خلال التكنولوجيا.\",\n",
      "          \"تجربة مكتبة دبي الرقمية هي مثال على جهود جيدة لتعزيز المحتوى العربي.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"لننتقل الآن إلى الحديث عن الجهود المبذولة لتطوير نماذج ذكاء اصطناعي محلية.\",\n",
      "        \"emotional_triggers\": \"الشعور بالإحباط عندما لا تُفهم الثقافة العربية بشكل صحيح في التطبيقات.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"مبادرات عربية لتطوير نماذج ذكاء اصطناعي محلية\",\n",
      "        \"personal_angle\": \"ليلى: الإمارات والسعودية تعملان على نماذج مثل 'جايس' و'الحوراء'. هل تعتقد أن هذه المبادرات كافية؟\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ليلى: هل تعتقد أن هذه المبادرات يمكنها أن تنافس النماذج الغربية؟\",\n",
      "          \"د. سامي: بالتأكيد، إذا حصلت على الدعم الكافي والبيانات المناسبة.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"بعض النقاد يرون أن هذه المبادرات قد تكون محدودة إذا لم تتوسع لتشمل تعاونًا إقليميًا أوسع.\",\n",
      "        \"cultural_references\": [\n",
      "          \"تجربة السعودية في تطوير الذكاء الاصطناعي لخدمة اللغة العربية تُظهر كيف يمكن للتكنولوجيا أن تخدم الثقافة.\",\n",
      "          \"كما يقول المثل: 'الثقافة هي الجسر بين الماضي والمستقبل'.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"هذا يقودنا إلى النقاش الأهم حول كيفية استخدام هذه التكنولوجيا لتعزيز الثقافة العربية.\",\n",
      "        \"emotional_triggers\": \"الفخر بالمبادرات العربية وجهودها للنهوض بالتكنولوجيا.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"كيفية استخدام الذكاء الاصطناعي لتعزيز الثقافة العربية\",\n",
      "        \"personal_angle\": \"د. سامي: يمكننا استخدام الذكاء الاصطناعي لإنشاء محتوى عربي غني وتعزيز اللغة العربية في العالم الرقمي.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"ليلى: هل يمكن للذكاء الاصطناعي أن يساعد في تعليم اللغة العربية للجيل الجديد؟\",\n",
      "          \"د. سامي: بالتأكيد، يمكن تطوير تطبيقات تعليمية مبتكرة.\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكن أن يكون هناك خطر من الاعتماد المفرط على التكنولوجيا في الحفاظ على الثقافة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"مبادرة مكتبة دبي الرقمية تقدم نموذجًا عمليًا للاستخدام الثقافي للتكنولوجيا.\",\n",
      "          \"كما يقول المثل: 'من عرف قدر نفسه لم يهينه'.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"لنختتم هذا النقاش بتسليط الضوء على أهمية التعاون بين الحكومات والمؤسسات لتحقيق هذه الأهداف.\",\n",
      "        \"emotional_triggers\": \"الأمل بأن التكنولوجيا يمكن أن تُصبح أداة قوية لخدمة الثقافة.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"التقنيات الحديثة تحمل إمكانيات كبيرة، ولكن علينا استخدامها بحذر لضمان حماية هويتنا.\",\n",
      "        \"guest_final_message\": \"نحتاج إلى تعاون بين الحكومات والمؤسسات الأكاديمية لتطوير حلول تقنية تخدم ثقافتنا وقيمنا.\",\n",
      "        \"host_closing_thoughts\": \"الحفاظ على الهوية العربية في العصر الرقمي يتطلب وعيًا وجهودًا مستمرة.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكرًا جزيلاً لك د. سامي على مشاركتك القيمة معنا اليوم.\",\n",
      "        \"audience_thanks\": \"شكرًا لكم مستمعينا على انضمامكم إلينا في هذه الحلقة.\",\n",
      "        \"call_to_action\": \"لا تنسوا مشاركة آرائكم حول هذا الموضوع على منصاتنا الاجتماعية.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة!\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"natural_interruptions\": [\n",
      "      \"ليلى: عذرًا، دكتور سامي، أريد أن أضيف نقطة مهمة تتعلق بتجربتي مع التطبيقات الرقمية.\",\n",
      "      \"د. سامي: صحيح، لكن هذا يذكرني بفكرة أخرى يمكن أن تكون ذات صلة مباشرة.\"\n",
      "    ],\n",
      "    \"emotional_reactions\": [\n",
      "      \"ليلى: هذا فعلاً مؤثر جدًا! نحن بحاجة إلى مزيد من الجهود في هذا المجال.\",\n",
      "      \"د. سامي: أشعر بالفخر بأننا نرى جهود عربية ملموسة في هذا الاتجاه.\"\n",
      "    ],\n",
      "    \"personal_stories\": [\n",
      "      \"ليلى: أتذكر عندما كنت أبحث عن محتوى عربي لتعليم طفل صغير، وقابلت تحديات كبيرة في العثور على مواد ملائمة.\",\n",
      "      \"د. سامي: في إحدى مشاريعي البحثية، اضطررت إلى إنشاء قاعدة بيانات عربية من الصفر بسبب نقص المحتوى الجاهز.\"\n",
      "    ],\n",
      "    \"humorous_moments\": [\n",
      "      \"ليلى: هل يمكن أن يُساعدنا الذكاء الاصطناعي في صنع أمثال عربية جديدة بطريقة إبداعية؟\",\n",
      "      \"د. سامي: ربما، لكنني أخشى أن تكون الأمثال مضحكة أكثر من كونها حكيمة!\"\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"host_strengths\": \"قدرة ليلى أحمد على طرح أسئلة تحليلية تحفز النقاش وتجعل الحلقة أكثر تفاعلًا.\",\n",
      "    \"guest_expertise\": \"خبرة د. سامي الحسن في تطوير نماذج الذكاء الاصطناعي وتقديم أفكار علمية مبسطة للجمهور.\",\n",
      "    \"natural_chemistry\": \"هناك انسجام واضح بين ليلى ود. سامي، حيث تكمل أسئلة ليلى التحليلية خبرة سامي العلمية، مما يجعل النقاش ممتعًا ومتوازنًا.\",\n",
      "    \"tension_points\": \"هناك اختلاف بسيط في وجهات النظر حول كيفية مواجهة التحديات التقنية؛ ليلى تعتقد أن الجهود الحالية تحتاج إلى تسريع، بينما يرى سامي أن استدامة المبادرات هي الأهم.\",\n",
      "    \"collaboration_moments\": \"اتفاقهما على أهمية تعزيز المحتوى العربي والتعاون بين الدول العربية لتطوير نماذج أكثر فعالية.\"\n",
      "  },\n",
      "  \"shared_experiences\": {\n",
      "    \"common_ground\": [\n",
      "      \"كلاهما يُظهر اهتمامًا شخصيًا بالحفاظ على الهوية الثقافية العربية.\",\n",
      "      \"تجربة مشتركة تتعلق بالصعوبات في إيجاد محتوى عربي عالي الجودة في التطبيقات الرقمية.\"\n",
      "    ],\n",
      "    \"generational_perspectives\": [\n",
      "      \"ليلى تتحدث من منظور الجيل الذي نشأ مع التكنولوجيا ولكنه يحاول حماية القيم التقليدية.\",\n",
      "      \"د. سامي يقدم منظورًا أكاديميًا ومهنيًا، يعكس خبرة متعددة السنوات في البحث والتطوير.\"\n",
      "    ]\n",
      "  },\n",
      "  \"contemporary_relevance\": {\n",
      "    \"current_events\": [\n",
      "      \"الإعلان الأخير عن شراكة بين السعودية والإمارات لتطوير محتوى عربي باستخدام الذكاء الاصطناعي.\",\n",
      "      \"زيادة الاهتمام العالمي بالمبادرات العربية، مثل مشروع 'الحوراء' في الذكاء الاصطناعي.\"\n",
      "    ],\n",
      "    \"future_implications\": [\n",
      "      \"توقع تطور تطبيقات تعليمية عربية مدعومة بالذكاء الاصطناعي في المدارس والجامعات.\",\n",
      "      \"إمكانية إنشاء نماذج عربية تنافسية عالميًا تزيد من انتشار اللغة والثقافة العربية.\"\n",
      "    ]\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من جد وجد ومن سار على الدرب وصل.\",\n",
      "      \"العلم نور والجهل ظلام.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"مشروع 'جايس' من الإمارات كنموذج للذكاء الاصطناعي المحلي.\",\n",
      "      \"تجربة جامعة الملك عبد الله للعلوم والتقنية في تطوير أدوات رقمية تخدم اللغة العربية.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي ومناسب لنقاش تحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام مصطلحات تقنية باللغة العربية الفصحى.\",\n",
      "    \"vocabulary_richness\": \"مفردات تعكس أهمية الموضوع وتناسب الجمهور المثقف.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"توزيع النقاط بحيث تُناقش كل نقطة في حوالي 3 دقائق.\",\n",
      "    \"pause_points\": \"التوقف بعد كل نقطة رئيسية للسماح بالتفاعل أو التفكير.\",\n",
      "    \"emphasis_moments\": \"التأكيد على دور الذكاء الاصطناعي في تعزيز الهوية الثقافية.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "polisher = FinalPolishEnhancer(deployment, \"gpt-4o\")\n",
    "final_outline = polisher.add_final_polish(topic, information, classification_result, persona_result, style_enhanced_result)\n",
    "print(final_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridScriptGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "        \n",
    "        # V1-style rich dialogue examples\n",
    "        self.arabic_dialogue_styles = {\n",
    "            \"حواري\": {\n",
    "                \"host_example\": \"أحمد: يا أهلاً نور! كيف الحال؟ اممم... قوليلي، شو اللي خلاكِ تدخلي هذا المجال؟ <happy>\",\n",
    "                \"guest_example\": \"نور: أهلاً أحمد! الله يعطيك العافية... يعني بصراحة، هاي قصة طويلة شوي [pause: 2s] بس باختصار، كنت أشوف المشاكل حولي وأقول: ليش ما نحلها بالتقنية؟\"\n",
    "            },\n",
    "            \"تعليمي\": {\n",
    "                \"host_example\": \"أحمد: اممم... نور، ممكن تشرحي لنا بطريقة بسيطة، يعني شلون تشتغل هاي التقنية؟ <happy>\",\n",
    "                \"guest_example\": \"نور: طبعاً أحمد! يعني... اههه كيف أشرح [pause: 2s] تخيل إنك عندك نظام ذكي جداً، بس هذا النظام مش إنسان، هو كمبيوتر! واو صح؟\"\n",
    "            },\n",
    "            \"ترفيهي\": {\n",
    "                \"host_example\": \"أحمد: هاي نور! <happy> قوليلي، إيش أغرب موقف صار معكِ في الشغل؟ يعني شي يضحك؟\",\n",
    "                \"guest_example\": \"نور: ههههه واو أحمد! بصراحة مواقف كثيرة... اممم مرة كنت أجرب البرنامج وفجأة [pause: 2s] خلاص ما عاد يشتغل! قعدت أصرخ: وين راح كودي؟! <surprise>\"\n",
    "            },\n",
    "            \"تحليلي\": {\n",
    "                \"host_example\": \"أحمد: نور، بناءً على الإحصائيات الحديثة، وش رايكِ في التحديات الرئيسية اللي تواجه هذا المجال؟\",\n",
    "                \"guest_example\": \"نور: سؤال ممتاز أحمد... يعني إذا نتكلم بشكل تحليلي، عندنا ثلاث تحديات أساسية [pause: 2s] أولها التقنية، ثانيها التمويل، وثالثها... اممم التقبل المجتمعي\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # V1-style comprehensive fillers guide\n",
    "        self.fillers_guide = \"\"\"\n",
    "Use natural conversation fillers with moderate density:\n",
    "- Thinking: اممم، اههه، يعني كيف أقول، خلاص، شوف\n",
    "- Confirmation: طبعاً، تماماً، بالضبط، صحيح، أكيد\n",
    "- Hesitation: يعنييييي، يعني، اه ما أدري، مش عارف\n",
    "- Emotion: واو، يا الله، ما شاء الله، الله يعطيك العافية\n",
    "- Connection: بس، لكن، وبعدين، يا أخي، اسمع، انتبه\n",
    "- Light Gulf dialect: شلون، وش رايك، زين، ماشي الحال، الله يعافيك\n",
    "\"\"\"\n",
    "\n",
    "    def generate_enhanced_intro(self, topic, final_outline_result, optimal_style):\n",
    "        \"\"\"\n",
    "        Step 1: Generate enhanced intro (intro1 + intro2) - V1 enhancer style\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract outline elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        intro1 = conv_flow.get(\"intro1\", {})\n",
    "        intro2 = conv_flow.get(\"intro2\", {})\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style examples\n",
    "        style_examples = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in writing natural and engaging Arabic podcast introductions.\n",
    "\n",
    "Task: Write a complete natural introduction (intro1 + intro2) that combines welcome, topic introduction, and guest introduction.\n",
    "\n",
    "Style examples required:\n",
    "Host: {style_examples[\"host_example\"]}\n",
    "Guest: {style_examples[\"guest_example\"]}\n",
    "\n",
    "Introduction elements from outline:\n",
    "Opening line: {intro1.get('opening_line', '')}\n",
    "Podcast introduction: {intro1.get('podcast_introduction', '')}\n",
    "Episode hook: {intro1.get('episode_hook', '')}\n",
    "Spontaneity elements: {intro1.get('spontaneity_elements', [])}\n",
    "\n",
    "Topic introduction: {intro2.get('topic_introduction', '')}\n",
    "Guest welcome: {intro2.get('guest_welcome', '')}\n",
    "Guest bio highlight: {intro2.get('guest_bio_highlight', '')}\n",
    "Cultural connections: {intro2.get('cultural_connections', [])}\n",
    "\n",
    "Available cultural references: {cultural_context.get('proverbs_sayings', [])}\n",
    "\n",
    "{self.fillers_guide}\n",
    "\n",
    "Introduction requirements:\n",
    "1. Start with host {host_name} speaking alone (intro1)\n",
    "2. Then bring guest {guest_name} into the conversation (intro2)\n",
    "3. Use 70% MSA and 30% light Gulf touches\n",
    "4. Add natural fillers with moderate density\n",
    "5. Naturally incorporate spontaneous and cultural elements\n",
    "6. Make smooth transition from host alone to dialogue with guest\n",
    "7. Use actual character names\n",
    "8. Add natural interactions: <happy>, <pause: 2s>, <overlap>\n",
    "9. Make introduction engaging with 2-3 minutes duration\n",
    "10. End with natural transition to main discussion\n",
    "11. Write all dialogue content in Modern Standard Arabic with light dialectal touches\n",
    "\n",
    "Dialogue format:\n",
    "المقدم: [text]\n",
    "الضيف: [text]\n",
    "\n",
    "Write the complete introduction:\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in writing natural and engaging Arabic podcast introductions. Style: {optimal_style}. Always write dialogue content in Modern Standard Arabic with light dialectal touches.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_flowing_main_discussion(self, topic, final_outline_result, optimal_style, intro_dialogue):\n",
    "        \"\"\"\n",
    "        Step 2: Generate flowing main discussion (all 3 points) - V1 dialogue generator style\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract outline elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        main_discussion = conv_flow.get(\"main_discussion\", [])\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        spontaneous_moments = outline.get(\"spontaneous_moments\", {})\n",
    "        personality_interactions = outline.get(\"personality_interactions\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style examples\n",
    "        style_examples = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        # Build main points summary\n",
    "        points_summary = \"\"\n",
    "        for i, point in enumerate(main_discussion):\n",
    "            points_summary += f\"\"\"\n",
    "Point {i+1}: {point.get('point_title', '')}\n",
    "- Personal angle: {point.get('personal_angle', '')}\n",
    "- Spontaneous triggers: {point.get('spontaneous_triggers', [])}\n",
    "- Disagreement points: {point.get('disagreement_points', '')}\n",
    "- Cultural references: {point.get('cultural_references', [])}\n",
    "- Emotional triggers: {point.get('emotional_triggers', '')}\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in writing natural flowing dialogues for Arabic podcasts.\n",
    "\n",
    "Task: Write the main discussion as a natural flowing dialogue covering all three points.\n",
    "\n",
    "Style examples required:\n",
    "Host: {style_examples[\"host_example\"]}\n",
    "Guest: {style_examples[\"guest_example\"]}\n",
    "\n",
    "Context - end of introduction:\n",
    "{intro_dialogue[-300:]}\n",
    "\n",
    "Points to cover:\n",
    "{points_summary}\n",
    "\n",
    "Available spontaneous elements:\n",
    "- Natural interruptions: {spontaneous_moments.get('natural_interruptions', [])}\n",
    "- Emotional reactions: {spontaneous_moments.get('emotional_reactions', [])}\n",
    "- Personal stories: {spontaneous_moments.get('personal_stories', [])}\n",
    "- Humorous moments: {spontaneous_moments.get('humorous_moments', [])}\n",
    "\n",
    "Character dynamics:\n",
    "- Natural chemistry: {personality_interactions.get('natural_chemistry', '')}\n",
    "- Tension points: {personality_interactions.get('tension_points', '')}\n",
    "- Collaboration moments: {personality_interactions.get('collaboration_moments', '')}\n",
    "\n",
    "{self.fillers_guide}\n",
    "\n",
    "Discussion requirements:\n",
    "1. Start with natural transition from introduction\n",
    "2. Cover all three points with flowing natural dialogue\n",
    "3. Don't strictly follow point order - let dialogue flow naturally\n",
    "4. Naturally incorporate spontaneous and cultural elements\n",
    "5. Add disagreement points and healthy debate\n",
    "6. Use personal stories and cultural references\n",
    "7. Make {host_name} and {guest_name} interact with their personalities\n",
    "8. Add funny and surprising moments\n",
    "9. Use 70% MSA and 30% Gulf touches\n",
    "10. Duration: 6-7 minutes of natural dialogue\n",
    "11. End with natural lead-in to conclusion\n",
    "12. Write all dialogue content in Modern Standard Arabic with light dialectal touches\n",
    "\n",
    "Dialogue format:\n",
    "المقدم: [text]\n",
    "الضيف: [text]\n",
    "\n",
    "Write the complete discussion:\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in writing flowing and natural dialogues. Style: {optimal_style}. Always write dialogue content in Modern Standard Arabic with light dialectal touches.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_natural_closing(self, topic, final_outline_result, optimal_style, intro_dialogue, main_dialogue):\n",
    "        \"\"\"\n",
    "        Step 3: Generate natural closing (conclusion + outro) - V1 enhancer style\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract outline elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        closing = conv_flow.get(\"closing\", {})\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style examples\n",
    "        style_examples = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in writing impactful and natural Arabic podcast closings.\n",
    "\n",
    "Task: Write a natural and impactful closing (conclusion + outro) for the episode.\n",
    "\n",
    "Style examples required:\n",
    "Host: {style_examples[\"host_example\"]}\n",
    "\n",
    "Context - end of discussion:\n",
    "{main_dialogue[-300:]}\n",
    "\n",
    "Closing elements from outline:\n",
    "Main takeaways: {closing.get('conclusion', {}).get('main_takeaways', '')}\n",
    "Guest final message: {closing.get('conclusion', {}).get('guest_final_message', '')}\n",
    "Host closing thoughts: {closing.get('conclusion', {}).get('host_closing_thoughts', '')}\n",
    "\n",
    "Guest appreciation: {closing.get('outro', {}).get('guest_appreciation', '')}\n",
    "Audience thanks: {closing.get('outro', {}).get('audience_thanks', '')}\n",
    "Call to action: {closing.get('outro', {}).get('call_to_action', '')}\n",
    "Final goodbye: {closing.get('outro', {}).get('final_goodbye', '')}\n",
    "\n",
    "Cultural references: {cultural_context.get('proverbs_sayings', [])}\n",
    "\n",
    "{self.fillers_guide}\n",
    "\n",
    "Closing requirements:\n",
    "1. Start with natural transition from discussion\n",
    "2. Summarize key points naturally, not mechanically\n",
    "3. Have {guest_name} deliver impactful final message\n",
    "4. Have {host_name} add his closing thoughts\n",
    "5. Add sincere and warm thanks to guest and listeners\n",
    "6. Include natural call for engagement\n",
    "7. Use cultural touch in farewell\n",
    "8. Make ending leave positive impact\n",
    "9. Use 70% MSA and 30% Gulf touches\n",
    "10. Duration: 1-2 impactful minutes\n",
    "11. Write all dialogue content in Modern Standard Arabic with light dialectal touches\n",
    "\n",
    "Dialogue format:\n",
    "المقدم: [text]\n",
    "الضيف: [text]\n",
    "\n",
    "Write the complete closing:\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in writing impactful and natural closings. Style: {optimal_style}. Always write dialogue content in Modern Standard Arabic with light dialectal touches.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_complete_script(self, topic, final_outline_result):\n",
    "        \"\"\"\n",
    "        Generate complete script using 3-step hybrid approach\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        optimal_style = \"تعليمي\"  # Default\n",
    "        if \"language_style\" in outline:\n",
    "            formality = outline[\"language_style\"].get(\"formality_level\", \"\")\n",
    "            if \"حواري\" in formality or \"ودي\" in formality:\n",
    "                optimal_style = \"حواري\"\n",
    "            elif \"تحليلي\" in formality:\n",
    "                optimal_style = \"تحليلي\"\n",
    "            elif \"مرح\" in formality or \"ترفيهي\" in formality:\n",
    "                optimal_style = \"ترفيهي\"\n",
    "        \n",
    "        print(f\"Starting script generation with style: {optimal_style}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(\" Step 1: Generating enhanced introduction...\")\n",
    "        intro_dialogue = self.generate_enhanced_intro(topic, final_outline_result, optimal_style)\n",
    "        print(\"Introduction completed\")\n",
    "        \n",
    "        print(\" Step 2: Generating flowing discussion...\")\n",
    "        main_dialogue = self.generate_flowing_main_discussion(topic, final_outline_result, optimal_style, intro_dialogue)\n",
    "        print(\" Main discussion completed\")\n",
    "        \n",
    "        print(\" Step 3: Generating natural closing...\")\n",
    "        closing_dialogue = self.generate_natural_closing(topic, final_outline_result, optimal_style, intro_dialogue, main_dialogue)\n",
    "        print(\"Closing completed\")\n",
    "        \n",
    "        complete_script = f\"\"\"=== المقدمة ===\n",
    "{intro_dialogue}\n",
    "\n",
    "=== النقاش الرئيسي ===\n",
    "{main_dialogue}\n",
    "\n",
    "=== الختام ===\n",
    "{closing_dialogue}\"\"\"\n",
    "        \n",
    "        print(\"🎉 Complete script generated successfully!\")\n",
    "        \n",
    "        return {\n",
    "            \"intro\": intro_dialogue,\n",
    "            \"main_discussion\": main_dialogue,\n",
    "            \"closing\": closing_dialogue,\n",
    "            \"complete_script\": complete_script,\n",
    "            \"script_length\": len(complete_script),\n",
    "            \"estimated_duration\": \"10 دقائق تقريباً\",\n",
    "            \"style_used\": optimal_style\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7838c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️ Starting script generation with style: تحليلي\n",
      "==================================================\n",
      "📝 Step 1: Generating enhanced introduction...\n",
      "✅ Introduction completed\n",
      "📝 Step 2: Generating flowing discussion...\n",
      "✅ Main discussion completed\n",
      "📝 Step 3: Generating natural closing...\n",
      "✅ Closing completed\n",
      "🎉 Complete script generated successfully!\n",
      "=== المقدمة ===\n",
      "المقدمة: ليلى أحمد: مرحبًا بكم جميعًا في حلقة جديدة من بودكاستنا حيث نناقش القضايا التي تؤثر على ثقافتنا وهويتنا بطريقة تحاكي واقعنا وتُلهمنا. أمم، شلون أقول، اليوم موضوعنا جدًا مثير للاهتمام... الذكاء الاصطناعي والهوية العربية! شوفوا، كلنا نلاحظ كيف الذكاء الاصطناعي صار جزءًا من حياتنا اليومية، أليس كذلك؟ يعني من التطبيقات، إلى القرارات، وحتى المحتوى الرقمي اللي نتعامل معه يوميًا. <pause: 1s> شخصيًا، كثيرًا ما أسأل نفسي: هل هالتقنيات المتطورة ممكن تكون أداة لتعزيز هويتنا الثقافية؟ ولا بالعكس، ممكن تشكل خطر يهدد اللغة والقيم اللي نحاول نحافظ عليها؟\n",
      "\n",
      "أههه، طبعًا، الموضوع مو بسيط أبدًا، وفيه جوانب تقنية وثقافية وحتى اجتماعية تحتاج لتحليل عميق. واليوم، يسعدني جدًا أننا ما رح نناقش هذا الموضوع لوحدي، بل معي ضيف متخصص، د. سامي الحسن، اللي ما شاء الله عليه عنده خبرة طويلة ومتميزة في مجال الذكاء الاصطناعي وتأثيراته على الثقافة.\n",
      "\n",
      "<pause: 2s>\n",
      "\n",
      "المقدمة: ليلى أحمد: دكتور سامي، الله يعطيك العافية، وشلونك اليوم؟ <سعيدة> \n",
      "الضيف: د. سامي الحسن: الله يعافيكِ ليلى، الحمد لله، بخير، وشكرًا على الاستضافة الجميلة. الموضوع اللي اخترتيه مهم جدًا، وأنا متحمس أشارككم الأفكار حوله.\n",
      "المقدمة: ليلى أحمد: طبعًا، أكيد متحمسين نسمع منك. قبل ما نبدأ في التفاصيل، أحب أقدمك للمتابعين بشكل بسيط. د. سامي الحسن، أستاذ جامعي وخبير في تطبيقات الذكاء الاصطناعي، وله أبحاث عديدة تركز على التأثير الثقافي لهذه التكنولوجيا. أمم، يعني إذا بنربط هذا بموضوعنا اليوم، يمكننا نسأل سؤال جوهري: كيف التطورات التقنية تخدم اللغة العربية؟ وهل ممكن الذكاء الاصطناعي يكون جزءًا من جهود الحفاظ على هويتنا؟\n",
      "الضيف: د. سامي الحسن: صحيح ليلى، هذا سؤال محوري. يعنييي، من المطبعة في التاريخ العربي إلى البرمجيات الحديثة، دائمًا كان فيه علاقة بين التكنولوجيا واللغة. ويمكن، لو نظرنا للعصر العباسي كمثال، نشوف كيف الاهتمام بالترجمة والتكنولوجيا ساهم في إثراء المعرفة والحفاظ على اللغة. وبالمثل، اليوم الذكاء الاصطناعي يحمل إمكانيات ضخمة، لكن التحدي الأكبر هو كيف نستخدمها بالشكل الصحيح.\n",
      "\n",
      "المقدمة: ليلى أحمد: واو، كلامك فعلاً يفتح أبواب للنقاش. زين، خلونا نبدأ اليوم بسؤال بسيط لكنه عميق: كيف يمكن للذكاء الاصطناعي أن يكون حليفًا للثقافة العربية؟ وهل نحن كفاية مستعدين لهذا التحول؟ <انتقال طبيعي للنقاش الرئيسي>\n",
      "\n",
      "=== النقاش الرئيسي ===\n",
      "### الحوار الكامل:\n",
      "\n",
      "**ليلى أحمد:** زين، دكتور سامي، خلنا نبدأ من نقطة حساسة شوي... تأثير تدريب نماذج الذكاء الاصطناعي على بيانات غربية، وش رايك في هالموضوع؟ هل فعلاً هالشيء يحدّ من فهم الثقافة العربية؟ \n",
      "\n",
      "**د. سامي الحسن:** واو، هذا سؤال عميق يا ليلى. بصراحة، نعم، تدريب النماذج على بيانات غربية فقط يخلق نوع من التحيّز الثقافي. يعني، شوف بعض التطبيقات، لما نجرب نستخدمها في فهم السياق العربي، النتائج أحيانًا تكون بعيدة تمامًا عن الواقع. \n",
      "\n",
      "**ليلى أحمد:** صحيح، أذكر مرة كنت أبحث عن ترجمة لجملة عربية بسيطة، وكانت الترجمة مضحكة وغير معقولة. تحس أن النموذج ما \"استوعب\" المعنى الحقيقي. \n",
      "\n",
      "**د. سامي الحسن:** بالضبط! أنا في إحدى مشاريعي البحثية اضطررت أصنع قاعدة بيانات عربية من الصفر لأن المحتوى العربي المتوفر كان ناقص أو مش مناسب. \n",
      "\n",
      "**ليلى أحمد:** طيب... وش الحل؟ هل ممكن نعتمد بس على بياناتنا المحلية لتطوير نماذج أفضل؟ \n",
      "\n",
      "**د. سامي الحسن:** هو لازم نكون واقعيين شوي. الاعتماد على بيانات محلية فقط فكرة ممتازة، لكنها تحدي كبير، لأن حجم البيانات العربية مقارنة بالبيانات الغربية محدود، وأحياناً التنوع الثقافي العربي نفسه يطلب مزيد من الجهد. \n",
      "\n",
      "**ليلى أحمد:** تمام، بس هنا يجي دور المبادرات العربية، مثل الإمارات والسعودية اللي شغالين على مشاريع مثل \"جايس\" و\"الحوراء\". هل تعتقد أن هذي الجهود كافية يا دكتور؟ \n",
      "\n",
      "**د. سامي الحسن:** شوف، أنا أشوف إنها خطوة مهمة جداً، خاصة إذا حصلت على دعم قوي وتعاون إقليمي. يعني، مثلما يقول المثل: \"التعاون أساس النجاح\"، لو الدول العربية اشتغلت معاً في هذا المجال، راح نقدر ننافس النماذج الغربية بفعالية. \n",
      "\n",
      "**ليلى أحمد:** واو، كلامك جميل. لكن هل تعتقد أن هذه المبادرات ممكن تواجه تحديات من حيث التمويل أو تقبل السوق العالمي؟ \n",
      "\n",
      "**د. سامي الحسن:** طبعًا، هذي تحديات موجودة، لكن العمل على تعزيز المحتوى العربي والتعاون بين الدول العربية ممكن يقللها. شوف تجربة السعودية في تطوير الذكاء الاصطناعي لخدمة اللغة العربية، مثال رائع كيف التكنولوجيا تساعد الثقافة. \n",
      "\n",
      "**ليلى أحمد:** صحيح، مثلما يقول المثل: \"الثقافة هي الجسر بين الماضي والمستقبل.\" لكن يا دكتور، وش رأيك في فكرة استخدام الذكاء الاصطناعي لتعزيز الثقافة بشكل مباشر؟ مثلاً في إنتاج محتوى ثقافي عربي؟ \n",
      "\n",
      "**د. سامي الحسن:** فكرة ممتازة يا ليلى. الذكاء الاصطناعي ممكن يساعدنا في إنشاء مواد تعليمية، كتب، وحتى محتوى رقمي يدعم اللغة العربية ويسهل تعلمها للجيل الجديد. \n",
      "\n",
      "**ليلى أحمد:** واو، تخيل لو صار عندنا تطبيق ذكاء اصطناعي يُعلم الأطفال اللغة العربية بأسلوب ممتع وتفاعلي. \n",
      "\n",
      "**د. سامي الحسن:** هذا ممكن جداً، وأنا متأكد أننا قريباً بنشوف تطبيقات تعليمية مبتكرة تخدم هالهدف. لكن انتبهي، فيه خطر من الاعتماد الكامل على التكنولوجيا، لأن الثقافة تحتاج أيضاً إلى تفاعل إنساني. \n",
      "\n",
      "**ليلى أحمد:** صحيح، التوازن مهم. لكن، هل تعتقد أن المبادرات مثل مكتبة دبي الرقمية تُقدم نموذج عملي للاستخدام الثقافي للتكنولوجيا؟ \n",
      "\n",
      "**د. سامي الحسن:** نعم، مكتبة دبي الرقمية مثال رائع كيف يمكن للتكنولوجيا أن تخدم الثقافة وتُعززها. وهنا لازم نقول: \"من عرف قدر نفسه لم يهينه\"، يعني لازم نعرف قيمة ثقافتنا ونشتغل عليها بذكاء. \n",
      "\n",
      "**ليلى أحمد:** واو، كلامك مُلهم يا دكتور. لكن أمازحك شوي: تتوقع ممكن الذكاء الاصطناعي يساعدنا في صنع أمثال عربية جديدة؟ \n",
      "\n",
      "**د. سامي الحسن:** [يضحك] يمكن يساعد، لكن أخشى تكون الأمثال مضحكة أكثر من كونها حكيمة! \n",
      "\n",
      "**ليلى أحمد:** [تضحك] صحيح، بس يمكن هالشيء يضيف لمسة إبداعية للثقافة! المهم، النقاش اليوم أعطانا رؤية واضحة عن التحديات والفرص اللي ممكن يوفرها الذكاء الاصطناعي للثقافة العربية. \n",
      "\n",
      "**د. سامي الحسن:** أكيد، وأنا أشعر بالفخر أننا نرى جهود عربية ملموسة في هذا الاتجاه. \n",
      "\n",
      "**ليلى أحمد:** الله يعطيك العافية يا دكتور سامي. خلنا ننتقل للحلقة الختامية ونناقش كيف نُحفّز الشباب العربي للمشاركة في تطوير مشاريع الذكاء الاصطناعي. \n",
      "\n",
      "### نهاية النقاش وانتقال طبيعي للخاتمة\n",
      "\n",
      "=== الختام ===\n",
      "المقدم: ليلى أحمد: يعني، لو نرجع نلخص النقاش، التقنيات الحديثة مثل الذكاء الاصطناعي فعلاً تحمل إمكانيات كبيرة، لكن زي ما ذكرنا، استخدام هذه التقنيات يحتاج إلى وعي وحذر عشان نحافظ على هويتنا وثقافتنا العربية. دكتور سامي، قبل نختم، وش الرسالة الأخيرة اللي تحب توصلها للمستمعين؟  \n",
      "\n",
      "الضيف: د. سامي الحسن: أكيد، شوفوا، أنا دايم أقول إن المستقبل ما ينتظر أحد. إذا ما عملنا اليوم بشكل جماعي—يعني بين الحكومات، المؤسسات الأكاديمية، وحتى الأفراد—عشان نطور حلول تقنية تخدم ثقافتنا وقيمنا، بنكون مجرد مستهلكين بدل ما نصير صانعين. المستقبل العربي يحتاج إلى عقول مبدعة تؤمن بقدرتها على التغيير.  \n",
      "\n",
      "المقدم: ليلى أحمد: يا الله! كلام في الصميم، دكتور سامي. الله يعطيك العافية على مشاركتك القيمة معنا اليوم، فعلاً أثريت النقاش بشكل جميل ومفيد.  \n",
      "\n",
      "المقدم: أحمد: وشكراً لكم مستمعينا الأعزاء على انضمامكم إلينا في هذه الحلقة. تذكروا دائماً أن العلم نور والجهل ظلام، ولازم نكون مستعدين نواكب العصر، لكن بدون ما نخسر هويتنا.  \n",
      "\n",
      "المقدم: ليلى أحمد: لا تنسوا تشاركونا آرائكم حول موضوع الحلقة على منصاتنا الاجتماعية، وش نقدر نسوي كمجتمع عربي لتبني التقنيات بشكل يحترم هويتنا؟  \n",
      "\n",
      "المقدم: أحمد: من جد وجد ومن سار على الدرب وصل، وإحنا كمجتمع عربي قادرين نكون جزء من مستقبل واعد.  \n",
      "\n",
      "المقدم: ليلى أحمد: إلى اللقاء في الحلقة القادمة، مع موضوع جديد وحوار شيّق آخر. في أمان الله!  \n"
     ]
    }
   ],
   "source": [
    "script_generator = HybridScriptGenerator(deployment, \"gpt-4o\")\n",
    "script_result = script_generator.generate_complete_script(topic, final_outline)\n",
    "print(script_result[\"complete_script\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
