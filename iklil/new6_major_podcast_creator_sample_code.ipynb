{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e5796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# import openai\n",
    "from openai import AzureOpenAI\n",
    "# !pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def APIKeyManager(model_type, key_path):\n",
    "    \n",
    "    load_dotenv(dotenv_path=key_path, override=True)\n",
    "    if model_type=='azure':\n",
    "        client = AzureOpenAI(\n",
    "            api_version=os.environ[\"AZURE_API_VERSION\"],\n",
    "            azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "        )\n",
    "        return client\n",
    "    elif model_type=='fanar':\n",
    "        client = OpenAI(\n",
    "            base_url = \"https://api.fanar.qa/v1\",\n",
    "            api_key  = os.environ[\"FANAR_API_KEY\"],\n",
    "        )\n",
    "        # Option A – set a default so you don’t repeat `model=…` later\n",
    "        client.default_params = {\"model\": \"Fanar-C-1-8.7B\"}\n",
    "        return client    \n",
    "    elif model_type=='gemini':\n",
    "        pass\n",
    "    return client\n",
    "\n",
    "# Load environment variables\n",
    "model_type=\"fanar\"\n",
    "deployment = APIKeyManager(model_type, \"./azure.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a84582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicClassifier:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def classify_topic(self, topic, information):\n",
    "        \"\"\"\n",
    "        Classify podcast topic and determine optimal approach\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            \n",
    "        Returns:\n",
    "            JSON with classification results\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في تحليل المواضيع وتصنيفها لإنتاج بودكاست عربي طبيعي وجذاب.\n",
    "\n",
    "المهمة: حلل الموضوع التالي وحدد أفضل نهج لتقديمه في بودكاست عربي.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات الأساسية: {information}\n",
    "\n",
    "قم بتحليل الموضوع وإرجاع النتيجة بصيغة JSON تحتوي على:\n",
    "\n",
    "{{\n",
    "    \"primary_category\": \"الفئة الرئيسية\",\n",
    "    \"category_justification\": \"سبب اختيار هذه الفئة بناءً على طبيعة الموضوع\",\n",
    "    \"optimal_style\": \"الأسلوب الأمثل للمناقشة\",\n",
    "    \"discourse_pattern\": \"نمط الخطاب المناسب\",\n",
    "    \"audience_engagement_goal\": \"هدف تفاعل الجمهور\",\n",
    "    \"cultural_sensitivity_level\": \"مستوى الحساسية الثقافية\",\n",
    "    \"controversy_potential\": \"احتمالية الجدل\",\n",
    "    \"key_discussion_angles\": [\n",
    "        \"زوايا النقاش الرئيسية المتوقعة\",\n",
    "        \"النقاط التي ستثير اهتمام الجمهور العربي\"\n",
    "    ],\n",
    "    \"natural_tension_points\": [\n",
    "        \"نقاط التوتر الطبيعية في الموضوع\",\n",
    "        \"الجوانب التي قد تثير جدلاً صحياً\"\n",
    "    ],\n",
    "    \"cultural_connection_opportunities\": [\n",
    "        \"فرص الربط بالثقافة العربية\",\n",
    "        \"المراجع المحلية والإقليمية ذات الصلة\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "الفئات المتاحة:\n",
    "1. \"العلوم والتكنولوجيا\" - للمواضيع التقنية والعلمية والابتكارات\n",
    "2. \"السياسة والشؤون العامة\" - للمواضيع السياسية والأحداث الجارية والقضايا العامة\n",
    "3. \"القضايا الاجتماعية\" - للمواضيع المجتمعية والعلاقات والقيم والتحديات الاجتماعية\n",
    "4. \"الرياضة والترفيه\" - للمواضيع الرياضية والفنية والترفيهية\n",
    "5. \"التاريخ والثقافة\" - للمواضيع التاريخية والتراثية والثقافية\n",
    "\n",
    "الأساليب المتاحة:\n",
    "- \"حواري\" - حوار طبيعي وودي بين المقدم والضيف\n",
    "- \"تعليمي\" - تركيز على الشرح والتعليم بطريقة ممتعة\n",
    "- \"ترفيهي\" - مرح وخفيف مع لمسات فكاهية\n",
    "- \"تحليلي\" - نقاش عميق ومتخصص وتحليلي\n",
    "\n",
    "أنماط الخطاب:\n",
    "- \"رسمي\" - لغة رسمية ومحترمة\n",
    "- \"ودي\" - لغة دافئة ومألوفة\n",
    "- \"جدلي\" - نقاش حيوي مع وجهات نظر متعددة\n",
    "- \"سردي\" - أسلوب حكواتي وقصصي\n",
    "\n",
    "\n",
    "\n",
    "مستوى الحساسية الثقافية:\n",
    "- \"عالي\" - يتطلب حذراً شديداً في التعامل\n",
    "- \"متوسط\" - يحتاج مراعاة ثقافية معتدلة  \n",
    "- \"منخفض\" - موضوع مقبول عموماً\n",
    "\n",
    "احتمالية الجدل:\n",
    "- \"عالية\" - موضوع مثير للجدل بطبيعته\n",
    "- \"متوسطة\" - قد يثير بعض الاختلافات\n",
    "- \"منخفضة\" - موضوع مقبول عموماً\n",
    "\n",
    "تعليمات مهمة:\n",
    "- حلل الموضوع بعمق وليس بشكل سطحي\n",
    "- اعتبر السياق الثقافي العربي في التحليل\n",
    "- ركز على ما يجعل الموضوع جذاباً للجمهور العربي\n",
    "- تأكد أن التصنيف يخدم إنتاج محتوى طبيعي وتلقائي\n",
    "- لا تضع علامات ```json في البداية أو النهاية\n",
    "- أرجع JSON صحيح فقط بدون أي نص إضافي\n",
    "-المدة 10 دقائق هي المدة المثلى للحلقة\n",
    "- \"،\"  لا تستخدم الفاصلة العربية \n",
    "\"\"\"\n",
    "\n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"أنت خبير في تحليل المواضيع وتصنيفها لإنتاج بودكاست عربي احترافي. تخصصك في فهم الجمهور العربي واهتماماته.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3  # Lower temperature for more consistent classification\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bde0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Result:\n",
      "{\n",
      "    \"primary_category\": \"التاريخ والثقافة\",\n",
      "    \"category_justification\": \"الموضوع يتناول الهوية الثقافية العربية وكيفية الحفاظ عليها في مواجهة التحديات التقنية الحديثة، مما يجعله مرتبطاً بشكل مباشر بالثقافة والتراث.\",\n",
      "    \"optimal_style\": \"تحليلي\",\n",
      "    \"discourse_pattern\": \"جدلي\",\n",
      "    \"audience_engagement_goal\": \"إثارة التفكير والنقاش حول تأثير الذكاء الاصطناعي على الهوية العربية وتشجيع الجمهور على استكشاف الحلول الممكنة.\",\n",
      "    \"cultural_sensitivity_level\": \"عالي\",\n",
      "    \"controversy_potential\": \"متوسطة\",\n",
      "    \"key_discussion_angles\": [\n",
      "        \"تأثير الذكاء الاصطناعي على اللغة العربية والمحتوى الثقافي.\",\n",
      "        \"جهود الدول العربية في تطوير نماذج ذكاء اصطناعي محلية.\",\n",
      "        \"كيفية تحقيق التوازن بين الاستفادة من التقنية والحفاظ على الهوية الثقافية.\",\n",
      "        \"أهمية تدريب نماذج الذكاء الاصطناعي على بيانات عربية لفهم السياق المحلي.\"\n",
      "    ],\n",
      "    \"natural_tension_points\": [\n",
      "        \"الهيمنة الغربية على تدريب نماذج الذكاء الاصطناعي وتأثيرها على الثقافة العربية.\",\n",
      "        \"التحديات التي تواجه الدول العربية في تطوير تقنيات محلية تنافسية.\",\n",
      "        \"مخاوف تهميش اللغة العربية في المحتوى الرقمي العالمي.\"\n",
      "    ],\n",
      "    \"cultural_connection_opportunities\": [\n",
      "        \"الإشارة إلى مبادرات عربية مثل نموذج \\\"جايس\\\" و\\\"الحوراء\\\".\",\n",
      "        \"تسليط الضوء على أهمية اللغة العربية كجزء من الهوية الثقافية.\",\n",
      "        \"مناقشة دور المؤسسات التعليمية والثقافية في تعزيز المحتوى العربي الرقمي.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Testing Instructions:\n",
    "\n",
    "# To test Step 1, add this to a new cell in your notebook:\n",
    "\n",
    "# Test Step 1: Topic Classification\n",
    "classifier = TopicClassifier(deployment, \"gpt-4o\")\n",
    "\n",
    "# Test with the singlehood topic\n",
    "topic = \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\"\n",
    "\n",
    "information = '''\n",
    "مع انتشار تقنيات الذكاء الاصطناعي بسرعة في العالم العربي، تزداد المخاوف حول تأثيرها على الهوية الثقافية واللغة العربية. \n",
    "تشير الدراسات إلى أن 78% من المحتوى الرقمي باللغة الإنجليزية، بينما المحتوى العربي لا يتجاوز 3%. \n",
    "معظم نماذج الذكاء الاصطناعي الحالية مدربة على بيانات غربية، مما يثير تساؤلات حول قدرتها على فهم السياق الثقافي العربي.\n",
    "في المقابل، تسعى دول مثل الإمارات والسعودية لتطوير نماذج ذكاء اصطناعي عربية مثل \"جايس\" و\"الحوراء\" لمواجهة هذا التحدي.\n",
    "التحدي الأكبر يكمن في كيفية الاستفادة من هذه التقنيات لتعزيز الثقافة العربية بدلاً من تهميشها، وضمان أن تخدم الذكاء الاصطناعي قيمنا ومبادئنا.\n",
    "'''\n",
    "\n",
    "# Run classification\n",
    "classification_result = classifier.classify_topic(topic, information)\n",
    "print(\"Classification Result:\")\n",
    "print(classification_result)\n",
    "\n",
    "\n",
    "\n",
    "# Parse and examine the JSON\n",
    "try:\n",
    "    parsed_result = json.loads(classification_result)\n",
    "    # print(f\"\\nPrimary Category: {parsed_result['primary_category']}\")\n",
    "    # print(f\"Optimal Style: {parsed_result['optimal_style']}\")\n",
    "    # print(f\"Discourse Pattern: {parsed_result['discourse_pattern']}\")\n",
    "except:\n",
    "    print(\"Error parsing JSON result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9ee26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePersonaGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def generate_personas(self, topic, information, classification_result):\n",
    "        \"\"\"\n",
    "        Generate simple but effective host and guest personas\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            \n",
    "        Returns:\n",
    "            JSON with simple host and guest personas\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse classification to understand the requirements\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid classification JSON provided\")\n",
    "        \n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في تصميم شخصيات البودكاست العربي.\n",
    "\n",
    "المهمة: أنشئ مقدم وضيف بسيطين ومناسبين لهذا الموضوع.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات: {information}\n",
    "الفئة: {primary_category}\n",
    "الأسلوب المطلوب: {optimal_style}\n",
    "\n",
    "أرجع النتيجة بصيغة JSON بسيط:\n",
    "\n",
    "{{\n",
    "    \"host\": {{\n",
    "        \"name\": \"اسم المقدم\",\n",
    "        \"age\": عمر رقمي,\n",
    "        \"background\": \"خلفية مختصرة في جملة واحدة\",\n",
    "        \"personality\": \"وصف شخصيته في جملة واحدة\",\n",
    "        \"speaking_style\": \"أسلوب حديثه في جملة واحدة\"\n",
    "    }},\n",
    "    \"guest\": {{\n",
    "        \"name\": \"اسم الضيف\", \n",
    "        \"age\": عمر رقمي,\n",
    "        \"background\": \"خلفية مختصرة في جملة واحدة\",\n",
    "        \"expertise\": \"مجال خبرته في جملة واحدة\",\n",
    "        \"personality\": \"وصف شخصيته في جملة واحدة\",\n",
    "        \"speaking_style\": \"أسلوب حديثه في جملة واحدة\"\n",
    "    }},\n",
    "    \"why_good_match\": \"لماذا هذا المقدم والضيف مناسبان لهذا الموضوع - جملة واحدة\"\n",
    "}}\n",
    "\n",
    "متطلبات:\n",
    "- أسماء عربية مألوفة\n",
    "- شخصيات بسيطة وقابلة للتصديق\n",
    "- مناسبة للموضوع والأسلوب المطلوب\n",
    "- المقدم فضولي والضيف خبير أو صاحب تجربة\n",
    "- لا تضع علامات ```json\n",
    "- أرجع JSON فقط\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في تصميم شخصيات بودكاست بسيطة ومؤثرة. الأسلوب المطلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f699140",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona = SimplePersonaGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "persona_result = persona.generate_personas(topic, information, classification_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab52d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationStructureGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def generate_conversation_structure(self, topic, information, classification_result, personas_result):\n",
    "        \"\"\"\n",
    "        Step 3: Generate core conversation structure (V1 skeleton)\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            \n",
    "        Returns:\n",
    "            JSON with V1-style conversation structure (without rich dialogue content)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided for classification or personas\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        discourse_pattern = classification.get(\"discourse_pattern\", \"\")\n",
    "        recommended_duration = classification.get(\"recommended_duration\", \"10 دقيقة\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في تصميم هيكل المحادثات للبودكاست العربي.\n",
    "\n",
    "المهمة: أنشئ الهيكل الأساسي للمحادثة بتنسيق حوار طبيعي.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات: {information}\n",
    "\n",
    "السياق:\n",
    "- الفئة: {primary_category}\n",
    "- الأسلوب: {optimal_style}\n",
    "- نمط الخطاب: {discourse_pattern}\n",
    "- المدة: {recommended_duration}\n",
    "\n",
    "الشخصيات:\n",
    "- المقدم: {host_name} - {host.get('background', '')}\n",
    "- الضيف: {guest_name} - {guest.get('background', '')}\n",
    "\n",
    "أنشئ مخطط المحادثة بصيغة JSON:\n",
    "\n",
    "{{\n",
    "    \"episode_topic\": \"{topic}\",\n",
    "    \"personas\": {{\n",
    "        \"host\": {{\n",
    "            \"name\": \"{host_name}\",\n",
    "            \"background\": \"{host.get('background', '')}\",\n",
    "            \"speaking_style\": \"{host.get('speaking_style', '')}\"\n",
    "        }},\n",
    "        \"guest\": {{\n",
    "            \"name\": \"{guest_name}\",\n",
    "            \"background\": \"{guest.get('background', '')}\",\n",
    "            \"speaking_style\": \"{guest.get('speaking_style', '')}\"\n",
    "        }}\n",
    "    }},\n",
    "    \"conversation_flow\": {{\n",
    "        \"intro1\": {{\n",
    "            \"opening_line\": \"الجملة الافتتاحية الفعلية للمقدم\",\n",
    "            \"podcast_introduction\": \"تعريف بالبودكاست مرتبط بالموضوع\",\n",
    "            \"episode_hook\": \"جملة تشويقية محددة عن الموضوع\",\n",
    "            \"tone_guidance\": \"نبرة مناسبة للأسلوب {optimal_style}\"\n",
    "        }},\n",
    "        \"intro2\": {{\n",
    "            \"topic_introduction\": \"تقديم الموضوع بوضوح\",\n",
    "            \"guest_welcome\": \"ترحيب بالضيف {guest_name}\",\n",
    "            \"guest_bio_highlight\": \"تعريف بخلفية الضيف\",\n",
    "            \"transition_to_discussion\": \"انتقال للنقاش الرئيسي\"\n",
    "        }},\n",
    "        \"main_discussion\": [\n",
    "            {{\n",
    "                \"point_title\": \"النقطة الرئيسية الأولى للموضوع\",\n",
    "                \"personal_angle\": \"كيف ترتبط بخلفية الشخصيات\"\n",
    "            }},\n",
    "            {{\n",
    "                \"point_title\": \"النقطة الرئيسية الثانية للموضوع\", \n",
    "                \"personal_angle\": \"الزاوية الشخصية لهذه النقطة\"\n",
    "            }},\n",
    "            {{\n",
    "                \"point_title\": \"النقطة الرئيسية الثالثة للموضوع\",\n",
    "                \"personal_angle\": \"الربط الشخصي والختامي\"\n",
    "            }}\n",
    "        ],\n",
    "        \"closing\": {{\n",
    "            \"conclusion\": {{\n",
    "                \"main_takeaways\": \"الخلاصات الرئيسية\",\n",
    "                \"guest_final_message\": \"رسالة الضيف الختامية\",\n",
    "                \"host_closing_thoughts\": \"أفكار المقدم الختامية\"\n",
    "            }},\n",
    "            \"outro\": {{\n",
    "                \"guest_appreciation\": \"شكر الضيف\",\n",
    "                \"audience_thanks\": \"شكر المستمعين\",\n",
    "                \"call_to_action\": \"دعوة للتفاعل\",\n",
    "                \"final_goodbye\": \"وداع نهائي\"\n",
    "            }}\n",
    "        }}\n",
    "    }},\n",
    "    \"cultural_context\": {{\n",
    "        \"proverbs_sayings\": [\n",
    "            \"مثل عربي مناسب للموضوع\",\n",
    "            \"حكمة ذات صلة بالموضوع\"\n",
    "        ],\n",
    "        \"regional_references\": [\n",
    "            \"مرجع محلي متعلق بالموضوع\",\n",
    "            \"تجربة عربية ذات صلة\"\n",
    "        ]\n",
    "    }},\n",
    "    \"language_style\": {{\n",
    "        \"formality_level\": \"مستوى مناسب للأسلوب {optimal_style}\",\n",
    "        \"dialect_touches\": \"لمسات لهجية خفيفة حسب المقدم\",\n",
    "        \"vocabulary_richness\": \"مفردات مناسبة للموضوع\"\n",
    "    }},\n",
    "    \"technical_notes\": {{\n",
    "        \"pacing_guidance\": \"إيقاع مناسب للمدة {recommended_duration}\",\n",
    "        \"pause_points\": \"نقاط توقف طبيعية\",\n",
    "        \"emphasis_moments\": \"لحظات تأكيد مهمة\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "متطلبات مهمة:\n",
    "- اكتب نصوص فعلية وليس أوصاف\n",
    "- استخدم أسماء الشخصيات الحقيقية ({host_name}, {guest_name})\n",
    "- اجعل كل محتوى مرتبط بالموضوع: {topic}\n",
    "- ركز على بناء الهيكل الأساسي للمحادثة\n",
    "- اجعل المحتوى جاهز للتطوير في الخطوة التالية\n",
    "- لا تضع علامات ```json\n",
    "- أرجع JSON صحيح فقط\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في تصميم هيكل المحادثات للبودكاست العربي. الأسلوب المطلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6  # Balanced for structure creation\n",
    "        )\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(response.choices[0].message.content)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except:\n",
    "            # If parsing fails, return raw response\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def validate_conversation_structure(self, structure_json):\n",
    "        \"\"\"\n",
    "        Validate the conversation structure\n",
    "        \"\"\"\n",
    "        required_keys = [\"episode_topic\", \"personas\", \"conversation_flow\", \"cultural_context\", \"language_style\", \"technical_notes\"]\n",
    "        \n",
    "        conversation_flow_required = [\"intro1\", \"intro2\", \"main_discussion\", \"closing\"]\n",
    "        intro1_required = [\"opening_line\", \"podcast_introduction\", \"episode_hook\"]\n",
    "        intro2_required = [\"topic_introduction\", \"guest_welcome\", \"guest_bio_highlight\"]\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            structure = json.loads(structure_json)\n",
    "            \n",
    "            missing_keys = []\n",
    "            \n",
    "            # Check main structure\n",
    "            for key in required_keys:\n",
    "                if key not in structure:\n",
    "                    missing_keys.append(key)\n",
    "            \n",
    "            # Check conversation flow\n",
    "            if \"conversation_flow\" in structure:\n",
    "                conv_flow = structure[\"conversation_flow\"]\n",
    "                for key in conversation_flow_required:\n",
    "                    if key not in conv_flow:\n",
    "                        missing_keys.append(f\"conversation_flow.{key}\")\n",
    "                \n",
    "                # Check intro1\n",
    "                if \"intro1\" in conv_flow:\n",
    "                    intro1 = conv_flow[\"intro1\"]\n",
    "                    for key in intro1_required:\n",
    "                        if key not in intro1:\n",
    "                            missing_keys.append(f\"intro1.{key}\")\n",
    "                \n",
    "                # Check intro2\n",
    "                if \"intro2\" in conv_flow:\n",
    "                    intro2 = conv_flow[\"intro2\"]\n",
    "                    for key in intro2_required:\n",
    "                        if key not in intro2:\n",
    "                            missing_keys.append(f\"intro2.{key}\")\n",
    "                \n",
    "                # Check main discussion\n",
    "                if \"main_discussion\" in conv_flow:\n",
    "                    main_disc = conv_flow[\"main_discussion\"]\n",
    "                    if not isinstance(main_disc, list) or len(main_disc) < 3:\n",
    "                        missing_keys.append(\"main_discussion (need at least 3 points)\")\n",
    "                    else:\n",
    "                        for i, point in enumerate(main_disc):\n",
    "                            if \"point_title\" not in point:\n",
    "                                missing_keys.append(f\"main_discussion[{i}].point_title\")\n",
    "            \n",
    "            if missing_keys:\n",
    "                return False, f\"Missing required keys: {missing_keys}\"\n",
    "            \n",
    "            return True, \"Conversation structure validation successful\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_structure_quality(self, structure_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality of the conversation structure\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            structure = json.loads(structure_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check completeness\n",
    "            conv_flow = structure.get(\"conversation_flow\", {})\n",
    "            analysis[\"has_intro1\"] = bool(conv_flow.get(\"intro1\"))\n",
    "            analysis[\"has_intro2\"] = bool(conv_flow.get(\"intro2\"))\n",
    "            analysis[\"has_main_discussion\"] = bool(conv_flow.get(\"main_discussion\"))\n",
    "            analysis[\"has_closing\"] = bool(conv_flow.get(\"closing\"))\n",
    "            \n",
    "            # Check main discussion depth\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            analysis[\"discussion_points\"] = len(main_disc)\n",
    "            analysis[\"adequate_points\"] = len(main_disc) >= 3\n",
    "            \n",
    "            # Check cultural context\n",
    "            cultural = structure.get(\"cultural_context\", {})\n",
    "            analysis[\"has_proverbs\"] = len(cultural.get(\"proverbs_sayings\", [])) >= 1\n",
    "            analysis[\"has_regional_refs\"] = len(cultural.get(\"regional_references\", [])) >= 1\n",
    "            \n",
    "            # Overall readiness\n",
    "            readiness_indicators = [\n",
    "                analysis[\"has_intro1\"],\n",
    "                analysis[\"has_intro2\"],\n",
    "                analysis[\"has_main_discussion\"],\n",
    "                analysis[\"has_closing\"],\n",
    "                analysis[\"adequate_points\"],\n",
    "                analysis[\"has_proverbs\"]\n",
    "            ]\n",
    "            analysis[\"readiness_score\"] = sum(readiness_indicators)\n",
    "            analysis[\"ready_for_next_step\"] = analysis[\"readiness_score\"] >= 5\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze structure quality\"}\n",
    "\n",
    "# Usage:\n",
    "# generator = ConversationStructureGenerator(deployment, \"Fanar\") \n",
    "# structure_result = generator.generate_conversation_structure(topic, information, classification_result, personas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09091744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"سامي الجابري\",\n",
      "      \"background\": \"صحفي مهتم بالتكنولوجيا والثقافة العربية.\",\n",
      "      \"speaking_style\": \"يطرح أسئلة مباشرة ويسعى لتوضيح الأفكار بأسلوب بسيط.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. ليلى العمري\",\n",
      "      \"background\": \"أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات.\",\n",
      "      \"speaking_style\": \"تشرح الأفكار بأسلوب أكاديمي مبسط مدعوم بالأمثلة.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحباً بكم مستمعينا في بودكاست 'نبض الثقافة'، حيث نناقش القضايا التي تمس هويتنا وثقافتنا في عالم متغير.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع يشغل بال الكثيرين: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هل يمكن لهذه التقنية أن تصبح حليفاً للثقافة العربية أم أنها تهدد بتهميشها؟\"\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءاً من حياتنا اليومية، ولكن هل نحن مستعدون لمواجهة تأثيراته على هويتنا الثقافية؟\",\n",
      "      \"guest_welcome\": \"معنا اليوم د. ليلى العمري، أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات. أهلاً وسهلاً بكِ د. ليلى.\",\n",
      "      \"guest_bio_highlight\": \"د. ليلى لديها خبرة طويلة في دراسة تأثير التكنولوجيا على اللغة والثقافة، وهي صوت مهم في هذا المجال.\",\n",
      "      \"transition_to_discussion\": \"دعينا نبدأ بالنظر إلى الوضع الحالي: كيف ترين تأثير الذكاء الاصطناعي على اللغة والثقافة العربية حتى الآن؟\"\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"الفجوة الرقمية: هيمنة المحتوى الغربي\",\n",
      "        \"personal_angle\": \"سامي: أرقام المحتوى الرقمي مخيفة، 78% بالإنجليزية مقابل 3% فقط بالعربية. هل يمكننا سد هذه الفجوة؟ د. ليلى: هذه الفجوة تعكس تحديات كبيرة، ولكن هناك جهود بدأت تظهر مثل تطوير نماذج عربية كجايس والحوراء.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"نماذج الذكاء الاصطناعي والسياق الثقافي العربي\",\n",
      "        \"personal_angle\": \"سامي: معظم نماذج الذكاء الاصطناعي مدربة على بيانات غربية. هل هذا يعني أنها لا تفهمنا؟ د. ليلى: بالتأكيد، هذه النماذج قد تواجه صعوبة في فهم السياقات العربية، لكن تطوير نماذج محلية خطوة مهمة لتجاوز هذه العقبة.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"الاستفادة من الذكاء الاصطناعي لتعزيز الثقافة\",\n",
      "        \"personal_angle\": \"سامي: هل يمكن للذكاء الاصطناعي أن يصبح أداة لتعزيز الثقافة العربية بدلاً من تهديدها؟ د. ليلى: نعم، إذا تم توجيهه بشكل صحيح، يمكن أن يساهم في نشر اللغة العربية وتوثيق التراث الثقافي بطرق مبتكرة.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الذكاء الاصطناعي يمكن أن يكون تهديداً أو فرصة للثقافة العربية، حسب كيفية استخدامنا له.\",\n",
      "        \"guest_final_message\": \"أدعو الجميع لدعم المبادرات التي تهدف إلى تطوير محتوى عربي رقمي قوي، فهذا جزء من الحفاظ على هويتنا.\",\n",
      "        \"host_closing_thoughts\": \"التكنولوجيا ليست عدواً، بل أداة. علينا أن نتعلم كيف نستخدمها لصالحنا.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكراً جزيلاً د. ليلى على مشاركتك القيمة اليوم.\",\n",
      "        \"audience_thanks\": \"شكراً لكم مستمعينا على تخصيص وقتكم للاستماع إلينا.\",\n",
      "        \"call_to_action\": \"إذا أعجبكم الموضوع، شاركوا آرائكم معنا على منصات التواصل الاجتماعي، ولا تنسوا متابعة الحلقات القادمة.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة من 'نبض الثقافة'.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من عرف قدر نفسه لم يهلك.\",\n",
      "      \"اللغة وعاء الفكر.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"جهود الإمارات في تطوير نموذج 'جايس'.\",\n",
      "      \"مبادرات السعودية في الذكاء الاصطناعي مثل 'الحوراء'.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي معتدل يناسب الأسلوب التحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام بعض الكلمات باللهجة العربية الفصحى مع لمسات محلية عند الحاجة.\",\n",
      "    \"vocabulary_richness\": \"مصطلحات تقنية وثقافية مع شرح بسيط.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"الإيقاع متوازن بين التعمق في النقاط وبين الانتقال للموضوع التالي.\",\n",
      "    \"pause_points\": \"توقف طبيعي بعد كل نقطة نقاشية للسماح بالتفكير.\",\n",
      "    \"emphasis_moments\": \"تأكيد على النقاط المتعلقة بتطوير نماذج عربية وتأثير الذكاء الاصطناعي على اللغة.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "generator = ConversationStructureGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "outline_result = generator.generate_conversation_structure(topic, information, classification_result, persona_result)\n",
    "print(outline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cece3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueContentEnhancer:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def enhance_dialogue_content(self, topic, information, classification_result, personas_result, structure_result):\n",
    "        \"\"\"\n",
    "        Step 4: Enhance conversation structure with rich dialogue content\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            structure_result: JSON string from Step 3 conversation structure\n",
    "            \n",
    "        Returns:\n",
    "            Enhanced structure with rich dialogue content (V1 style)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "            structure = json.loads(structure_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        cultural_sensitivity = classification.get(\"cultural_sensitivity_level\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في إثراء المحادثات بالمحتوى الحواري الطبيعي للبودكاست العربي.\n",
    "\n",
    "المهمة: أضف محتوى حواري غني للهيكل الموجود ليصبح جاهزاً لتوليد السكريبت.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات: {information}\n",
    "\n",
    "السياق:\n",
    "- الفئة: {primary_category}\n",
    "- الأسلوب: {optimal_style}\n",
    "- الحساسية الثقافية: {cultural_sensitivity}\n",
    "\n",
    "الشخصيات:\n",
    "- المقدم: {host_name} - {host.get('personality', '')}\n",
    "- الضيف: {guest_name} - {guest.get('expertise', '')}\n",
    "\n",
    "الهيكل الحالي:\n",
    "{structure_result}\n",
    "\n",
    "أضف العناصر التالية للهيكل الموجود وأرجع النتيجة كاملة:\n",
    "\n",
    "للـ intro1: أضف\n",
    "- \"spontaneity_elements\": [قائمة بعبارات تلقائية محددة]\n",
    "\n",
    "للـ intro2: أضف  \n",
    "- \"cultural_connections\": [ربط ثقافي محدد بالموضوع]\n",
    "\n",
    "لكل نقطة في main_discussion: أضف\n",
    "- \"spontaneous_triggers\": [محفزات تلقائية مرتبطة بالنقطة]\n",
    "- \"disagreement_points\": \"نقاط اختلاف محتملة\"\n",
    "- \"cultural_references\": [أمثال ومراجع ثقافية]\n",
    "- \"natural_transitions\": \"انتقال طبيعي للنقطة التالية\"\n",
    "- \"emotional_triggers\": \"محفزات عاطفية\"\n",
    "\n",
    "أضف قسم جديد:\n",
    "\"spontaneous_moments\": {{\n",
    "    \"natural_interruptions\": [نقاط تداخل طبيعية],\n",
    "    \"emotional_reactions\": [ردود فعل عاطفية],\n",
    "    \"personal_stories\": [قصص شخصية حسب خلفية الشخصيات],\n",
    "    \"humorous_moments\": [لحظات طريفة مرتبطة بالموضوع]\n",
    "}},\n",
    "\n",
    "أضف قسم جديد:\n",
    "\"personality_interactions\": {{\n",
    "    \"host_strengths\": \"نقاط قوة {host_name} في الحوار\",\n",
    "    \"guest_expertise\": \"مجالات خبرة {guest_name}\",\n",
    "    \"natural_chemistry\": \"كيف يتفاعلان طبيعياً\",\n",
    "    \"tension_points\": \"نقاط توتر صحية\",\n",
    "    \"collaboration_moments\": \"لحظات تعاون\"\n",
    "}}\n",
    "\n",
    "متطلبات مهمة:\n",
    "- احتفظ بكل المحتوى الموجود من الهيكل الأساسي\n",
    "- أضف المحتوى الجديد فقط\n",
    "- اكتب نصوص فعلية وليس أوصاف\n",
    "- اجعل كل إضافة مرتبطة بالموضوع: {topic}\n",
    "- اجعل المحتوى مناسب للأسلوب: {optimal_style}\n",
    "- استخدم أسماء الشخصيات ({host_name}, {guest_name})\n",
    "- اجعل المحتوى طبيعي وقابل للحوار\n",
    "- لا تضع علامات ```json\n",
    "- أرجع JSON كامل محسن\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في إثراء المحادثات بالمحتوى الحواري الطبيعي. الأسلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7  # Higher creativity for dialogue content\n",
    "        )\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(response.choices[0].message.content)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except:\n",
    "            # If parsing fails, return raw response\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def validate_enhanced_content(self, enhanced_json):\n",
    "        \"\"\"\n",
    "        Validate the enhanced dialogue content\n",
    "        \"\"\"\n",
    "        required_new_elements = [\"spontaneous_moments\", \"personality_interactions\"]\n",
    "        \n",
    "        # Elements that should be added to existing sections\n",
    "        intro1_should_have = [\"spontaneity_elements\"]\n",
    "        intro2_should_have = [\"cultural_connections\"]\n",
    "        main_discussion_should_have = [\"spontaneous_triggers\", \"cultural_references\", \"disagreement_points\"]\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            enhanced = json.loads(enhanced_json)\n",
    "            \n",
    "            missing_elements = []\n",
    "            \n",
    "            # Check new sections\n",
    "            for element in required_new_elements:\n",
    "                if element not in enhanced:\n",
    "                    missing_elements.append(element)\n",
    "            \n",
    "            # Check enhanced intro1\n",
    "            conv_flow = enhanced.get(\"conversation_flow\", {})\n",
    "            intro1 = conv_flow.get(\"intro1\", {})\n",
    "            for element in intro1_should_have:\n",
    "                if element not in intro1:\n",
    "                    missing_elements.append(f\"intro1.{element}\")\n",
    "            \n",
    "            # Check enhanced intro2\n",
    "            intro2 = conv_flow.get(\"intro2\", {})\n",
    "            for element in intro2_should_have:\n",
    "                if element not in intro2:\n",
    "                    missing_elements.append(f\"intro2.{element}\")\n",
    "            \n",
    "            # Check enhanced main discussion\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            for i, point in enumerate(main_disc):\n",
    "                for element in main_discussion_should_have:\n",
    "                    if element not in point:\n",
    "                        missing_elements.append(f\"main_discussion[{i}].{element}\")\n",
    "            \n",
    "            if missing_elements:\n",
    "                return False, f\"Missing enhanced elements: {missing_elements}\"\n",
    "            \n",
    "            return True, \"Dialogue content enhancement validation successful\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_enhancement_quality(self, enhanced_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality of dialogue content enhancement\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            enhanced = json.loads(enhanced_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check spontaneous moments\n",
    "            spont_moments = enhanced.get(\"spontaneous_moments\", {})\n",
    "            analysis[\"has_interruptions\"] = len(spont_moments.get(\"natural_interruptions\", [])) >= 2\n",
    "            analysis[\"has_personal_stories\"] = len(spont_moments.get(\"personal_stories\", [])) >= 2\n",
    "            analysis[\"has_humor\"] = len(spont_moments.get(\"humorous_moments\", [])) >= 1\n",
    "            \n",
    "            # Check personality interactions\n",
    "            personality = enhanced.get(\"personality_interactions\", {})\n",
    "            analysis[\"has_chemistry\"] = bool(personality.get(\"natural_chemistry\"))\n",
    "            analysis[\"has_host_strengths\"] = bool(personality.get(\"host_strengths\"))\n",
    "            analysis[\"has_guest_expertise\"] = bool(personality.get(\"guest_expertise\"))\n",
    "            \n",
    "            # Check main discussion enhancement\n",
    "            conv_flow = enhanced.get(\"conversation_flow\", {})\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            \n",
    "            enhanced_points = 0\n",
    "            for point in main_disc:\n",
    "                if (point.get(\"spontaneous_triggers\") and \n",
    "                    point.get(\"cultural_references\") and \n",
    "                    point.get(\"disagreement_points\")):\n",
    "                    enhanced_points += 1\n",
    "            \n",
    "            analysis[\"enhanced_discussion_points\"] = enhanced_points\n",
    "            analysis[\"all_points_enhanced\"] = enhanced_points == len(main_disc)\n",
    "            \n",
    "            # Overall readiness for script generation\n",
    "            readiness_indicators = [\n",
    "                analysis[\"has_interruptions\"],\n",
    "                analysis[\"has_personal_stories\"],\n",
    "                analysis[\"has_chemistry\"],\n",
    "                analysis[\"has_host_strengths\"],\n",
    "                analysis[\"all_points_enhanced\"]\n",
    "            ]\n",
    "            analysis[\"readiness_score\"] = sum(readiness_indicators)\n",
    "            analysis[\"ready_for_script_generation\"] = analysis[\"readiness_score\"] >= 4\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze enhancement quality\"}\n",
    "\n",
    "# Usage:\n",
    "# enhancer = DialogueContentEnhancer(deployment, \"Fanar\")\n",
    "# enhanced_result = enhancer.enhance_dialogue_content(topic, information, classification_result, personas_result, structure_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07febcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"سامي الجابري\",\n",
      "      \"background\": \"صحفي مهتم بالتكنولوجيا والثقافة العربية.\",\n",
      "      \"speaking_style\": \"يطرح أسئلة مباشرة ويسعى لتوضيح الأفكار بأسلوب بسيط.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. ليلى العمري\",\n",
      "      \"background\": \"أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات.\",\n",
      "      \"speaking_style\": \"تشرح الأفكار بأسلوب أكاديمي مبسط مدعوم بالأمثلة.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحباً بكم مستمعينا في بودكاست 'نبض الثقافة'، حيث نناقش القضايا التي تمس هويتنا وثقافتنا في عالم متغير.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع يشغل بال الكثيرين: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هل يمكن لهذه التقنية أن تصبح حليفاً للثقافة العربية أم أنها تهدد بتهميشها؟\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"سامي: هل فكرت يوماً في تأثير التكنولوجيا على لغتك اليومية؟\",\n",
      "        \"سامي: يا ترى، لو كان الذكاء الاصطناعي يتحدث باللهجة المحلية، كيف سيكون الحوار؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءاً من حياتنا اليومية، ولكن هل نحن مستعدون لمواجهة تأثيراته على هويتنا الثقافية؟\",\n",
      "      \"guest_welcome\": \"معنا اليوم د. ليلى العمري، أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات. أهلاً وسهلاً بكِ د. ليلى.\",\n",
      "      \"guest_bio_highlight\": \"د. ليلى لديها خبرة طويلة في دراسة تأثير التكنولوجيا على اللغة والثقافة، وهي صوت مهم في هذا المجال.\",\n",
      "      \"transition_to_discussion\": \"دعينا نبدأ بالنظر إلى الوضع الحالي: كيف ترين تأثير الذكاء الاصطناعي على اللغة والثقافة العربية حتى الآن؟\",\n",
      "      \"cultural_connections\": [\n",
      "        \"سامي: أذكر أن جدتي كانت دائماً تقول 'اللغة وعاء الفكر'، هل تعتقدين أننا نفقد شيئاً من هذا الوعاء في ظل الذكاء الاصطناعي؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"الفجوة الرقمية: هيمنة المحتوى الغربي\",\n",
      "        \"personal_angle\": \"سامي: أرقام المحتوى الرقمي مخيفة، 78% بالإنجليزية مقابل 3% فقط بالعربية. هل يمكننا سد هذه الفجوة؟ د. ليلى: هذه الفجوة تعكس تحديات كبيرة، ولكن هناك جهود بدأت تظهر مثل تطوير نماذج عربية كجايس والحوراء.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل تعتقدين أن الأجيال القادمة ستكون أكثر انفتاحاً على المحتوى العربي، أم أن الإنجليزية ستظل طاغية؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يجب أن نعتمد فقط على المبادرات الحكومية أم أن هناك دوراً أكبر للمجتمع المدني؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"القول الشائع: 'من عرف قدر نفسه لم يهلك'، يعبر عن أهمية إدراك قيمة لغتنا وثقافتنا في مواجهة المحتوى الغربي.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: هذا يقودني إلى سؤال مهم، هل النماذج الغربية للذكاء الاصطناعي قادرة على فهم الثقافة العربية حقاً؟\",\n",
      "        \"emotional_triggers\": \"الخوف من أن تصبح اللغة العربية مجرد لغة ثانوية في العالم الرقمي.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"نماذج الذكاء الاصطناعي والسياق الثقافي العربي\",\n",
      "        \"personal_angle\": \"سامي: معظم نماذج الذكاء الاصطناعي مدربة على بيانات غربية. هل هذا يعني أنها لا تفهمنا؟ د. ليلى: بالتأكيد، هذه النماذج قد تواجه صعوبة في فهم السياقات العربية، لكن تطوير نماذج محلية خطوة مهمة لتجاوز هذه العقبة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل يمكن أن تؤدي هذه النماذج إلى تحريف بعض المفاهيم الثقافية التقليدية؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يجب التركيز أكثر على تدريب النماذج الحالية أم بناء نماذج جديدة من الصفر؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"سامي: أذكر أنني قرأت عن مبادرة سعودية لتوثيق التراث الشعبي باستخدام الذكاء الاصطناعي، هل هذا نموذج يمكن أن نقتدي به؟\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: إذاً، يمكن للذكاء الاصطناعي أن يكون جزءاً من الحل وليس المشكلة، لكن كيف يمكننا ضمان ذلك عملياً؟\",\n",
      "        \"emotional_triggers\": \"الشعور بالفخر عندما يتم الحديث عن جهود عربية ريادية.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"الاستفادة من الذكاء الاصطناعي لتعزيز الثقافة\",\n",
      "        \"personal_angle\": \"سامي: هل يمكن للذكاء الاصطناعي أن يصبح أداة لتعزيز الثقافة العربية بدلاً من تهديدها؟ د. ليلى: نعم، إذا تم توجيهه بشكل صحيح، يمكن أن يساهم في نشر اللغة العربية وتوثيق التراث الثقافي بطرق مبتكرة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل يمكن أن نرى قصائد المتنبي تُقرأ بأصوات ذكاء اصطناعي قريباً؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكن للتكنولوجيا أن تكون بديلاً عن التدخلات البشرية في الحفاظ على الثقافة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"د. ليلى: هناك مثل يقول 'اللغة هي روح الأمة'، وهذا يعكس أهمية استخدام التكنولوجيا للحفاظ عليها.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: هذا يقودني للتفكير في المستقبل، كيف يمكننا إعداد الأجيال القادمة لهذه التحديات؟\",\n",
      "        \"emotional_triggers\": \"الإلهام بفكرة أن التكنولوجيا يمكن أن تبني جسوراً بين الماضي والمستقبل.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الذكاء الاصطناعي يمكن أن يكون تهديداً أو فرصة للثقافة العربية، حسب كيفية استخدامنا له.\",\n",
      "        \"guest_final_message\": \"أدعو الجميع لدعم المبادرات التي تهدف إلى تطوير محتوى عربي رقمي قوي، فهذا جزء من الحفاظ على هويتنا.\",\n",
      "        \"host_closing_thoughts\": \"التكنولوجيا ليست عدواً، بل أداة. علينا أن نتعلم كيف نستخدمها لصالحنا.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكراً جزيلاً د. ليلى على مشاركتك القيمة اليوم.\",\n",
      "        \"audience_thanks\": \"شكراً لكم مستمعينا على تخصيص وقتكم للاستماع إلينا.\",\n",
      "        \"call_to_action\": \"إذا أعجبكم الموضوع، شاركوا آرائكم معنا على منصات التواصل الاجتماعي، ولا تنسوا متابعة الحلقات القادمة.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة من 'نبض الثقافة'.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من عرف قدر نفسه لم يهلك.\",\n",
      "      \"اللغة وعاء الفكر.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"جهود الإمارات في تطوير نموذج 'جايس'.\",\n",
      "      \"مبادرات السعودية في الذكاء الاصطناعي مثل 'الحوراء'.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي معتدل يناسب الأسلوب التحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام بعض الكلمات باللهجة العربية الفصحى مع لمسات محلية عند الحاجة.\",\n",
      "    \"vocabulary_richness\": \"مصطلحات تقنية وثقافية مع شرح بسيط.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"الإيقاع متوازن بين التعمق في النقاط وبين الانتقال للموضوع التالي.\",\n",
      "    \"pause_points\": \"توقف طبيعي بعد كل نقطة نقاشية للسماح بالتفكير.\",\n",
      "    \"emphasis_moments\": \"تأكيد على النقاط المتعلقة بتطوير نماذج عربية وتأثير الذكاء الاصطناعي على اللغة.\"\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"natural_interruptions\": [\n",
      "      \"سامي: د. ليلى، لحظة، هل تعنين أن اللغة العربية قد تصبح لغة نادرة في المستقبل؟\",\n",
      "      \"سامي: هذا يذكرني بشيء قرأته مؤخراً عن تأثير التكنولوجيا على اللهجات المحلية.\"\n",
      "    ],\n",
      "    \"emotional_reactions\": [\n",
      "      \"سامي: هذا فعلاً شيء يدعو للتفكير العميق، كيف يمكن أن يحدث هذا؟\",\n",
      "      \"د. ليلى: أشعر بالفخر عندما أرى مبادرات عربية تنافس عالمياً.\"\n",
      "    ],\n",
      "    \"personal_stories\": [\n",
      "      \"سامي: أذكر أنني كنت أبحث عن قصص أطفال بالعربية لابنتي، ووجدت أن الخيارات الرقمية قليلة جداً.\",\n",
      "      \"د. ليلى: عندما بدأت البحث في هذا المجال، لاحظت كيف أن كثيراً من المفاهيم العربية تُترجم بشكل خاطئ.\"\n",
      "    ],\n",
      "    \"humorous_moments\": [\n",
      "      \"سامي: تخيل لو كان الذكاء الاصطناعي يحاول فهم الأمثال العربية، مثل 'ضربني وبكى سبقني واشتكى'، كيف سيفسرها؟\"\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"host_strengths\": \"سامي الجابري بارع في طرح الأسئلة التي تحفز التفكير ويجعل النقاش ممتعاً ومفيداً.\",\n",
      "    \"guest_expertise\": \"د. ليلى العمري تمتلك خبرة عميقة في مجال الذكاء الاصطناعي واللغويات، مما يجعلها قادرة على تقديم رؤى علمية مدعومة بالأمثلة.\",\n",
      "    \"natural_chemistry\": \"التفاعل بين سامي وليلى يتسم بالتوازن بين الفضول الصحفي والتخصص الأكاديمي، مما يجعل الحوار غني وممتع.\",\n",
      "    \"tension_points\": \"سامي قد يطرح أسئلة تستفز التفكير النقدي، مثل التركيز على الفجوة بين المبادرات الحكومية والمجتمعية، مما يدعو ليلى للدفاع عن وجهة نظرها.\",\n",
      "    \"collaboration_moments\": \"لحظات يتفق فيها سامي وليلى على أهمية المبادرات المحلية ودور الأفراد في تعزيز المحتوى العربي.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "style_enhancer = DialogueContentEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "style_enhanced_result = style_enhancer.enhance_dialogue_content(topic, information, classification_result, persona_result, outline_result)\n",
    "print(style_enhanced_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79cd062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalPolishEnhancer:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def add_final_polish(self, topic, information, classification_result, personas_result, enhanced_content_result):\n",
    "        \"\"\"\n",
    "        Step 5: Add final polish and spontaneity for natural flow\n",
    "        \n",
    "        Args:\n",
    "            topic: Main topic of the podcast episode\n",
    "            information: Background information about the topic\n",
    "            classification_result: JSON string from Step 1 classification\n",
    "            personas_result: JSON string from Step 2 personas\n",
    "            enhanced_content_result: JSON string from Step 4 enhanced content\n",
    "            \n",
    "        Returns:\n",
    "            Final V1-style outline with complete natural flow elements\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse inputs\n",
    "        import json\n",
    "        try:\n",
    "            classification = json.loads(classification_result)\n",
    "            personas = json.loads(personas_result)\n",
    "            enhanced_content = json.loads(enhanced_content_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid JSON provided\")\n",
    "        \n",
    "        # Extract key info\n",
    "        primary_category = classification.get(\"primary_category\", \"\")\n",
    "        optimal_style = classification.get(\"optimal_style\", \"\")\n",
    "        cultural_sensitivity = classification.get(\"cultural_sensitivity_level\", \"\")\n",
    "        \n",
    "        host = personas.get(\"host\", {})\n",
    "        guest = personas.get(\"guest\", {})\n",
    "        host_name = host.get('name', 'المقدم')\n",
    "        guest_name = guest.get('name', 'الضيف')\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في إضافة اللمسات الأخيرة للمحادثات لجعلها طبيعية وتلقائية تماماً.\n",
    "\n",
    "المهمة: أضف اللمسات الأخيرة والتدفق الطبيعي للمحتوى المحسن.\n",
    "\n",
    "الموضوع: {topic}\n",
    "المعلومات: {information}\n",
    "\n",
    "السياق:\n",
    "- الفئة: {primary_category}\n",
    "- الأسلوب: {optimal_style}\n",
    "- الحساسية الثقافية: {cultural_sensitivity}\n",
    "\n",
    "الشخصيات:\n",
    "- المقدم: {host_name} - {host.get('speaking_style', '')}\n",
    "- الضيف: {guest_name} - {guest.get('speaking_style', '')}\n",
    "\n",
    "المحتوى المحسن الحالي:\n",
    "{enhanced_content_result}\n",
    "\n",
    "أضف التحسينات النهائية التالية:\n",
    "\n",
    "1. حسّن \"spontaneous_moments\" بإضافة المزيد من التفاصيل:\n",
    "   - أضف المزيد من \"natural_interruptions\" محددة\n",
    "   - أضف المزيد من \"emotional_reactions\" واقعية\n",
    "   - أضف المزيد من \"personal_stories\" مناسبة للشخصيات\n",
    "   - أضف المزيد من \"humorous_moments\" مرتبطة بالموضوع\n",
    "\n",
    "2. حسّن \"personality_interactions\" بتفاصيل أكثر:\n",
    "   - اجعل \"natural_chemistry\" أكثر تحديداً\n",
    "   - أضف تفاصيل لـ \"tension_points\" \n",
    "   - اجعل \"collaboration_moments\" أكثر وضوحاً\n",
    "\n",
    "3. أضف قسم جديد \"shared_experiences\":\n",
    "   {{\n",
    "       \"common_ground\": [\n",
    "           \"نقاط تشابه بين المقدم والضيف\",\n",
    "           \"تجارب مشتركة يمكن أن يتحدثا عنها\"\n",
    "       ],\n",
    "       \"generational_perspectives\": [\n",
    "           \"اختلافات جيلية قد تظهر في النقاش\",\n",
    "           \"وجهات نظر مختلفة بناء على العمر والخبرة\"\n",
    "       ]\n",
    "   }}\n",
    "\n",
    "4. أضف قسم جديد \"contemporary_relevance\":\n",
    "   {{\n",
    "       \"current_events\": [\n",
    "           \"أحداث جارية مرتبطة بالموضوع\",\n",
    "           \"تطورات حديثة في المجال\"\n",
    "       ],\n",
    "       \"future_implications\": [\n",
    "           \"التأثيرات المستقبلية للموضوع\",\n",
    "           \"ما يمكن توقعه في السنوات القادمة\"\n",
    "       ]\n",
    "   }}\n",
    "\n",
    "5. حسّن أقسام \"cultural_context\" بمزيد من التفاصيل:\n",
    "   - أضف المزيد من \"proverbs_sayings\"\n",
    "   - أضف المزيد من \"regional_references\"\n",
    "   - اجعل \"shared_experiences\" أكثر تحديداً\n",
    "\n",
    "متطلبات نهائية:\n",
    "- احتفظ بكل المحتوى الموجود من الخطوة 4\n",
    "- أضف التحسينات النهائية فقط\n",
    "- اكتب محتوى محدد وليس عام\n",
    "- اجعل كل إضافة مرتبطة بالموضوع: {topic}\n",
    "- اجعل الشخصيات تبدو حقيقية ومتفاعلة\n",
    "- استخدم أسماء الشخصيات ({host_name}, {guest_name})\n",
    "- اجعل التدفق طبيعي للغاية\n",
    "- لا تضع علامات ```json\n",
    "- أرجع JSON كامل ونهائي\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في إضافة اللمسات الأخيرة للمحادثات الطبيعية. الأسلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8  # High creativity for final spontaneity\n",
    "        )\n",
    "        \n",
    "        # Parse and reformat the JSON for proper structure\n",
    "        try:\n",
    "            import json\n",
    "            result_json = json.loads(response.choices[0].message.content)\n",
    "            return json.dumps(result_json, ensure_ascii=False, indent=2)\n",
    "        except:\n",
    "            # If parsing fails, return raw response\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def validate_final_outline(self, final_json):\n",
    "        \"\"\"\n",
    "        Validate the final polished outline\n",
    "        \"\"\"\n",
    "        required_new_elements = [\"shared_experiences\", \"contemporary_relevance\"]\n",
    "        \n",
    "        # Enhanced elements that should be richer\n",
    "        enhanced_elements = {\n",
    "            \"spontaneous_moments\": [\"natural_interruptions\", \"emotional_reactions\", \"personal_stories\", \"humorous_moments\"],\n",
    "            \"personality_interactions\": [\"natural_chemistry\", \"tension_points\", \"collaboration_moments\"]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            import json\n",
    "            final_outline = json.loads(final_json)\n",
    "            \n",
    "            missing_elements = []\n",
    "            \n",
    "            # Check new sections\n",
    "            for element in required_new_elements:\n",
    "                if element not in final_outline:\n",
    "                    missing_elements.append(element)\n",
    "            \n",
    "            # Check enhanced spontaneous moments\n",
    "            spont_moments = final_outline.get(\"spontaneous_moments\", {})\n",
    "            for element in enhanced_elements[\"spontaneous_moments\"]:\n",
    "                if element not in spont_moments:\n",
    "                    missing_elements.append(f\"spontaneous_moments.{element}\")\n",
    "                elif len(spont_moments.get(element, [])) < 2:\n",
    "                    missing_elements.append(f\"spontaneous_moments.{element} (needs at least 2 items)\")\n",
    "            \n",
    "            # Check enhanced personality interactions\n",
    "            personality = final_outline.get(\"personality_interactions\", {})\n",
    "            for element in enhanced_elements[\"personality_interactions\"]:\n",
    "                if element not in personality:\n",
    "                    missing_elements.append(f\"personality_interactions.{element}\")\n",
    "            \n",
    "            if missing_elements:\n",
    "                return False, f\"Missing final elements: {missing_elements}\"\n",
    "            \n",
    "            return True, \"Final outline validation successful - ready for V1 script generation\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, \"Invalid JSON format\"\n",
    "\n",
    "    def analyze_final_quality(self, final_json):\n",
    "        \"\"\"\n",
    "        Analyze the quality and completeness of the final outline\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            final_outline = json.loads(final_json)\n",
    "            \n",
    "            analysis = {}\n",
    "            \n",
    "            # Check V1 compatibility\n",
    "            required_v1_sections = [\"episode_topic\", \"personas\", \"conversation_flow\", \"spontaneous_moments\", \"personality_interactions\"]\n",
    "            analysis[\"v1_compatible\"] = all(section in final_outline for section in required_v1_sections)\n",
    "            \n",
    "            # Check conversation flow completeness\n",
    "            conv_flow = final_outline.get(\"conversation_flow\", {})\n",
    "            analysis[\"has_complete_flow\"] = all(section in conv_flow for section in [\"intro1\", \"intro2\", \"main_discussion\", \"closing\"])\n",
    "            \n",
    "            # Check spontaneous moments richness\n",
    "            spont_moments = final_outline.get(\"spontaneous_moments\", {})\n",
    "            spont_count = sum(len(spont_moments.get(key, [])) for key in [\"natural_interruptions\", \"personal_stories\", \"humorous_moments\"])\n",
    "            analysis[\"spontaneous_richness\"] = spont_count\n",
    "            analysis[\"adequate_spontaneity\"] = spont_count >= 6\n",
    "            \n",
    "            # Check cultural integration depth\n",
    "            cultural = final_outline.get(\"cultural_context\", {})\n",
    "            cultural_count = sum(len(cultural.get(key, [])) for key in [\"proverbs_sayings\", \"regional_references\", \"shared_experiences\"])\n",
    "            analysis[\"cultural_depth\"] = cultural_count\n",
    "            analysis[\"adequate_culture\"] = cultural_count >= 4\n",
    "            \n",
    "            # Check main discussion enhancement\n",
    "            main_disc = conv_flow.get(\"main_discussion\", [])\n",
    "            enhanced_points = sum(1 for point in main_disc if all(key in point for key in [\"spontaneous_triggers\", \"cultural_references\", \"disagreement_points\"]))\n",
    "            analysis[\"enhanced_discussion_points\"] = enhanced_points\n",
    "            analysis[\"all_discussions_enhanced\"] = enhanced_points == len(main_disc)\n",
    "            \n",
    "            # Overall V1 readiness score\n",
    "            v1_readiness_indicators = [\n",
    "                analysis[\"v1_compatible\"],\n",
    "                analysis[\"has_complete_flow\"],\n",
    "                analysis[\"adequate_spontaneity\"],\n",
    "                analysis[\"adequate_culture\"],\n",
    "                analysis[\"all_discussions_enhanced\"]\n",
    "            ]\n",
    "            analysis[\"v1_readiness_score\"] = sum(v1_readiness_indicators)\n",
    "            analysis[\"ready_for_v1_script_generation\"] = analysis[\"v1_readiness_score\"] >= 4\n",
    "            analysis[\"perfect_v1_outline\"] = analysis[\"v1_readiness_score\"] == 5\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not analyze final quality\"}\n",
    "\n",
    "    def create_v1_summary(self, final_json):\n",
    "        \"\"\"\n",
    "        Create a summary showing V1 compatibility\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import json\n",
    "            final_outline = json.loads(final_json)\n",
    "            \n",
    "            summary = {}\n",
    "            \n",
    "            # Extract key V1 elements\n",
    "            conv_flow = final_outline.get(\"conversation_flow\", {})\n",
    "            summary[\"intro1_ready\"] = bool(conv_flow.get(\"intro1\", {}).get(\"opening_line\"))\n",
    "            summary[\"main_points_count\"] = len(conv_flow.get(\"main_discussion\", []))\n",
    "            summary[\"spontaneous_elements\"] = len(final_outline.get(\"spontaneous_moments\", {}).get(\"natural_interruptions\", []))\n",
    "            summary[\"cultural_references\"] = len(final_outline.get(\"cultural_context\", {}).get(\"proverbs_sayings\", []))\n",
    "            summary[\"personality_defined\"] = bool(final_outline.get(\"personality_interactions\", {}).get(\"natural_chemistry\"))\n",
    "            \n",
    "            # V1 script generation readiness\n",
    "            summary[\"v1_script_ready\"] = all([\n",
    "                summary[\"intro1_ready\"],\n",
    "                summary[\"main_points_count\"] >= 3,\n",
    "                summary[\"spontaneous_elements\"] >= 2,\n",
    "                summary[\"personality_defined\"]\n",
    "            ])\n",
    "            \n",
    "            return summary\n",
    "            \n",
    "        except:\n",
    "            return {\"error\": \"Could not create V1 summary\"}\n",
    "\n",
    "# Usage:\n",
    "# polisher = FinalPolishEnhancer(deployment, \"Fanar\")\n",
    "# final_outline = polisher.add_final_polish(topic, information, classification_result, personas_result, enhanced_content_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fa49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"episode_topic\": \"الذكاء الاصطناعي والهوية العربية: كيف نحافظ على ثقافتنا في العصر الرقمي\",\n",
      "  \"personas\": {\n",
      "    \"host\": {\n",
      "      \"name\": \"سامي الجابري\",\n",
      "      \"background\": \"صحفي مهتم بالتكنولوجيا والثقافة العربية.\",\n",
      "      \"speaking_style\": \"يطرح أسئلة مباشرة ويسعى لتوضيح الأفكار بأسلوب بسيط.\"\n",
      "    },\n",
      "    \"guest\": {\n",
      "      \"name\": \"د. ليلى العمري\",\n",
      "      \"background\": \"أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات.\",\n",
      "      \"speaking_style\": \"تشرح الأفكار بأسلوب أكاديمي مبسط مدعوم بالأمثلة.\"\n",
      "    }\n",
      "  },\n",
      "  \"conversation_flow\": {\n",
      "    \"intro1\": {\n",
      "      \"opening_line\": \"مرحباً بكم مستمعينا في بودكاست 'نبض الثقافة'، حيث نناقش القضايا التي تمس هويتنا وثقافتنا في عالم متغير.\",\n",
      "      \"podcast_introduction\": \"اليوم سنتحدث عن موضوع يشغل بال الكثيرين: الذكاء الاصطناعي والهوية العربية، وكيف يمكننا الحفاظ على ثقافتنا في العصر الرقمي.\",\n",
      "      \"episode_hook\": \"مع انتشار الذكاء الاصطناعي، هل يمكن لهذه التقنية أن تصبح حليفاً للثقافة العربية أم أنها تهدد بتهميشها؟\",\n",
      "      \"spontaneity_elements\": [\n",
      "        \"سامي: هل فكرت يوماً في تأثير التكنولوجيا على لغتك اليومية؟\",\n",
      "        \"سامي: يا ترى، لو كان الذكاء الاصطناعي يتحدث باللهجة المحلية، كيف سيكون الحوار؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"intro2\": {\n",
      "      \"topic_introduction\": \"الذكاء الاصطناعي أصبح جزءاً من حياتنا اليومية، ولكن هل نحن مستعدون لمواجهة تأثيراته على هويتنا الثقافية؟\",\n",
      "      \"guest_welcome\": \"معنا اليوم د. ليلى العمري، أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات. أهلاً وسهلاً بكِ د. ليلى.\",\n",
      "      \"guest_bio_highlight\": \"د. ليلى لديها خبرة طويلة في دراسة تأثير التكنولوجيا على اللغة والثقافة، وهي صوت مهم في هذا المجال.\",\n",
      "      \"transition_to_discussion\": \"دعينا نبدأ بالنظر إلى الوضع الحالي: كيف ترين تأثير الذكاء الاصطناعي على اللغة والثقافة العربية حتى الآن؟\",\n",
      "      \"cultural_connections\": [\n",
      "        \"سامي: أذكر أن جدتي كانت دائماً تقول 'اللغة وعاء الفكر'، هل تعتقدين أننا نفقد شيئاً من هذا الوعاء في ظل الذكاء الاصطناعي؟\"\n",
      "      ]\n",
      "    },\n",
      "    \"main_discussion\": [\n",
      "      {\n",
      "        \"point_title\": \"الفجوة الرقمية: هيمنة المحتوى الغربي\",\n",
      "        \"personal_angle\": \"سامي: أرقام المحتوى الرقمي مخيفة، 78% بالإنجليزية مقابل 3% فقط بالعربية. هل يمكننا سد هذه الفجوة؟ د. ليلى: هذه الفجوة تعكس تحديات كبيرة، ولكن هناك جهود بدأت تظهر مثل تطوير نماذج عربية كجايس والحوراء.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل تعتقدين أن الأجيال القادمة ستكون أكثر انفتاحاً على المحتوى العربي، أم أن الإنجليزية ستظل طاغية؟\",\n",
      "          \"سامي: لماذا برأيك المحتوى العربي يعاني من نقص كبير في المجال الرقمي مقارنة بلغات أخرى؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يجب أن نعتمد فقط على المبادرات الحكومية أم أن هناك دوراً أكبر للمجتمع المدني؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"القول الشائع: 'من عرف قدر نفسه لم يهلك'، يعبر عن أهمية إدراك قيمة لغتنا وثقافتنا في مواجهة المحتوى الغربي.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: هذا يقودني إلى سؤال مهم، هل النماذج الغربية للذكاء الاصطناعي قادرة على فهم الثقافة العربية حقاً؟\",\n",
      "        \"emotional_triggers\": \"الخوف من أن تصبح اللغة العربية مجرد لغة ثانوية في العالم الرقمي.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"نماذج الذكاء الاصطناعي والسياق الثقافي العربي\",\n",
      "        \"personal_angle\": \"سامي: معظم نماذج الذكاء الاصطناعي مدربة على بيانات غربية. هل هذا يعني أنها لا تفهمنا؟ د. ليلى: بالتأكيد، هذه النماذج قد تواجه صعوبة في فهم السياقات العربية، لكن تطوير نماذج محلية خطوة مهمة لتجاوز هذه العقبة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل يمكن أن تؤدي هذه النماذج إلى تحريف بعض المفاهيم الثقافية التقليدية؟\",\n",
      "          \"سامي: كيف يمكن أن تساعد اللغة العربية في إعادة صياغة هذه النماذج لتتناسب مع الهوية الثقافية؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يجب التركيز أكثر على تدريب النماذج الحالية أم بناء نماذج جديدة من الصفر؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"سامي: أذكر أنني قرأت عن مبادرة سعودية لتوثيق التراث الشعبي باستخدام الذكاء الاصطناعي، هل هذا نموذج يمكن أن نقتدي به؟\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: إذاً، يمكن للذكاء الاصطناعي أن يكون جزءاً من الحل وليس المشكلة، لكن كيف يمكننا ضمان ذلك عملياً؟\",\n",
      "        \"emotional_triggers\": \"الشعور بالفخر عندما يتم الحديث عن جهود عربية ريادية.\"\n",
      "      },\n",
      "      {\n",
      "        \"point_title\": \"الاستفادة من الذكاء الاصطناعي لتعزيز الثقافة\",\n",
      "        \"personal_angle\": \"سامي: هل يمكن للذكاء الاصطناعي أن يصبح أداة لتعزيز الثقافة العربية بدلاً من تهديدها؟ د. ليلى: نعم، إذا تم توجيهه بشكل صحيح، يمكن أن يساهم في نشر اللغة العربية وتوثيق التراث الثقافي بطرق مبتكرة.\",\n",
      "        \"spontaneous_triggers\": [\n",
      "          \"سامي: هل يمكن أن نرى قصائد المتنبي تُقرأ بأصوات ذكاء اصطناعي قريباً؟\",\n",
      "          \"سامي: ماذا لو استخدمنا الذكاء الاصطناعي لتعليم الأطفال اللغة العربية بطريقة ممتعة؟\"\n",
      "        ],\n",
      "        \"disagreement_points\": \"هل يمكن للتكنولوجيا أن تكون بديلاً عن التدخلات البشرية في الحفاظ على الثقافة؟\",\n",
      "        \"cultural_references\": [\n",
      "          \"د. ليلى: هناك مثل يقول 'اللغة هي روح الأمة'، وهذا يعكس أهمية استخدام التكنولوجيا للحفاظ عليها.\"\n",
      "        ],\n",
      "        \"natural_transitions\": \"سامي: هذا يقودني للتفكير في المستقبل، كيف يمكننا إعداد الأجيال القادمة لهذه التحديات؟\",\n",
      "        \"emotional_triggers\": \"الإلهام بفكرة أن التكنولوجيا يمكن أن تبني جسوراً بين الماضي والمستقبل.\"\n",
      "      }\n",
      "    ],\n",
      "    \"closing\": {\n",
      "      \"conclusion\": {\n",
      "        \"main_takeaways\": \"الذكاء الاصطناعي يمكن أن يكون تهديداً أو فرصة للثقافة العربية، حسب كيفية استخدامنا له.\",\n",
      "        \"guest_final_message\": \"أدعو الجميع لدعم المبادرات التي تهدف إلى تطوير محتوى عربي رقمي قوي، فهذا جزء من الحفاظ على هويتنا.\",\n",
      "        \"host_closing_thoughts\": \"التكنولوجيا ليست عدواً، بل أداة. علينا أن نتعلم كيف نستخدمها لصالحنا.\"\n",
      "      },\n",
      "      \"outro\": {\n",
      "        \"guest_appreciation\": \"شكراً جزيلاً د. ليلى على مشاركتك القيمة اليوم.\",\n",
      "        \"audience_thanks\": \"شكراً لكم مستمعينا على تخصيص وقتكم للاستماع إلينا.\",\n",
      "        \"call_to_action\": \"إذا أعجبكم الموضوع، شاركوا آرائكم معنا على منصات التواصل الاجتماعي، ولا تنسوا متابعة الحلقات القادمة.\",\n",
      "        \"final_goodbye\": \"إلى اللقاء في الحلقة القادمة من 'نبض الثقافة'.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"cultural_context\": {\n",
      "    \"proverbs_sayings\": [\n",
      "      \"من عرف قدر نفسه لم يهلك.\",\n",
      "      \"اللغة وعاء الفكر.\",\n",
      "      \"الجذور العميقة لا تخشى الرياح.\"\n",
      "    ],\n",
      "    \"regional_references\": [\n",
      "      \"جهود الإمارات في تطوير نموذج 'جايس'.\",\n",
      "      \"مبادرات السعودية في الذكاء الاصطناعي مثل 'الحوراء'.\",\n",
      "      \"مشروع 'ثنائيات اللغة' في مصر لتعزيز المحتوى العربي.\"\n",
      "    ]\n",
      "  },\n",
      "  \"language_style\": {\n",
      "    \"formality_level\": \"رسمي معتدل يناسب الأسلوب التحليلي.\",\n",
      "    \"dialect_touches\": \"استخدام بعض الكلمات باللهجة العربية الفصحى مع لمسات محلية عند الحاجة.\",\n",
      "    \"vocabulary_richness\": \"مصطلحات تقنية وثقافية مع شرح بسيط.\"\n",
      "  },\n",
      "  \"technical_notes\": {\n",
      "    \"pacing_guidance\": \"الإيقاع متوازن بين التعمق في النقاط وبين الانتقال للموضوع التالي.\",\n",
      "    \"pause_points\": \"توقف طبيعي بعد كل نقطة نقاشية للسماح بالتفكير.\",\n",
      "    \"emphasis_moments\": \"تأكيد على النقاط المتعلقة بتطوير نماذج عربية وتأثير الذكاء الاصطناعي على اللغة.\"\n",
      "  },\n",
      "  \"spontaneous_moments\": {\n",
      "    \"natural_interruptions\": [\n",
      "      \"سامي: د. ليلى، لحظة، هل تعنين أن اللغة العربية قد تصبح لغة نادرة في المستقبل؟\",\n",
      "      \"سامي: هذا يذكرني بشيء قرأته مؤخراً عن تأثير التكنولوجيا على اللهجات المحلية.\",\n",
      "      \"سامي: هل تعتقدين أن اللهجات المختلفة داخل العالم العربي يمكن أن تكون عائقاً أمام تطوير نماذج موحدة للذكاء الاصطناعي؟\"\n",
      "    ],\n",
      "    \"emotional_reactions\": [\n",
      "      \"سامي: هذا فعلاً شيء يدعو للتفكير العميق، كيف يمكن أن يحدث هذا؟\",\n",
      "      \"د. ليلى: أشعر بالفخر عندما أرى مبادرات عربية تنافس عالمياً.\",\n",
      "      \"سامي: بصراحة، هذا يجعلني أشعر بقلق حقيقي على مستقبل اللغة العربية.\"\n",
      "    ],\n",
      "    \"personal_stories\": [\n",
      "      \"سامي: أذكر أنني كنت أبحث عن قصص أطفال بالعربية لابنتي، ووجدت أن الخيارات الرقمية قليلة جداً.\",\n",
      "      \"د. ليلى: عندما بدأت البحث في هذا المجال، لاحظت كيف أن كثيراً من المفاهيم العربية تُترجم بشكل خاطئ.\",\n",
      "      \"د. ليلى: ذات مرة حضرت معرضاً تقنياً، وكان علي شرح معنى 'الكرم العربي' لأحد مطوري الذكاء الاصطناعي الأجانب.\"\n",
      "    ],\n",
      "    \"humorous_moments\": [\n",
      "      \"سامي: تخيل لو كان الذكاء الاصطناعي يحاول فهم الأمثال العربية، مثل 'ضربني وبكى سبقني واشتكى'، كيف سيفسرها؟\",\n",
      "      \"سامي: ما رأيك لو حاول الذكاء الاصطناعي كتابة أغنية شعبية باللهجة المصرية؟\"\n",
      "    ]\n",
      "  },\n",
      "  \"personality_interactions\": {\n",
      "    \"host_strengths\": \"سامي الجابري بارع في طرح الأسئلة التي تحفز التفكير ويجعل النقاش ممتعاً ومفيداً.\",\n",
      "    \"guest_expertise\": \"د. ليلى العمري تمتلك خبرة عميقة في مجال الذكاء الاصطناعي واللغويات، مما يجعلها قادرة على تقديم رؤى علمية مدعومة بالأمثلة.\",\n",
      "    \"natural_chemistry\": \"التفاعل بين سامي وليلى يتسم بالتوازن بين الفضول الصحفي والتخصص الأكاديمي، كما أن سامي يضيف لمسة من الاستفسارات العاطفية التي تجعل ليلى تعمق النقاش بشكل أكثر إنسانية.\",\n",
      "    \"tension_points\": \"سامي قد يطرح أسئلة تستفز التفكير النقدي، مثل التركيز على الفجوة بين المبادرات الحكومية والمجتمعية، مما يدعو ليلى للدفاع عن وجهة نظرها حول أهمية التعاون بين الجانبين.\",\n",
      "    \"collaboration_moments\": \"يتفق سامي وليلى بشكل واضح عند الحديث عن أهمية تعزيز المحتوى العربي، حيث يضيف سامي مثالاً من حياته الشخصية بينما تقدم ليلى حلولاً عملية للتحديات.\"\n",
      "  },\n",
      "  \"shared_experiences\": {\n",
      "    \"common_ground\": [\n",
      "      \"كلاهما متفق على أهمية الحفاظ على اللغة العربية في المجال الرقمي.\",\n",
      "      \"كلاهما لديه تجارب مع نقص المحتوى العربي الرقمي.\"\n",
      "    ],\n",
      "    \"generational_perspectives\": [\n",
      "      \"سامي يمثل وجهة نظر جيل يرتبط بالهوية الثقافية التقليدية ويبحث عن حلول عصرية، بينما ليلى تمثل جيل الباحثين الذين يرون في التكنولوجيا فرصة للتطوير.\",\n",
      "      \"قد تظهر اختلافات في وجهات النظر حول سرعة التغيير وكيفية التعامل معه بين الجيلين.\"\n",
      "    ]\n",
      "  },\n",
      "  \"contemporary_relevance\": {\n",
      "    \"current_events\": [\n",
      "      \"إطلاق الإمارات لنموذج 'جايس' كأول نموذج ذكاء اصطناعي باللغة العربية.\",\n",
      "      \"مبادرات سعودية حديثة لتوثيق التراث باستخدام الذكاء الاصطناعي.\"\n",
      "    ],\n",
      "    \"future_implications\": [\n",
      "      \"الذكاء الاصطناعي قد يصبح أداة رئيسية في الحفاظ على التراث العربي وتعزيزه.\",\n",
      "      \"في السنوات القادمة، قد نشهد نماذج ذكاء اصطناعي تفهم اللهجات المحلية بشكل أفضل.\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "polisher = FinalPolishEnhancer(deployment, \"Fanar-C-1-8.7B\")\n",
    "final_outline = polisher.add_final_polish(topic, information, classification_result, persona_result, style_enhanced_result)\n",
    "print(final_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae7f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridScriptGenerator:\n",
    "    def __init__(self, deployment, model=\"gpt-4o\"):\n",
    "        self.model = model\n",
    "        self.deployment = deployment\n",
    "        \n",
    "        # V1-style rich dialogue examples\n",
    "        self.arabic_dialogue_styles = {\n",
    "            \"حواري\": {\n",
    "                \"host_example\": \"أحمد: يا أهلاً نور! كيف الحال؟ اممم... قوليلي، شو اللي خلاكِ تدخلي هذا المجال؟ <happy>\",\n",
    "                \"guest_example\": \"نور: أهلاً أحمد! الله يعطيك العافية... يعني بصراحة، هاي قصة طويلة شوي [pause: 2s] بس باختصار، كنت أشوف المشاكل حولي وأقول: ليش ما نحلها بالتقنية؟\"\n",
    "            },\n",
    "            \"تعليمي\": {\n",
    "                \"host_example\": \"أحمد: اممم... نور، ممكن تشرحي لنا بطريقة بسيطة، يعني شلون تشتغل هاي التقنية؟ <happy>\",\n",
    "                \"guest_example\": \"نور: طبعاً أحمد! يعني... اههه كيف أشرح [pause: 2s] تخيل إنك عندك نظام ذكي جداً، بس هذا النظام مش إنسان، هو كمبيوتر! واو صح؟\"\n",
    "            },\n",
    "            \"ترفيهي\": {\n",
    "                \"host_example\": \"أحمد: هاي نور! <happy> قوليلي، إيش أغرب موقف صار معكِ في الشغل؟ يعني شي يضحك؟\",\n",
    "                \"guest_example\": \"نور: ههههه واو أحمد! بصراحة مواقف كثيرة... اممم مرة كنت أجرب البرنامج وفجأة [pause: 2s] خلاص ما عاد يشتغل! قعدت أصرخ: وين راح كودي؟! <surprise>\"\n",
    "            },\n",
    "            \"تحليلي\": {\n",
    "                \"host_example\": \"أحمد: نور، بناءً على الإحصائيات الحديثة، وش رايكِ في التحديات الرئيسية اللي تواجه هذا المجال؟\",\n",
    "                \"guest_example\": \"نور: سؤال ممتاز أحمد... يعني إذا نتكلم بشكل تحليلي، عندنا ثلاث تحديات أساسية [pause: 2s] أولها التقنية، ثانيها التمويل، وثالثها... اممم التقبل المجتمعي\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # V1-style comprehensive fillers guide\n",
    "        self.fillers_guide = \"\"\"\n",
    "استخدم حشو المحادثة الطبيعي بكثافة متوسطة:\n",
    "- تفكير: اممم، اههه، يعني كيف أقول، خلاص، شوف\n",
    "- تأكيد: طبعاً، تماماً، بالضبط، صحيح، أكيد\n",
    "- تردد: يعنييييي، يعني، اه ما أدري، مش عارف\n",
    "- انفعال: واو، يا الله، ما شاء الله، الله يعطيك العافية\n",
    "- ربط: بس، لكن، وبعدين، يا أخي، اسمع، انتبه\n",
    "- خليجي خفيف: شلون، وش رايك، زين، ماشي الحال، الله يعافيك\n",
    "\"\"\"\n",
    "\n",
    "    def generate_enhanced_intro(self, topic, final_outline_result, optimal_style):\n",
    "        \"\"\"\n",
    "        Step 1: Generate enhanced intro (intro1 + intro2) - V1 enhancer style\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract outline elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        intro1 = conv_flow.get(\"intro1\", {})\n",
    "        intro2 = conv_flow.get(\"intro2\", {})\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style examples\n",
    "        style_examples = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في كتابة مقدمات البودكاست العربي الطبيعية والجذابة.\n",
    "\n",
    "المهمة: اكتب مقدمة كاملة طبيعية (intro1 + intro2) تجمع بين الترحيب وتقديم الموضوع والضيف.\n",
    "\n",
    "أمثلة على الأسلوب المطلوب:\n",
    "المقدم: {style_examples[\"host_example\"]}\n",
    "الضيف: {style_examples[\"guest_example\"]}\n",
    "\n",
    "عناصر المقدمة من المخطط:\n",
    "الافتتاحية: {intro1.get('opening_line', '')}\n",
    "تعريف البودكاست: {intro1.get('podcast_introduction', '')}\n",
    "جملة التشويق: {intro1.get('episode_hook', '')}\n",
    "العناصر التلقائية: {intro1.get('spontaneity_elements', [])}\n",
    "\n",
    "تقديم الموضوع: {intro2.get('topic_introduction', '')}\n",
    "ترحيب بالضيف: {intro2.get('guest_welcome', '')}\n",
    "تعريف الضيف: {intro2.get('guest_bio_highlight', '')}\n",
    "الروابط الثقافية: {intro2.get('cultural_connections', [])}\n",
    "\n",
    "المراجع الثقافية المتاحة: {cultural_context.get('proverbs_sayings', [])}\n",
    "\n",
    "{self.fillers_guide}\n",
    "\n",
    "متطلبات المقدمة:\n",
    "1. ابدأ بالمقدم {host_name} يتحدث منفرداً (intro1)\n",
    "2. ثم أدخل الضيف {guest_name} في المحادثة (intro2)\n",
    "3. استخدم 70% فصحى و 30% لمسات خليجية خفيفة\n",
    "4. أضف حشو طبيعي متوسط الكثافة\n",
    "5. أدرج العناصر التلقائية والثقافية بطبيعية\n",
    "6. اجعل الانتقال سلس من المقدم لوحده إلى حوار مع الضيف\n",
    "7. استخدم أسماء الشخصيات الفعلية\n",
    "8. أضف تفاعلات طبيعية: <happy>, <pause: 2s>, <overlap>\n",
    "9. اجعل المقدمة مشوقة ومدتها 2-3 دقائق\n",
    "10. انته بانتقال طبيعي للنقاش الرئيسي\n",
    "\n",
    "تنسيق الحوار:\n",
    "المقدم: [النص]\n",
    "الضيف: [النص]\n",
    "\n",
    "اكتب المقدمة كاملة:\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في كتابة مقدمات بودكاست عربية طبيعية وجذابة. الأسلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_flowing_main_discussion(self, topic, final_outline_result, optimal_style, intro_dialogue):\n",
    "        \"\"\"\n",
    "        Step 2: Generate flowing main discussion (all 3 points) - V1 dialogue generator style\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract outline elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        main_discussion = conv_flow.get(\"main_discussion\", [])\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        spontaneous_moments = outline.get(\"spontaneous_moments\", {})\n",
    "        personality_interactions = outline.get(\"personality_interactions\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style examples\n",
    "        style_examples = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        # Build main points summary\n",
    "        points_summary = \"\"\n",
    "        for i, point in enumerate(main_discussion):\n",
    "            points_summary += f\"\"\"\n",
    "النقطة {i+1}: {point.get('point_title', '')}\n",
    "- الزاوية الشخصية: {point.get('personal_angle', '')}\n",
    "- المحفزات التلقائية: {point.get('spontaneous_triggers', [])}\n",
    "- نقاط الاختلاف: {point.get('disagreement_points', '')}\n",
    "- المراجع الثقافية: {point.get('cultural_references', [])}\n",
    "- المحفزات العاطفية: {point.get('emotional_triggers', '')}\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في كتابة الحوارات الطبيعية المتدفقة للبودكاست العربي.\n",
    "\n",
    "المهمة: اكتب النقاش الرئيسي كحوار متدفق طبيعي يغطي جميع النقاط الثلاث.\n",
    "\n",
    "أمثلة على الأسلوب المطلوب:\n",
    "المقدم: {style_examples[\"host_example\"]}\n",
    "الضيف: {style_examples[\"guest_example\"]}\n",
    "\n",
    "السياق - نهاية المقدمة:\n",
    "{intro_dialogue[-300:]}\n",
    "\n",
    "النقاط المطلوب تغطيتها:\n",
    "{points_summary}\n",
    "\n",
    "عناصر التلقائية المتاحة:\n",
    "- المقاطعات الطبيعية: {spontaneous_moments.get('natural_interruptions', [])}\n",
    "- ردود الفعل العاطفية: {spontaneous_moments.get('emotional_reactions', [])}\n",
    "- القصص الشخصية: {spontaneous_moments.get('personal_stories', [])}\n",
    "- اللحظات المرحة: {spontaneous_moments.get('humorous_moments', [])}\n",
    "\n",
    "ديناميكية الشخصيات:\n",
    "- الكيمياء الطبيعية: {personality_interactions.get('natural_chemistry', '')}\n",
    "- نقاط التوتر: {personality_interactions.get('tension_points', '')}\n",
    "- لحظات التعاون: {personality_interactions.get('collaboration_moments', '')}\n",
    "\n",
    "{self.fillers_guide}\n",
    "\n",
    "متطلبات النقاش:\n",
    "1. ابدأ بانتقال طبيعي من المقدمة\n",
    "2. غط النقاط الثلاث بحوار متدفق وطبيعي\n",
    "3. لا تلتزم بترتيب النقاط بصرامة - دع الحوار يتدفق\n",
    "4. أدرج العناصر التلقائية والثقافية بطبيعية\n",
    "5. أضف نقاط اختلاف وجدل صحي\n",
    "6. استخدم القصص الشخصية والمراجع الثقافية\n",
    "7. اجعل {host_name} و{guest_name} يتفاعلان بشخصيتهما\n",
    "8. أضف لحظات مرحة ومفاجئة\n",
    "9. استخدم 70% فصحى و 30% لمسات خليجية\n",
    "10. المدة: 6-7 دقائق من الحوار الطبيعي\n",
    "11. انته بتمهيد طبيعي للختام\n",
    "\n",
    "تنسيق الحوار:\n",
    "المقدم: [النص]\n",
    "الضيف: [النص]\n",
    "\n",
    "اكتب النقاش كاملاً:\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في كتابة حوارات متدفقة وطبيعية. الأسلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_natural_closing(self, topic, final_outline_result, optimal_style, intro_dialogue, main_dialogue):\n",
    "        \"\"\"\n",
    "        Step 3: Generate natural closing (conclusion + outro) - V1 enhancer style\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Extract outline elements\n",
    "        conv_flow = outline.get(\"conversation_flow\", {})\n",
    "        closing = conv_flow.get(\"closing\", {})\n",
    "        personas = outline.get(\"personas\", {})\n",
    "        cultural_context = outline.get(\"cultural_context\", {})\n",
    "        \n",
    "        host_name = personas.get(\"host\", {}).get(\"name\", \"المقدم\")\n",
    "        guest_name = personas.get(\"guest\", {}).get(\"name\", \"الضيف\")\n",
    "        \n",
    "        # Get style examples\n",
    "        style_examples = self.arabic_dialogue_styles.get(optimal_style, self.arabic_dialogue_styles[\"تعليمي\"])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "أنت خبير في كتابة خواتيم البودكاست العربي المؤثرة والطبيعية.\n",
    "\n",
    "المهمة: اكتب ختام طبيعي ومؤثر (خلاصة + وداع) للحلقة.\n",
    "\n",
    "أمثلة على الأسلوب المطلوب:\n",
    "المقدم: {style_examples[\"host_example\"]}\n",
    "\n",
    "السياق - نهاية النقاش:\n",
    "{main_dialogue[-300:]}\n",
    "\n",
    "عناصر الختام من المخطط:\n",
    "الخلاصات المهمة: {closing.get('conclusion', {}).get('main_takeaways', '')}\n",
    "رسالة الضيف الختامية: {closing.get('conclusion', {}).get('guest_final_message', '')}\n",
    "أفكار المقدم الختامية: {closing.get('conclusion', {}).get('host_closing_thoughts', '')}\n",
    "\n",
    "شكر الضيف: {closing.get('outro', {}).get('guest_appreciation', '')}\n",
    "شكر المستمعين: {closing.get('outro', {}).get('audience_thanks', '')}\n",
    "دعوة للتفاعل: {closing.get('outro', {}).get('call_to_action', '')}\n",
    "الوداع النهائي: {closing.get('outro', {}).get('final_goodbye', '')}\n",
    "\n",
    "المراجع الثقافية: {cultural_context.get('proverbs_sayings', [])}\n",
    "\n",
    "{self.fillers_guide}\n",
    "\n",
    "متطلبات الختام:\n",
    "1. ابدأ بانتقال طبيعي من النقاش\n",
    "2. لخص النقاط المهمة بطريقة طبيعية وليس آلية\n",
    "3. اجعل {guest_name} يقدم رسالة ختامية مؤثرة\n",
    "4. اجعل {host_name} يضيف أفكاره الختامية\n",
    "5. أضف شكر صادق ودافئ للضيف والمستمعين\n",
    "6. أدرج دعوة طبيعية للتفاعل\n",
    "7. استخدم لمسة ثقافية في الوداع\n",
    "8. اجعل النهاية تترك أثراً إيجابياً\n",
    "9. استخدم 70% فصحى و 30% لمسات خليجية\n",
    "10. المدة: 1-2 دقيقة مؤثرة\n",
    "\n",
    "تنسيق الحوار:\n",
    "المقدم: [النص]\n",
    "الضيف: [النص]\n",
    "\n",
    "اكتب الختام كاملاً:\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.deployment.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"أنت خبير في كتابة خواتيم مؤثرة وطبيعية. الأسلوب: {optimal_style}\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_complete_script(self, topic, final_outline_result):\n",
    "        \"\"\"\n",
    "        Generate complete script using 3-step hybrid approach\n",
    "        \"\"\"\n",
    "        \n",
    "        import json\n",
    "        try:\n",
    "            outline = json.loads(final_outline_result)\n",
    "        except:\n",
    "            raise ValueError(\"Invalid outline JSON\")\n",
    "        \n",
    "        # Determine optimal style from outline or default\n",
    "        optimal_style = \"تعليمي\"  # Default\n",
    "        if \"language_style\" in outline:\n",
    "            formality = outline[\"language_style\"].get(\"formality_level\", \"\")\n",
    "            if \"حواري\" in formality or \"ودي\" in formality:\n",
    "                optimal_style = \"حواري\"\n",
    "            elif \"تحليلي\" in formality:\n",
    "                optimal_style = \"تحليلي\"\n",
    "            elif \"مرح\" in formality or \"ترفيهي\" in formality:\n",
    "                optimal_style = \"ترفيهي\"\n",
    "        \n",
    "        print(f\"🎙️ بدء توليد السكريبت بأسلوب: {optimal_style}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Step 1: Enhanced Intro\n",
    "        print(\"📝 الخطوة 1: توليد المقدمة المحسنة...\")\n",
    "        intro_dialogue = self.generate_enhanced_intro(topic, final_outline_result, optimal_style)\n",
    "        print(\"✅ تم إنجاز المقدمة\")\n",
    "        \n",
    "        # Step 2: Flowing Main Discussion\n",
    "        print(\"📝 الخطوة 2: توليد النقاش المتدفق...\")\n",
    "        main_dialogue = self.generate_flowing_main_discussion(topic, final_outline_result, optimal_style, intro_dialogue)\n",
    "        print(\"✅ تم إنجاز النقاش الرئيسي\")\n",
    "        \n",
    "        # Step 3: Natural Closing\n",
    "        print(\"📝 الخطوة 3: توليد الختام الطبيعي...\")\n",
    "        closing_dialogue = self.generate_natural_closing(topic, final_outline_result, optimal_style, intro_dialogue, main_dialogue)\n",
    "        print(\"✅ تم إنجاز الختام\")\n",
    "        \n",
    "        # Combine all parts\n",
    "        complete_script = f\"\"\"=== المقدمة ===\n",
    "{intro_dialogue}\n",
    "\n",
    "=== النقاش الرئيسي ===\n",
    "{main_dialogue}\n",
    "\n",
    "=== الختام ===\n",
    "{closing_dialogue}\"\"\"\n",
    "        \n",
    "        print(\"🎉 تم إنجاز السكريبت الكامل!\")\n",
    "        \n",
    "        return {\n",
    "            \"intro\": intro_dialogue,\n",
    "            \"main_discussion\": main_dialogue,\n",
    "            \"closing\": closing_dialogue,\n",
    "            \"complete_script\": complete_script,\n",
    "            \"script_length\": len(complete_script),\n",
    "            \"estimated_duration\": \"10 دقائق تقريباً\",\n",
    "            \"style_used\": optimal_style\n",
    "        }\n",
    "\n",
    "# Usage:\n",
    "# generator = HybridScriptGenerator(deployment, \"Fanar\")\n",
    "# script_result = generator.generate_complete_script(topic, final_outline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️ بدء توليد السكريبت بأسلوب: تحليلي\n",
      "==================================================\n",
      "📝 الخطوة 1: توليد المقدمة المحسنة...\n",
      "✅ تم إنجاز المقدمة\n",
      "📝 الخطوة 2: توليد النقاش المتدفق...\n",
      "✅ تم إنجاز النقاش الرئيسي\n",
      "📝 الخطوة 3: توليد الختام الطبيعي...\n",
      "✅ تم إنجاز الختام\n",
      "🎉 تم إنجاز السكريبت الكامل!\n",
      "=== المقدمة ===\n",
      "المقدم: مرحباً بكم مستمعينا الكرام، في حلقة جديدة من بودكاست \"نبض الثقافة\"، حيث نغوص في أعماق القضايا التي تلامس هويتنا وثقافتنا في عالم يتغير بسرعة. أنا سامي الجابري، سعيد جداً أنكم معنا اليوم، ويا أخي، حلقتنا اليوم فعلاً مثيرة. يعني شوفوا، الذكاء الاصطناعي صار جزءاً من حياتنا اليومية، من التطبيقات اللي نستخدمها على الهاتف إلى الأدوات اللي بدأت تغيّر مسار الأعمال. بس، السؤال اللي يطرح نفسه: وش تأثير هذا كله على هويتنا العربية؟ <pause: 2s> \n",
      "\n",
      "المقدم: زين، يعني إذا فكرتوا شوي، هل الذكاء الاصطناعي ممكن يكون داعماً للثقافة العربية؟ أو بالعكس، يمكن يكون تهديد؟ أنا شخصياً دايماً أتساءل: لو الذكاء الاصطناعي صار يتحدث باللهجات المحلية مثلاً، كيف بيكون الحوار؟ وهل فعلاً بيعكس عمق حضارتنا؟ طبعاً الموضوع هذا كبير، وما نقدر نناقشه بدون خبرة عميقة. \n",
      "\n",
      "المقدم: عشان كذا، معنا اليوم ضيفة مميزة جداً، دكتورة ليلى العمري. هي أستاذة جامعية متخصصة في الذكاء الاصطناعي واللغويات، وصراحة ما شاء الله عليها، خبرتها طويلة في دراسة تأثير التكنولوجيا على اللغة والثقافة. أهلاً وسهلاً بكِ دكتورة ليلى، نورتي البودكاست.  \n",
      "\n",
      "الضيف: أهلاً وسهلاً سامي، الله يعطيك العافية، وشكراً على الاستضافة الكريمة. يعني بصراحة موضوع حلقتكم اليوم مهم جداً، وأعتقد إنه صار ضروري نناقشه بعمق.  \n",
      "\n",
      "المقدم: بالضبط، طبعاً دكتورة ليلى، عندك نظرة فريدة في هذا المجال. <happy> أذكر مرة قريتها لك مقولة عن اللغة وذكرتِ أنها \"وعاء الفكر\"، جدتي كانت دايماً تقول نفس الشي. هل تعتقدين أن هذا الوعاء بدأ يتأثر مع دخول الذكاء الاصطناعي؟  \n",
      "\n",
      "الضيف: صحيح سامي، يعني جدتك كانت على حق تماماً، اللغة فعلاً وعاء الفكر. لكن مع ظهور الذكاء الاصطناعي، أعتقد أننا بدأنا نواجه تحديات حقيقية. <pause: 2s> مثل ما قلت، هل التقنية هذه بتكون أداة للحفاظ على اللغة أم بتساهم في طمسها؟  \n",
      "\n",
      "المقدم: واو، كلامك فعلاً يفتح باب كبير للنقاش. زين دكتورة، خليني أقول لك شو رأيي بسرعة قبل ما ندخل في النقاش العميق... مستمعينا، استعدوا، لأن اللي جاي فعلاً بيكون مليء بالتفاصيل والأفكار الجديدة. يلا نبدأ! \n",
      "\n",
      "=== النقاش الرئيسي ===\n",
      "المقدم: سامي: زين، دكتورة ليلى، مثل ما قلنا في المقدمة، موضوعنا اليوم عن العلاقة بين الذكاء الاصطناعي والثقافة العربية. وش رايك نبدأ بالنقطة اللي كثير ناس يتكلمون عنها: الفجوة الرقمية وهيمنة المحتوى الغربي؟ يعني الأرقام مخيفة، 78% من المحتوى رقمي بالإنجليزية، مقابل 3% فقط بالعربية. هل نقدر نسد هالفجوة؟\n",
      "\n",
      "الضيف: د. ليلى: صحيح سامي، الأرقام فعلاً مفزعة. يعني، لو تأملنا شوي، الفجوة هذه تعكس مشكلات أعمق: نقص التمويل، قلة المبادرات المجتمعية، وأحياناً حتى عدم وجود رؤية واضحة. لكن ما أنكر إن فيه جهود بدأت تظهر مثل تطوير نماذج عربية، زي جايس والحوراء. هذي خطوات جميلة، لكنها تحتاج دعم أكبر.\n",
      "\n",
      "المقدم: سامي: لحظة، جايس؟ هذا مشروع إماراتي، صح؟ أنا سمعت عنه، بس وش وضعه؟ وهل المبادرات الفردية تكفي؟ يعني، هل نحتاج نعتمد على الحكومات بس، أو المجتمع المدني له دور أكبر؟\n",
      "\n",
      "الضيف: د. ليلى: بالضبط، جايس مشروع إماراتي مميز يخدم اللغة العربية. لكن لو بنكون واقعين، المبادرات الحكومية أساسية لأنها توفر التمويل والبنية التحتية. ومع ذلك، المجتمع المدني له دور كبير، مثل دعم المطورين المستقلين والمؤسسات الصغيرة اللي تشتغل في هذا المجال. لازم يكون فيه شراكة بين الطرفين، وإلا الجهود بتكون محدودة.\n",
      "\n",
      "المقدم: سامي: أممم، يعني كأنك تقولين إننا بحاجة لتوازن؟ بس، بصراحة، أنا خايف إن الأجيال القادمة تكون أكثر انفتاحاً على المحتوى الإنجليزي، خاصة مع هيمنته في العالم الرقمي. هل تحسين أن اللغة العربية في خطر؟\n",
      "\n",
      "الضيف: د. ليلى: سامي، هذا سؤال حساس. يعني شلون أقول لك، اللغة العربية فعلاً تواجه تحديات، لكن ما أظن إنها في خطر مباشر. إذا اشتغلنا على تحسين المحتوى العربي الرقمي وزيادة جاذبيته، أعتقد إن الأجيال القادمة بتكون أكثر انفتاحاً عليه. مثل ما يقولون، \"من عرف قدر نفسه لم يهلك\"، ولازم نعرف قيمة لغتنا وثقافتنا.\n",
      "\n",
      "المقدم: سامي: جميل، بس هذا يذكرني بشيء قرأته مؤخراً عن تأثير التكنولوجيا على اللهجات المحلية. هل تعتقدين أن هذا التحدي ممكن يعوق تطوير نماذج ذكاء اصطناعي تفهم كل السياقات العربية؟\n",
      "\n",
      "الضيف: د. ليلى: والله سؤال ذكي، سامي. شوف، اللهجات العربية متنوعة جداً، وهذا جزء من جمال لغتنا. لكن فعلاً، هذا التنوع ممكن يكون عائقاً إذا ما كان هناك جهود لتوحيد بعض المفاهيم. يعني تخيل لو نموذج ذكاء اصطناعي يواجه صعوبة في فهم كلمة بأكثر من معنى! لكن الحل يكمن في تدريب النماذج على بيانات متنوعة تغطي اللهجات المختلفة.\n",
      "\n",
      "المقدم: سامي: طيب، بما إننا دخلنا في موضوع الذكاء الاصطناعي، هل تحسين إنه ممكن يؤدي لتحريف بعض المفاهيم الثقافية التقليدية؟ خاصة إذا كان مدرب على بيانات غربية؟\n",
      "\n",
      "الضيف: د. ليلى: صحيح، هذه نقطة خطيرة. يعني النماذج الغربية قد تواجه صعوبة في فهم السياقات الثقافية العربية، لكن هذا ما يعني إننا لازم نستسلم. تطوير نماذج محلية هو الحل الأمثل. أذكر مرة حضرت معرض تقني، وكان علي شرح مفهوم \"الكرم العربي\" لأحد المطورين الأجانب. شافه كمفهوم اقتصادي بحت! شوف كيف الفهم مختلف.\n",
      "\n",
      "المقدم: سامي: هههه، تخيل لو الذكاء الاصطناعي يحاول يفهم الأمثال العربية، زي \"ضربني وبكى سبقني واشتكى\"، كيف بيترجمها؟!\n",
      "\n",
      "الضيف: د. ليلى: هههه، يا الله، صدقت! أعتقد إنه بيتلخبط تماماً. لكن هذا يثبت أهمية تطوير نماذج تفهم التفاصيل الثقافية الدقيقة، بدل ما تكون مجرّد ترجمة حرفية.\n",
      "\n",
      "المقدم: سامي: طيب، خلينا نغير زاوية النقاش شوي. هل تحسين إنه الذكاء الاصطناعي ممكن يكون أداة لتعزيز الثقافة العربية بدلاً من تهديدها؟\n",
      "\n",
      "الضيف: د. ليلى: أكيد، إذا وجهناه بشكل صحيح، ممكن يساهم في نشر اللغة العربية وتوثيق التراث بطرق مبتكرة. تخيل لو الذكاء الاصطناعي يقرأ قصائد المتنبي بأصوات مختلفة أو يساعد الأطفال يتعلمون اللغة بطريقة ممتعة!\n",
      "\n",
      "المقدم: سامي: واو، تخيل، أطفال يتعلمون اللغة العربية عن طريق ألعاب مدعومة بالذكاء الاصطناعي. هذا فعلاً شيء ملهم. لكن، هل يمكن للتكنولوجيا تكون بديلاً عن التدخلات البشرية في الحفاظ على الثقافة؟\n",
      "\n",
      "الضيف: د. ليلى: لا أعتقد، سامي. التكنولوجيا أداة قوية، لكنها تحتاج تدخل بشري لضمان الدقة والحفاظ على الروح الثقافية. مثل ما يقول المثل، \"اللغة هي روح الأمة\"، والتكنولوجيا لازم تكون جسراً بين الماضي والمستقبل، مش بديلاً.\n",
      "\n",
      "المقدم: سامي: صحيح، كلامك يحفز التفكير. يعني التكنولوجيا ممكن تكون داعمة، بس مش كافية لوحدها. دكتورة، الله يعطيك العافية، النقاش معك كان جداً ممتع وغني بالأفكار. مستمعينا، خلونا نختم ونقول إن المستقبل بيدنا إذا بدأنا نتخذ خطوات جدية. شكراً دكتورة ليلى على وقتك ومشاركتك القيّمة!\n",
      "\n",
      "الضيف: د. ليلى: الله يعافيك سامي، وأنا جداً استمتعت بالنقاش. شكراً لك ولمستمعينا الكرام.\n",
      "\n",
      "=== الختام ===\n",
      "المقدم: اممم، يعني شوف دكتورة ليلى، النقاش اليوم كان فعلاً ثري ومليء بالأفكار العميقة. تكلمنا عن الذكاء الاصطناعي وتأثيره على ثقافتنا العربية، وشفنا كيف ممكن يكون سلاح ذو حدين: تهديد إذا أُسيء استخدامه، وفرصة إذا عرفنا كيف نستغله. طبعاً المستقبل، مثل ما ذكرتِ، بيدنا، وبقراراتنا اليوم نقدر نرسم ملامحه. وش رايك نختم برسالة منك للمستمعين؟\n",
      "\n",
      "الضيف: أكيد سامي. يعني أولاً، الله يعطيكم العافية على هذا الحوار الجميل والمهم جداً. رسالتي للمستمعين هي إن كل واحد فينا عنده دور، مهما كان صغير، في الحفاظ على هويتنا الثقافية. دعم المبادرات اللي تهتم بالمحتوى العربي الرقمي، المشاركة الفاعلة في منصات التواصل العربية، وحتى مجرد الاهتمام باللغة والهوية في حياتنا اليومية، كلها خطوات مهمة. مثل ما يقولون، \"الجذور العميقة لا تخشى الرياح\"، وإذا حافظنا على جذورنا، ما في شيء يقدر يهددنا.\n",
      "\n",
      "المقدم: واااو، كلام كبير جداً. فعلاً مثل ما قلتي، الجذور هي الأساس، وإذا كانت قوية، الهوية تبقى مهما تغيرت الظروف. طبعاً مستمعينا، إذا تعلمنا شيء اليوم، فهو إن التكنولوجيا مش عدو، هي مجرد أداة، والطريقة اللي نستخدمها فيها هي اللي تحدد النتيجة. الله يعافيك دكتورة ليلى على وقتك ومشاركتك القيمة، والله كان حديث ممتع جداً.\n",
      "\n",
      "الضيف: الله يعافيك سامي، وأنا فعلاً استمتعت بالنقاش معكم. شكراً لكم ولكل المستمعين الكرام.\n",
      "\n",
      "المقدم: شكراً لكم مستمعينا، وجودكم معنا دائماً يعطينا الحماس للاستمرار. لا تنسوا تشاركونا آرائكم على منصات التواصل الاجتماعي وتقولون لنا وش المواضيع اللي تحبون نناقشها في الحلقات الجاية. وكالعادة، نبغى نسمع منكم، لأنكم جزء من هذا الحوار.\n",
      "\n",
      "المقدم: نختم ونقول، مثل ما يقول المثل \"من عرف قدر نفسه لم يهلك\"، خلونا نعرف قدر ثقافتنا وهويتنا ونحافظ عليها. إلى اللقاء في الحلقة القادمة من \"نبض الثقافة\"، مع موضوع جديد وقصة جديدة. مع السلامة، وكونوا بخير دائماً!\n"
     ]
    }
   ],
   "source": [
    "script_generator = HybridScriptGenerator(deployment, \"Fanar-C-1-8.7B\")\n",
    "script_result = script_generator.generate_complete_script(topic, final_outline)\n",
    "print(script_result[\"complete_script\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
